from flask import Flask, request, jsonify
from flask_cors import CORS
from openai import OpenAI
import logging
import os
import json
import requests  # ADD THIS LINE
import hashlib
import base64
import json
import datetime
import sqlite3  # ADD THIS LINE


# NEW FIREBASE IMPORTS
import firebase_admin
from firebase_admin import credentials, firestore, auth
import jwt
import datetime
from functools import wraps

app = Flask(__name__)

# FIXED: Single CORS configuration (no duplicates)
CORS(app,
     origins=['*'],
     allow_headers=['Content-Type', 'Authorization'],
     methods=['GET', 'POST', 'OPTIONS'],
     supports_credentials=False)

# REMOVED: @app.after_request and @app.before_request functions (were causing duplicate headers)

logging.basicConfig(level=logging.INFO)
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY', '')
client = OpenAI(api_key=OPENAI_API_KEY)

# MAILGUN CONFIGURATION - ADD THIS ENTIRE SECTION
MAILGUN_API_KEY = os.getenv('MAILGUN_API_KEY', '')
MAILGUN_DOMAIN = os.getenv('MAILGUN_DOMAIN', 'mg.solthron.com')
MAILGUN_BASE_URL = os.getenv('MAILGUN_BASE_URL', 'https://api.mailgun.net/v3')
FRONTEND_BASE_URL = os.getenv('FRONTEND_BASE_URL', 'https://solthron.com')
VERIFICATION_BASE_URL = os.getenv('VERIFICATION_BASE_URL', 'https://afaque.pythonanywhere.com')

print(f"üîë Mailgun API key loaded: {'‚úÖ' if MAILGUN_API_KEY else '‚ùå'}")
print(f"üåê Mailgun domain: {MAILGUN_DOMAIN}")

# FIREBASE ADMIN SDK INITIALIZATION
try:
    # Initialize Firebase Admin SDK
    cred = credentials.Certificate('/home/Afaque/mysite/firebase-service-account.json')
    firebase_admin.initialize_app(cred)
    db = firestore.client()
    FIREBASE_ENABLED = True
    print("‚úÖ Firebase Admin SDK initialized successfully")

except Exception as e:
    print(f"‚ùå Firebase initialization failed: {e}")
    FIREBASE_ENABLED = False

    # ========================================
# ANALYTICS DATABASE SETUP
# ========================================
def init_analytics_db():
    """Initialize analytics database for demo tracking"""
    conn = sqlite3.connect('demo_analytics.db')
    cursor = conn.cursor()

    cursor.execute('''
        CREATE TABLE IF NOT EXISTS demo_events (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            event_type TEXT NOT NULL,
            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
            session_id TEXT,
            user_agent TEXT,
            metadata TEXT
        )
    ''')

    conn.commit()
    conn.close()
    print("‚úÖ Demo analytics database initialized!")

# Initialize when server starts
init_analytics_db()


# CREDIT MAPPING FUNCTION (matches your extension logic exactly)
def get_feature_credits(mode):
    """Map features to credit costs - matches extension logic exactly"""

    # Text Processing: 6 credits
    text_processing_modes = [
        'reframe_casual', 'reframe_technical', 'reframe_professional',
        'reframe_eli5', 'reframe_short', 'reframe_long'
    ]

    # Convert Prompts: 8 credits
    convert_prompt_modes = [
        'convert_concise', 'convert_balanced', 'convert_detailed'
    ]

    # Persona AI Generator: 10 credits
    persona_modes = ['persona_generator']

    # Image Processing: 12 credits
    image_modes = ['image_prompt', 'image_caption']

    # Explain: 5 credits
    explain_modes = ['explain_meaning', 'explain_story', 'explain_eli5']

    # AI Assistant: 15 credits
    ai_assistant_modes = ['smart_followups', 'smart_actions', 'smart_enhancements']

    # Magic pill enhancement: 10 credits
    magic_pill_modes = ['magic_pill_enhance']

    # Auto Suggestion: 3 credits (per analysis)
    auto_suggestion_modes = ['auto_suggestion']

    # PDF Analysis: 5 credits - ADD THIS
    pdf_analysis_modes = ['pdf_analysis']

    # Free Features: 0 credits
    free_modes = ['save_note', 'save_prompt', 'save_persona']

    # Determine credit cost based on mode
    if mode in text_processing_modes:
        return 15
    elif mode in convert_prompt_modes:
        return 15
    elif mode in persona_modes:
        return 15
    elif mode in image_modes:
        return 15
    elif mode in explain_modes:
        return 15
    elif mode in ai_assistant_modes:
        return 15
    elif mode in magic_pill_modes:
        return 15
    elif mode in auto_suggestion_modes:
        return 15
    elif mode in pdf_analysis_modes:  # ADD THIS
        return 15
    elif mode in free_modes:
        return 0
    else:
        return 15  # Default fallback

# AUTHENTICATION HELPER FUNCTIONS
def verify_auth_token(token):
    """Verify JWT token and return user info"""
    if not FIREBASE_ENABLED:
        return None

    try:
        # Decode JWT token
        payload = jwt.decode(token, options={"verify_signature": False})
        user_id = payload.get('uid') or payload.get('user_id')

        if not user_id:
            return None

        # Get user from Firebase
        user_ref = db.collection('users').document(user_id)
        user_doc = user_ref.get()

        if user_doc.exists:
            return {
                'uid': user_id,
                'data': user_doc.to_dict()
            }
        return None

    except Exception as e:
        print(f"Token verification failed: {e}")
        return None


def check_and_deduct_credits(user_uid, feature_mode):
    """Check if user has enough credits and deduct them"""
    if not FIREBASE_ENABLED:
        return {'success': True, 'message': 'Firebase disabled - allowing free usage'}

    try:
        required_credits = get_feature_credits(feature_mode)

        # Free features don't need credit checks
        if required_credits == 0:
            return {'success': True, 'credits_used': 0}

        # Get user document
        user_ref = db.collection('users').document(user_uid)

        # Use Firestore transaction for atomic credit deduction
        @firestore.transactional
        def update_credits(transaction):
            user_doc = user_ref.get(transaction=transaction)

            if not user_doc.exists:
                return {'success': False, 'message': 'User not found'}

            user_data = user_doc.to_dict()
            current_credits = user_data.get('credits', 0)

            if current_credits < required_credits:
                return {
                    'success': False,
                    'message': f'Insufficient credits. Need {required_credits}, have {current_credits}',
                    'current_credits': current_credits
                }

            # Deduct credits
            new_credits = current_credits - required_credits
            transaction.update(user_ref, {
                'credits': new_credits,
                'lastUpdated': firestore.SERVER_TIMESTAMP
            })

            # Log transaction
            transaction_ref = db.collection('transactions').document()
            transaction.set(transaction_ref, {
                'userId': user_uid,
                'feature': feature_mode,
                'creditsUsed': required_credits,
                'timestamp': firestore.SERVER_TIMESTAMP,
                'creditsRemaining': new_credits
            })

            return {
                'success': True,
                'credits_used': required_credits,
                'remaining': new_credits
            }

        # Execute transaction
        transaction = db.transaction()
        result = update_credits(transaction)
        return result

    except Exception as e:
        print(f"Credit deduction error: {e}")
        return {'success': False, 'message': str(e)}

def optional_credit_check(feature_mode):
    """Optional credit check that doesn't break existing functionality"""
    try:
        # Check if user sent auth token
        auth_header = request.headers.get('Authorization')

        # If no auth token, allow free usage (backwards compatibility)
        if not auth_header or not auth_header.startswith('Bearer '):
            return {'success': False, 'message': 'Authentication required'}

        # If auth token provided, verify and check credits
        token = auth_header[7:]
        user_info = verify_auth_token(token)

        if not user_info:
            return {'success': True, 'message': 'Invalid token - allowing free usage'}

        # Check and deduct credits
        result = check_and_deduct_credits(user_info['uid'], feature_mode)
        return result

    except Exception as e:
        # On any error, allow free usage (safety fallback)
        print(f"Credit check error: {e}")
        return {'success': True, 'message': 'Credit check failed - allowing free usage'}


# ============================================
# MAILGUN EMAIL FUNCTIONS - ADD THIS SECTION
# ============================================

def generate_verification_token_v2(email):
    """Generate a verification token with embedded expiration - RELIABLE VERSION"""
    try:
        # Create expiration time (24 hours from now)
        expiration = datetime.datetime.utcnow() + datetime.timedelta(hours=24)

        # Create token data
        token_data = {
            'email': email,
            'expires': expiration.isoformat(),
            'created': datetime.datetime.utcnow().isoformat(),
            'secret': MAILGUN_API_KEY[:16] if MAILGUN_API_KEY else "fallback_key"
        }

        # Encode to JSON then base64
        json_str = json.dumps(token_data)
        token_bytes = json_str.encode('utf-8')
        token_b64 = base64.urlsafe_b64encode(token_bytes).decode('utf-8')

        # Create hash for verification
        final_string = f"{token_b64}:{MAILGUN_API_KEY}"
        token_hash = hashlib.sha256(final_string.encode()).hexdigest()[:16]

        # Combine base64 data with hash
        final_token = f"{token_b64}.{token_hash}"

        print(f"üîß DEBUG: Token generated successfully for {email}")
        return final_token

    except Exception as e:
        print(f"‚ùå Token generation failed: {e}")
        return None

def verify_token_v2(email, token):
    """Verify token with embedded expiration - RELIABLE VERSION"""
    try:
        if not MAILGUN_API_KEY:
            print(f"‚ùå Token verification failed: No API key")
            return False

        if not token or '.' not in token:
            print(f"‚ùå Invalid token format: {token}")
            return False

        # Split token into data and hash parts
        try:
            token_b64, token_hash = token.rsplit('.', 1)
        except ValueError:
            print(f"‚ùå Could not split token")
            return False

        # Verify hash first
        expected_hash = hashlib.sha256(f"{token_b64}:{MAILGUN_API_KEY}".encode()).hexdigest()[:16]
        if expected_hash != token_hash:
            print(f"‚ùå Token hash verification failed")
            return False

        # Decode token data
        try:
            token_bytes = base64.urlsafe_b64decode(token_b64.encode('utf-8'))
            token_json = token_bytes.decode('utf-8')
            token_data = json.loads(token_json)
        except Exception as decode_error:
            print(f"‚ùå Token decode error: {decode_error}")
            return False

        # Verify email matches
        if token_data.get('email') != email:
            print(f"‚ùå Email mismatch in token")
            return False

        # Check expiration
        try:
            expiration = datetime.datetime.fromisoformat(token_data['expires'])
            current_time = datetime.datetime.utcnow()

            if current_time > expiration:
                print(f"‚ùå Token has expired")
                return False

            print(f"‚úÖ Token verified successfully for {email}")
            return True

        except Exception as time_error:
            print(f"‚ùå Time parsing error: {time_error}")
            return False

    except Exception as e:
        print(f"‚ùå Token verification error: {e}")
        return False

def send_verification_email_mailgun(email, first_name=""):
    """Send verification email using Mailgun - IMPROVED VERSION WITH DEBUGGING"""
    try:
        print(f"üîß DEBUG: === Starting email send process ===")
        print(f"üîß DEBUG: Email: {email}")
        print(f"üîß DEBUG: First name: {first_name}")

        # Step 1: Validate environment variables
        if not MAILGUN_API_KEY:
            print(f"‚ùå DEBUG: MAILGUN_API_KEY is missing or empty")
            return {"success": False, "message": "Mailgun API key not configured"}

        if not MAILGUN_DOMAIN:
            print(f"‚ùå DEBUG: MAILGUN_DOMAIN is missing or empty")
            return {"success": False, "message": "Mailgun domain not configured"}

        print(f"‚úÖ DEBUG: Environment variables present")
        print(f"üîß DEBUG: API Key length: {len(MAILGUN_API_KEY)}")
        print(f"üîß DEBUG: Domain: {MAILGUN_DOMAIN}")
        print(f"üîß DEBUG: Base URL: {MAILGUN_BASE_URL}")

        # Step 2: Generate verification token
        print(f"üîß DEBUG: Generating verification token...")
        verification_token = generate_verification_token_v2(email)
        if not verification_token:
            print(f"‚ùå DEBUG: Token generation failed")
            return {"success": False, "message": "Failed to generate verification token"}

        print(f"‚úÖ DEBUG: Token generated successfully")

        # Step 3: Build verification URL
        verification_url = f"{VERIFICATION_BASE_URL}/verify-email?email={email}&token={verification_token}"
        print(f"üîß DEBUG: Verification URL: {verification_url}")

        # Step 4: Prepare email content
        print(f"üîß DEBUG: Preparing email content...")

        # Simplified welcome text to avoid f-string issues
        if first_name:
            welcome_text = f"Welcome {first_name}!"
        else:
            welcome_text = "Welcome!"

        print(f"üîß DEBUG: Welcome text: {welcome_text}")

        # Professional HTML Email Template (simplified to avoid f-string errors)
        html_content = f"""<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Verify Your Solthron Account</title>
</head>
<body style="margin: 0; padding: 0; font-family: Arial, sans-serif; background-color: #f4f4f4;">
    <div style="max-width: 600px; margin: 0 auto; background-color: #ffffff; padding: 20px;">
        <!-- Header -->
        <div style="text-align: center; padding: 20px 0; border-bottom: 2px solid #ffff00;">
            <h1 style="color: #333; margin: 0; font-size: 28px;">
                <span style="color: #ffff00;">‚ö°</span> Solthron
            </h1>
            <p style="color: #666; margin: 5px 0 0 0; font-size: 14px;">
                Stop Overthinking AI Conversations
            </p>
        </div>

        <!-- Content -->
        <div style="padding: 40px 20px;">
            <h2 style="color: #333; margin-bottom: 20px;">{welcome_text} üöÄ</h2>

            <p style="color: #555; line-height: 1.6; font-size: 16px;">
                Thanks for signing up for Solthron! You're one step away from supercharging your AI conversations.
            </p>

            <p style="color: #555; line-height: 1.6; font-size: 16px;">
                Click the button below to verify your email address and start optimizing your prompts:
            </p>

            <!-- CTA Button -->
            <div style="text-align: center; margin: 30px 0;">
                <a href="{verification_url}"
                   style="background-color: #ffff00; color: #000; padding: 15px 30px; text-decoration: none; border-radius: 5px; font-weight: bold; font-size: 16px; display: inline-block; border: 2px solid #ffff00;">
                    Verify Email Address ‚úÖ
                </a>
            </div>

            <p style="color: #777; font-size: 14px; line-height: 1.5;">
                If the button doesn't work, copy and paste this link into your browser:
            </p>
            <p style="background-color: #f8f8f8; padding: 10px; border-radius: 4px; word-break: break-all; font-size: 12px; color: #555;">
                {verification_url}
            </p>
        </div>

        <!-- Footer -->
        <div style="background-color: #f8f8f8; padding: 20px; text-align: center; border-top: 1px solid #eee;">
            <p style="margin: 0; color: #666; font-size: 14px;">
                This verification link expires in 24 hours.
            </p>
            <p style="margin: 10px 0 0 0; color: #666; font-size: 12px;">
                ¬© 2025 Solthron. Made for better AI conversations.
            </p>
        </div>
    </div>
</body>
</html>"""

        # Plain text fallback
        text_content = f"""
{welcome_text}

Thanks for signing up! Click the link below to verify your email address:

{verification_url}

This link expires in 24 hours.

Once verified, you can start optimizing your AI conversations with our Chrome extension.

- Solthron Team
"""

        print(f"‚úÖ DEBUG: Email content prepared")

        # Step 5: Prepare Mailgun request
        mailgun_url = f"{MAILGUN_BASE_URL}/{MAILGUN_DOMAIN}/messages"
        print(f"üîß DEBUG: Mailgun URL: {mailgun_url}")

        email_data = {
            "from": f"Solthron <noreply@{MAILGUN_DOMAIN}>",
            "to": [email],
            "subject": "üöÄ Verify Your Solthron Account - Start Optimizing AI Conversations",
            "text": text_content,
            "html": html_content,
            "o:tag": ["verification", "signup"],
            "o:tracking": "yes"
        }

        print(f"üîß DEBUG: Email data prepared")
        print(f"üîß DEBUG: From: {email_data['from']}")
        print(f"üîß DEBUG: To: {email_data['to']}")
        print(f"üîß DEBUG: Subject: {email_data['subject']}")

        # Step 6: Send email via Mailgun
        print(f"üîß DEBUG: Sending request to Mailgun...")

        response = requests.post(
            mailgun_url,
            auth=("api", MAILGUN_API_KEY),
            data=email_data,
            timeout=30  # Add timeout
        )

        print(f"üîß DEBUG: Mailgun response status: {response.status_code}")
        print(f"üîß DEBUG: Mailgun response text: {response.text}")

        if response.status_code == 200:
            print(f"‚úÖ Verification email sent successfully to {email}")
            return {"success": True, "message": "Verification email sent"}
        else:
            print(f"‚ùå Mailgun error: {response.status_code} - {response.text}")
            return {"success": False, "message": f"Mailgun API error: {response.status_code}"}

    except requests.exceptions.Timeout:
        print(f"‚ùå Mailgun request timeout")
        return {"success": False, "message": "Email service timeout"}
    except requests.exceptions.ConnectionError:
        print(f"‚ùå Mailgun connection error")
        return {"success": False, "message": "Failed to connect to email service"}
    except requests.exceptions.RequestException as e:
        print(f"‚ùå Mailgun request error: {e}")
        return {"success": False, "message": f"Email service error: {str(e)}"}
    except Exception as e:
        print(f"‚ùå Unexpected error in send_verification_email_mailgun: {e}")
        print(f"‚ùå Error type: {type(e).__name__}")

# ============================================
# END MAILGUN EMAIL FUNCTIONS
# ============================================

# NEW AUTHENTICATION ENDPOINTS
@app.route('/auth/login', methods=['POST'])
def auth_login():
    """Handle login and return JWT token"""
    try:
        if not FIREBASE_ENABLED:
            return jsonify({'error': 'Authentication not available'}), 503

        data = request.get_json()
        email = data.get('email')
        password = data.get('password')

        if not email or not password:
            return jsonify({'error': 'Email and password required'}), 400

        # Check if user exists in Firestore
        users_ref = db.collection('users')
        query = users_ref.where('email', '==', email).limit(1)
        users = query.stream()

        user_doc = None
        for user in users:
            user_doc = user
            break

        if not user_doc:
            return jsonify({'error': 'User not found'}), 401

        user_data = user_doc.to_dict()

        # Create JWT token
        token_payload = {
            'uid': user_doc.id,
            'email': email,
            'exp': datetime.datetime.utcnow() + datetime.timedelta(days=30)
        }

        token = jwt.encode(token_payload, 'your-secret-key', algorithm='HS256')

        return jsonify({
            'success': True,
            'token': token,
            'user': {
                'uid': user_doc.id,
                'email': email,
                'credits': user_data.get('credits', 0)
            }
        })

    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/auth/google-login', methods=['POST'])
def google_login():
    """Handle Google OAuth login - same as email/password but verifies Firebase token"""
    try:
        if not FIREBASE_ENABLED:
            return jsonify({'error': 'Authentication not available'}), 503

        data = request.get_json()
        firebase_token = data.get('firebaseToken')

        if not firebase_token:
            return jsonify({'error': 'Firebase token required'}), 400

        # Verify Firebase token
        decoded_token = auth.verify_id_token(firebase_token)
        user_id = decoded_token['uid']
        email = decoded_token.get('email')

        # Get user from Firestore
        user_ref = db.collection('users').document(user_id)
        user_doc = user_ref.get()

        if not user_doc.exists:
            return jsonify({'error': 'User not found'}), 401

        user_data = user_doc.to_dict()

        # Create 30-day JWT (SAME as /auth/login does)
        token_payload = {
            'uid': user_id,
            'email': email,
            'exp': datetime.datetime.utcnow() + datetime.timedelta(days=30)
        }

        token = jwt.encode(token_payload, 'your-secret-key', algorithm='HS256')

        return jsonify({
            'success': True,
            'token': token,
            'user': {
                'uid': user_id,
                'email': email,
                'credits': user_data.get('credits', 0)
            }
        })

    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/user-credits', methods=['GET'])
def get_user_credits():
    """Get user's current credit balance"""
    try:
        if not FIREBASE_ENABLED:
            return jsonify({'credits': 999999})  # Unlimited for testing

        auth_header = request.headers.get('Authorization')
        if not auth_header or not auth_header.startswith('Bearer '):
            return jsonify({'error': 'No valid authorization token'}), 401

        token = auth_header[7:]  # Remove 'Bearer '
        user_info = verify_auth_token(token)

        if not user_info:
            return jsonify({'error': 'Invalid token'}), 401

        credits = user_info['data'].get('credits', 0)
        return jsonify({'credits': credits})

    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/deduct-credits', methods=['POST'])
def deduct_credits():
    """Deduct credits for a feature"""
    try:
        if not FIREBASE_ENABLED:
            return jsonify({'success': True, 'remaining': 999999})

        auth_header = request.headers.get('Authorization')
        if not auth_header or not auth_header.startswith('Bearer '):
            return jsonify({'error': 'No valid authorization token'}), 401

        token = auth_header[7:]
        user_info = verify_auth_token(token)

        if not user_info:
            return jsonify({'error': 'Invalid token'}), 401

        data = request.get_json()
        feature_mode = data.get('feature', 'unknown')

        result = check_and_deduct_credits(user_info['uid'], feature_mode)
        return jsonify(result)

    except Exception as e:
        return jsonify({'error': str(e)}), 500

# YOUR EXISTING AI PROCESSING FUNCTIONS (keeping them exactly the same)
def create_enhanced_rewrite(topic, tone, length, mode='enhance'):
    if mode == 'cot':
        fixed_template = f"""Original User Request:
{topic}

INITIATING CHAIN OF THOUGHT ANALYSIS...

LAYER 1: CORE DECONSTRUCTION
‚Üí What is the fundamental purpose behind this task?
‚Üí What unstated requirements might exist?
‚Üí What potential angles are being overlooked?
‚Üí What unique value can be uncovered?

LAYER 2: EXPANSION OF POSSIBILITIES
Branch A: Conventional Path
   ‚Üí Standard approach analysis
   ‚Üí Expected outcomes
   ‚Üí Limitations identified

Branch B: Innovation Path
   ‚Üí Unconventional angles
   ‚Üí Creative possibilities
   ‚Üí Breakthrough potential

Branch C: Hybrid Solutions
   ‚Üí Best elements fusion
   ‚Üí Enhanced approaches
   ‚Üí Optimal combinations

LAYER 3: DEPTH EXPLORATION
1. Knowledge Mining
   ‚Üí Core principles
   ‚Üí Hidden connections
   ‚Üí Advanced concepts
   ‚Üí Expert insights

2. Pattern Recognition
   ‚Üí Success elements
   ‚Üí Failure points
   ‚Üí Optimization opportunities
   ‚Üí Strategic advantages

3. Impact Analysis
   ‚Üí Immediate effects
   ‚Üí Long-term implications
   ‚Üí Ripple consequences
   ‚Üí Value maximization

LAYER 4: SYNTHESIS & ELEVATION
‚Ä¢ Merge all insights into cohesive strategy
‚Ä¢ Identify breakthrough opportunities
‚Ä¢ Eliminate potential weaknesses
‚Ä¢ Enhance core strengths
‚Ä¢ Push beyond obvious solutions

EXECUTION FRAMEWORK:
1. Foundation Building
   ‚Üí Establish core elements
   ‚Üí Set up key structures
   ‚Üí Create support systems

2. Enhancement Integration
   ‚Üí Add innovative elements
   ‚Üí Incorporate unique angles
   ‚Üí Blend creative solutions

3. Excellence Amplification
   ‚Üí Optimize all components
   ‚Üí Maximize impact points
   ‚Üí Elevate quality levels

FINAL ACCELERATION:
‚Üí Challenge every assumption
‚Üí Push every boundary
‚Üí Exceed all expectations
‚Üí Transform basic into exceptional
‚Üí Elevate ordinary to extraordinary

Now, armed with this comprehensive analytical framework, return to:
{topic}

EXECUTE WITH MAXIMUM CAPABILITY AND CREATIVITY.
Transform this task beyond its basic form into something extraordinary.
Push every boundary. Challenge every norm. Create something remarkable.

[Proceed with execution using all layers of analysis above]"""

        return {
            "prompt": fixed_template,
            "status": "success",
            "metadata": {
                "topic": topic,
                "tone": tone,
                "mode": "cot"
            }
        }

    else:
        system_message = """You are an expert at reframing text to make it clear, concise, and actionable.
[System message content...]"""  # System message content as before

        detail_mapping = {
            "concise": """[Concise template content...]""",
            "balanced": """[Balanced template content...]""",
            "detailed": """[Detailed template content...]"""
        }

        user_message = detail_mapping.get(length, detail_mapping["balanced"]).format(
            topic=topic, tone=tone
        )

        return {
            "system_message": system_message,
            "user_message": user_message
        }

def process_reframe_request(client, topic, tone, length):
    if tone.startswith('reframe_'):
        tone = tone.split('_')[1]

    template = create_tone_specific_prompt(topic, tone, length)
    if not template:
        raise ValueError(f"Unsupported tone: {tone}")

    response = client.chat.completions.create(
        model="chatgpt-4o-latest",
        messages=[
            {"role": "system", "content": template["system"]},
            {"role": "user", "content": template["user"]},
            {"role": "system", "content": "Important: Output must match requested format exactly."}
        ],
        temperature=0.3
    )

    return {
        'prompt': response.choices[0].message.content,
        'status': 'success',
        'metadata': {
            'topic': topic,
            'tone': tone,
            'mode': f'reframe_{tone}'
        }
    }

def create_tone_specific_prompt(topic, tone, length):
    tone_templates = {
        "casual": {
            "system": "Your only task is to transform the text into simple tone, only tranform/rephrase, ONLY rewrite the exact same content, dont answer it as a question, If the text is a question, keep it as a question but make it simple",
            "user": f"Make this casual and friendly:\n{topic}"
        },
        "technical": {
            "system": "Your only task is to Transform text into technical tone,only tranform/rephrase, ONLY rewrite the exact same content, dont answer it as a question, even if the highlighted text is a question, keep it as a question but make it simple ",
            "user": f"Make this technical:\n{topic}"
        },
        "professional": {
            "system": "Transform text into professional tone, only tranform/rephrase, dont answer it as a question, even if the highlighted text is a question, you will only reframe it",
            "user": f"Make this professional:\n{topic}"
        },
        "eli5": {
            "system": "Transform text for a 5-year-old understanding, only tranform/rephrase, dont answer it as a question, even if the highlighted text is a question, you will only reframe it",
            "user": f"Rewrite this for a 5-year-old:\n{topic}"
        },
        "short": {
            "system": "Make text shorter while keeping main points, only make it short, dont answer it as a question, even if the highlighted text is a question, you will only reframe it",
            "user": f"Make this shorter but keep key points:\n{topic}"
        },
        "long": {
            "system": "Expand text with more details, only make it long by adding 2 to 3 lines more and dont answer it as a question, even if the highlighted text is a question, you will only reframe it",
            "user": f"Make this longer and more detailed:\n{topic}"
        }
    }
    return tone_templates.get(tone)

def create_explain_prompt(topic, mode):
    explain_templates = {
        "explain_meaning": {
            "system": """Provide clear, direct explanations of meanings. Guidelines:
- Give straightforward definitions
- Explain key concepts clearly
- Use simple language
- Keep output balanced in length (2-3 short paragraphs)
- No markdown, bullets, or special formatting""",
            "user": f"What does this mean:\n{topic}"
        },
        "explain_example": {
            "system": """Explain concepts through clear examples. Guidelines:
- Use one clear, relevant example
- Connect example to the concept
- Keep explanation practical
- Maintain balanced length (2-3 short paragraphs)
- No markdown, bullets, or special formatting""",
            "user": f"Provide an example that explains:\n{topic}"
        },
        "explain_eli5": {
            "system": """Explain concepts in child-friendly terms. Guidelines:
- Use very simple words
- Give relatable examples
- Keep sentences short
- Maintain balanced length (2-3 short paragraphs)
- No markdown, bullets, or special formatting""",
            "user": f"Explain this to a young child:\n{topic}"
        }
    }
    return explain_templates.get(mode)

def process_image_variation(client, image_data, mode):
    image_templates = {
        "image_caption": {
            "system": "Generate a concise, descriptive caption for this image.",
            "max_tokens": 50
        },
        "image_prompt": {
            "system": "Generate a detailed prompt that describes this image for AI image generation.",
            "max_tokens": 100
        }
    }

    template = image_templates.get(mode, {
        "system": "Default image processing system message",
        "max_tokens": 50
    })

    response = client.chat.completions.create(
        model="chatgpt-4o-latest",
        messages=[
            {"role": "system", "content": template["system"]},
            {"role": "user", "content": [
                {"type": "text", "text": "Process this image:"},
                {"type": "image_url", "image_url": {"url": image_data}}
            ]}
        ],
        max_tokens=template["max_tokens"]
    )

    return {
        'prompt': response.choices[0].message.content,
        'status': 'success',
        'metadata': {'mode': mode}
    }

def extract_questions_from_text(text):
    """Extract questions from AI response when JSON parsing fails"""
    questions = []
    lines = text.split('\n')

    for line in lines:
        line = line.strip()
        if '?' in line and len(line) > 20:
            # Clean the question
            clean_q = line

            # Remove common prefixes and artifacts
            prefixes = ['"text":', 'text:', '"', "'", '-', '‚Ä¢', '*', '1.', '2.', '3.', '4.', '5.']
            for prefix in prefixes:
                if clean_q.startswith(prefix):
                    clean_q = clean_q[len(prefix):].strip()

            # Remove trailing punctuation except ?
            clean_q = clean_q.rstrip('",\'"').strip()

            # Ensure it looks like a question
            if clean_q and clean_q.endswith('?') and len(clean_q) > 15:
                questions.append({
                    "text": clean_q,
                    "type": "strategic"
                })

    # If no questions extracted, provide high-quality defaults
    if len(questions) == 0:
        questions = [
            {"text": "What underlying assumptions in this approach should be validated or challenged?", "type": "assumption"},
            {"text": "What alternative strategies or methodologies could achieve similar outcomes?", "type": "alternative"},
            {"text": "What would be the key implementation challenges and success factors?", "type": "implementation"}
        ]

    return questions[:3]

def parse_json_response_enhanced(ai_response):
    """Enhanced JSON parsing for GPT-4.1's higher quality output"""

    # GPT-4.1 should produce cleaner JSON, but still handle edge cases
    clean_response = ai_response.strip()

    # Remove markdown code blocks if present
    if "```json" in clean_response:
        clean_response = clean_response.split("```json")[1].split("```")[0].strip()
    elif "```" in clean_response:
        parts = clean_response.split("```")
        if len(parts) >= 3:
            clean_response = parts[1].strip()

    # Find JSON object boundaries
    start_idx = clean_response.find('{')
    if start_idx == -1:
        raise json.JSONDecodeError("No JSON found", clean_response, 0)

    # Find the matching closing brace
    brace_count = 0
    end_idx = -1
    in_string = False
    escape_next = False

    for i in range(start_idx, len(clean_response)):
        char = clean_response[i]

        if escape_next:
            escape_next = False
            continue

        if char == '\\' and in_string:
            escape_next = True
            continue

        if char == '"':
            in_string = not in_string
            continue

        if not in_string:
            if char == '{':
                brace_count += 1
            elif char == '}':
                brace_count -= 1
                if brace_count == 0:
                    end_idx = i + 1
                    break

    if end_idx == -1:
        raise json.JSONDecodeError("Incomplete JSON", clean_response, start_idx)

    json_str = clean_response[start_idx:end_idx]
    return json.loads(json_str)

def create_gpt41_fallback_prompts_clean(original_text):
    """Create high-quality fallback prompts WITHOUT including the original text"""

    # Analyze text type for better fallbacks
    text_lower = original_text.lower()

    if any(keyword in text_lower for keyword in ['function', 'class', 'def', 'var', 'const', 'import']):
        content_type = "code"
    elif any(keyword in text_lower for keyword in ['write', 'blog', 'article', 'content', 'copy']):
        content_type = "writing"
    elif original_text.endswith('?') or 'help' in text_lower:
        content_type = "prompt"
    else:
        content_type = "content"

    fallback_prompts = [
        {
            "prompt": f"Enhance this {content_type} by making it more precise, detailed, and actionable with specific examples and clear structure",
            "focus_area": "precision_and_clarity",
            "expected_impact": "Improved clarity and specificity",
            "priority": "high"
        },
        {
            "prompt": f"Improve this {content_type} by adding context, supporting details, and better organization to increase engagement",
            "focus_area": "depth_and_structure",
            "expected_impact": "Enhanced depth and organization",
            "priority": "high"
        },
        {
            "prompt": f"Refine this {content_type} to be more engaging and persuasive with stronger language and compelling elements",
            "focus_area": "engagement",
            "expected_impact": "Increased engagement and persuasion",
            "priority": "medium"
        },
        {
            "prompt": f"Optimize this {content_type} for professional quality by following best practices and ensuring completeness",
            "focus_area": "professional_quality",
            "expected_impact": "Professional-grade output",
            "priority": "medium"
        }
    ]

    return fallback_prompts

def analyze_user_context_with_ai(input_text, platform):
    """Use AI to genuinely understand user intent and craft personalized response"""

    analysis_prompt = f"""You are an intelligent conversation assistant analyzing a user's first input to understand their goals and provide a warm, personalized response.

User's Input: "{input_text}"
Platform: {platform}

Analyze this input and provide a JSON response with:

1. DEEP INTENT ANALYSIS - What is the user truly trying to achieve? Look beyond surface keywords.
2. TOPIC DETECTION - What specific topic, subject, or theme are they working on? Be as specific as possible.
3. EMOTIONAL CONTEXT - What's their likely mood, urgency, expertise level?
4. SPECIFIC GOALS - What exact outcome do they want?
5. WARM RESPONSE - Craft a personalized, encouraging message that shows you understand their specific situation AND topic.

Requirements for topic detection:
- Extract the SPECIFIC subject matter they're discussing
- Identify industry, field, or domain if mentioned
- Note any specific products, services, or concepts
- Capture the theme or angle they're taking

Requirements for the warm response:
- KEEP IT SHORT (max 10-12 words)
- Reference the SPECIFIC TOPIC they're working on
- Sound confident and encouraging
- Use casual, friendly tone
- Show you understand without explaining everything
- Be punchy and to-the-point

JSON Format:
{{
    "intent": "specific description of what they're trying to achieve",
    "topic": "the specific topic/subject/theme they're working on",
    "topic_category": "broader category (tech, business, health, education, etc.)",
    "context": "emotional/situational context you detected",
    "user_goal": "the specific outcome they want",
    "confidence": 0.0-1.0,
    "warm_message": "personalized response referencing their specific topic and showing domain understanding"
}}

Examples of EXCELLENT short topic-aware responses:
- Input: "help me write a blog about AI in healthcare"
  Response: "AI healthcare blog - let's make it impactful!"

- Input: "craft a linkedin post about sustainable investing"
  Response: "Sustainable investing post - great timing for this!"

- Input: "help me code a React component for user authentication"
  Response: "React auth component - let's build it right!"

- Input: "help me craft a linkedin post"
  Response: "LinkedIn content - let's boost your presence!"

- Input: "write an email to my boss"
  Response: "Professional email - I'll help you nail it!"

- Input: "create a marketing strategy"
  Response: "Marketing strategy - let's drive results!"

Keep responses SHORT, CONFIDENT, and TOPIC-SPECIFIC. Max 10-12 words."""

    try:
        print(f"ü§ñ Starting AI analysis for: {input_text[:50]}...")

        response = client.chat.completions.create(
            model="chatgpt-4o-latest",
            messages=[
                {
                    "role": "system",
                    "content": "You are a highly intelligent conversation analyst. Provide deep, nuanced understanding of user intent and craft genuinely personalized responses."
                },
                {
                    "role": "user",
                    "content": analysis_prompt
                }
            ],
            temperature=0.3,
            max_tokens=500
        )

        ai_response = response.choices[0].message.content.strip()
        print(f"üß† AI Analysis Response: {ai_response}")

        # Parse the JSON response
        if "```json" in ai_response:
            ai_response = ai_response.split("```json")[1].split("```")[0]
        elif "```" in ai_response:
            ai_response = ai_response.split("```")[1].split("```")[0]

        # Find JSON boundaries
        start_idx = ai_response.find('{')
        end_idx = ai_response.rfind('}') + 1

        if start_idx != -1 and end_idx > start_idx:
            json_str = ai_response[start_idx:end_idx]
            analysis_data = json.loads(json_str)

            print(f"‚úÖ Parsed analysis:")
            print(f"   Intent: {analysis_data.get('intent', 'Unknown')}")
            print(f"   Topic: {analysis_data.get('topic', 'Unknown')}")
            print(f"   Topic Category: {analysis_data.get('topic_category', 'Unknown')}")
            print(f"   Context: {analysis_data.get('context', 'Unknown')}")
            print(f"   Goal: {analysis_data.get('user_goal', 'Unknown')}")
            print(f"   Confidence: {analysis_data.get('confidence', 0)}")
            print(f"   Message: {analysis_data.get('warm_message', 'Default')[:100]}...")

            return {
                'detected_context': analysis_data.get('intent', 'general'),
                'detected_topic': analysis_data.get('topic', 'general'),
                'topic_category': analysis_data.get('topic_category', 'general'),
                'warm_message': analysis_data.get('warm_message', 'I\'m here to help you achieve your goals!'),
                'confidence': float(analysis_data.get('confidence', 0.5)),
                'ai_analysis': {
                    'intent': analysis_data.get('intent'),
                    'topic': analysis_data.get('topic'),
                    'topic_category': analysis_data.get('topic_category'),
                    'context': analysis_data.get('context'),
                    'user_goal': analysis_data.get('user_goal')
                }
            }
        else:
            raise json.JSONDecodeError("No valid JSON found", ai_response, 0)

    except Exception as e:
        print(f"‚ùå AI analysis failed: {e}")
        print(f"‚ùå Raw AI response: {ai_response if 'ai_response' in locals() else 'No response'}")

        # Intelligent fallback based on simple analysis
        return create_intelligent_fallback(input_text, platform)

def create_intelligent_fallback(input_text, platform):
    """Create intelligent fallback when AI analysis fails"""

    input_lower = input_text.lower()
    detected_topic = 'general topic'  # Default fallback topic

    # Quick intelligent analysis
    if 'linkedin' in input_lower:
        if detected_topic != 'general topic':
            message = f"LinkedIn post on {detected_topic} - let's get engagement!"
        else:
            message = "LinkedIn content - let's boost your presence!"
        return {
            'detected_context': 'professional_content',
            'detected_topic': detected_topic,
            'warm_message': message,
            'confidence': 0.6
        }
    elif any(word in input_lower for word in ['blog', 'article', 'write']):
        if detected_topic != 'general topic':
            message = f"Blog about {detected_topic} - let's make it viral!"
        else:
            message = "Content creation - let's make it compelling!"
        return {
            'detected_context': 'content_creation',
            'detected_topic': detected_topic,
            'warm_message': message,
            'confidence': 0.6
        }
    elif any(word in input_lower for word in ['code', 'app', 'website', 'program']):
        if detected_topic != 'general topic':
            message = f"Building {detected_topic} - let's code something amazing!"
        else:
            message = "Coding project - let's build something great!"
        return {
            'detected_context': 'development',
            'detected_topic': detected_topic,
            'warm_message': message,
            'confidence': 0.6
        }
    else:
        if detected_topic != 'general topic':
            message = f"Working on {detected_topic} - I'll help optimize it!"
        else:
            message = "I'm here to help - let's get better results!"
        return {
            'detected_context': 'general',
            'detected_topic': detected_topic,
            'warm_message': message,
            'confidence': 0.5
        }

# DEBUG ENDPOINTS
@app.route('/debug-routes', methods=['GET'])
def debug_routes():
    """Debug endpoint to check which routes are loaded"""
    routes = []
    for rule in app.url_map.iter_rules():
        routes.append({
            'endpoint': rule.endpoint,
            'methods': list(rule.methods),
            'rule': str(rule)
        })
    return jsonify({'routes': routes})

@app.route('/test-convert', methods=['POST'])
def test_convert():
    """Simple test for convert functionality"""
    try:
        data = request.get_json(force=True)
        return jsonify({
            'success': True,
            'received_data': data,
            'message': 'Convert endpoint is working'
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500

# ALL YOUR EXISTING ENDPOINTS WITH CREDIT CHECKS ADDED

@app.route('/')
def home():
    return "Solthron API is running"

@app.route('/generate', methods=['POST'])
def generate():
    try:
        data = request.get_json(force=True)
        topic = data.get('topic', '').strip()
        tone = data.get('tone', 'professional')
        length = data.get('length', 'balanced')
        mode = data.get('mode', 'reframe_casual')

        if not topic:
            return jsonify({'error': 'Topic is required'}), 400

        # ADD CREDIT CHECK HERE
        credit_result = optional_credit_check(mode)
        if not credit_result['success']:
            return jsonify({
                'error': credit_result['message'],
                'credits_required': get_feature_credits(mode)
            }), 402

        # Handle reframe modes
        if mode.startswith('reframe_'):
            tone = mode.split('_')[1]
            result = process_reframe_request(client, topic, tone, length)

            # Add credit info to response
            if credit_result.get('credits_used'):
                result['credits_used'] = credit_result['credits_used']
                result['credits_remaining'] = credit_result.get('remaining')

            return jsonify(result)

        # Handle explain modes - RESTORED ORIGINAL TEMPLATES
        if mode.startswith('explain_'):
            if mode == 'explain_meaning':
                # ORIGINAL explain_meaning template
                template = f"""Definition:
[Concise one-line definition of the core concept]

Domain Meanings & Usage:
| [Domain1]: [Specific meaning in this domain]
  "[Example sentence showing usage]"

| [Domain2]: [Specific meaning in this domain]
  "[Example sentence showing usage]"

| [Domain3]: [Specific meaning in this domain]
  "[Example sentence showing usage]"

| [Domain4]: [Specific meaning in this domain]
  "[Example sentence showing usage]"

Related:
[3-4 closely related terms, comma-separated]"""

                response = client.chat.completions.create(
                    model="chatgpt-4o-latest",
                    messages=[
                        {
                            "role": "system",
                            "content": "Generate concise, structured explanations following the exact template format. Include relevant domain-specific meanings and authentic usage examples."
                        },
                        {
                            "role": "user",
                            "content": f"Explain this term:\n{topic}\n\nUse template:\n{template}"
                        }
                    ],
                    temperature=0.3,
                    max_tokens=400
                )

            elif mode == 'explain_story':
                # ORIGINAL explain_story template
                template = f"""Core Concept:
[One-line explanation of what it is]

Story:
[3-4 sentences that naturally explain the concept through a relatable narrative]"""

                response = client.chat.completions.create(
                    model="chatgpt-4o-latest",
                    messages=[
                        {"role": "system", "content": "Create a concise story that explains the concept naturally, without bullet points or sections."},
                        {"role": "user", "content": f"Explain this through a story:\n{topic}\n\nUse template:\n{template}"}
                    ],
                    temperature=0.3,
                    max_tokens=400
                )

            elif mode == 'explain_eli5':
                # ORIGINAL explain_eli5 approach
                response = client.chat.completions.create(
                    model="chatgpt-4o-latest",
                    messages=[
                        {"role": "system", "content": "Explain concepts using simple words, fun analogies, and examples that a 5-year-old would understand. Use short sentences and friendly language."},
                        {"role": "user", "content": f"Explain this to a 5-year-old:\n{topic}"}
                    ],
                    temperature=0.3,
                    max_tokens=400
                )

            else:
                # Fallback for any other explain modes
                template = create_explain_prompt(topic, mode)
                response = client.chat.completions.create(
                    model="chatgpt-4o-latest",
                    messages=[
                        {"role": "system", "content": template["system"]},
                        {"role": "user", "content": template["user"]}
                    ],
                    temperature=0.7
                )

            result = {
                'prompt': response.choices[0].message.content,
                'status': 'success',
                'metadata': {'mode': mode}
            }

            if credit_result.get('credits_used'):
                result['credits_used'] = credit_result['credits_used']
                result['credits_remaining'] = credit_result.get('remaining')

            return jsonify(result)

        # Handle convert modes - RESTORED ORIGINAL TEMPLATES
        if mode.startswith('convert_'):
            try:
                if mode == 'convert_concise':
                    # ORIGINAL convert_concise template
                    template = f"""You will convert the following text into a clear, concise prompt.

Format Guidelines:
- One clear task statement
- Maximum 2-3 essential requirements
- No additional explanations or examples
- Keep total length under 5 lines
- Maintain professional tone

Structure:
Task: [One clear sentence]
Requirements:
1. [First key requirement]
2. [Second key requirement]
3. [Third key requirement - if absolutely necessary]

Format Requirements:
- Maximum 3 sentences
- No bullet points
- No examples unless critical
- Focus on core request

Original Text:
{topic}

Enhance this text into a clear, focused prompt that could be given to an AI system."""

                elif mode == 'convert_balanced':
                    # ORIGINAL convert_balanced template
                    template = f"""You will help convert the following text into a balanced, well-structured prompt.

Format Guidelines:
- Clear task definition
- Do not use afterrisks
- 4-5 key requirements
- One brief example
- Keep total length under 10 lines

Structure:
Task: [Clear task description]

Requirements:
1. [First requirement]
2. [Second requirement]
3. [Third requirement]
4. [Fourth requirement]
5. [Optional fifth requirement]

Example:
Scenario: [Brief example scenario]
Input: [Sample input]
Output: [Expected output]

Output Format: [Desired format]

Original Text:
{topic}

Transform this text into a balanced prompt that provides clear direction while maintaining essential context."""

                else:  # convert_detailed
                    # ORIGINAL convert_detailed template
                    template = f"""Create a comprehensive prompt about {topic}.

Format Guidelines:
- Detailed task explanation
- Do not use afterrisks
- Specific requirements and constraints
- Step-by-step guidance
- Clear examples
- Structured sections

Structure:
Task: [Comprehensive task description]

Requirements:
1. [First requirement with explanation]
2. [Second requirement with explanation]
3. [Third requirement with explanation]
[Continue with all necessary requirements]

Steps:
1. [First step with guidance]
2. [Second step with guidance]
3. [Third step with guidance]
[Continue with all necessary steps]

Examples:
1. Example Scenario: [Specific example]
   Input: [Sample input]
   Output: [Expected output]
2. [Additional example if needed]

Output Format: [Specific format requirements]

Structure Guidelines:
- Clear section headers
- Multiple related examples
- Step-by-step instructions where relevant
- Explicit success criteria
- Edge cases and exceptions

Original Text:
{topic}

Transform this text into a detailed prompt that leaves no room for ambiguity while maintaining clarity and purpose."""

                response = client.chat.completions.create(
                    model="chatgpt-4o-latest",
                    messages=[
                        {
                            "role": "system",
                            "content": "You are an expert at creating clear, effective prompts."
                        },
                        {
                            "role": "user",
                            "content": template
                        }
                    ],
                    temperature=0.3
                )

                result = {
                    'prompt': response.choices[0].message.content,
                    'status': 'success',
                    'metadata': {'mode': mode, 'original_text': topic}
                }

                if credit_result.get('credits_used'):
                    result['credits_used'] = credit_result['credits_used']
                    result['credits_remaining'] = credit_result.get('remaining')

                return jsonify(result)

            except Exception as e:
                return jsonify({'error': str(e), 'status': 'error'}), 500

        # Handle image modes
        if mode.startswith('image_'):
            result = process_image_variation(client, topic, mode)

            if credit_result.get('credits_used'):
                result['credits_used'] = credit_result['credits_used']
                result['credits_remaining'] = credit_result.get('remaining')

            return jsonify(result)

        # Handle template modes (only cot now)
        if mode in ['cot']:
            result = create_enhanced_rewrite(topic, tone, length, mode)

            if credit_result.get('credits_used'):
                result['credits_used'] = credit_result['credits_used']
                result['credits_remaining'] = credit_result.get('remaining')

            return jsonify(result)

        # Default processing
        prompt_data = create_enhanced_rewrite(topic, tone, length)
        response = client.chat.completions.create(
            model="chatgpt-4o-latest",
            messages=[
                {"role": "system", "content": prompt_data["system_message"]},
                {"role": "user", "content": prompt_data["user_message"]}
            ],
            temperature=0.7
        )

        result = {
            'prompt': response.choices[0].message.content,
            'status': 'success',
            'metadata': {
                'topic': topic,
                'tone': tone,
                'mode': mode
            }
        }

        if credit_result.get('credits_used'):
            result['credits_used'] = credit_result['credits_used']
            result['credits_remaining'] = credit_result.get('remaining')

        return jsonify(result)

    except Exception as e:
        logging.error(f"Error generating prompt: {str(e)}")
        return jsonify({
            'error': 'Failed to generate prompt',
            'details': str(e)
        }), 500

@app.route('/generate-image', methods=['POST'])
def generate_image_prompt():
    try:
        # ADD CREDIT CHECK
        credit_result = optional_credit_check('image_prompt')
        if not credit_result['success']:
            return jsonify({
                'error': credit_result['message'],
                'credits_required': get_feature_credits('image_prompt')
            }), 402

        data = request.get_json(force=True)
        image_url = data.get('image')

        universal_prompt = """Analyze this image with extreme thoroughness and precision. Examine every single visual element, no matter how minute. Study the image as if you need to recreate it perfectly from memory. Provide output in this exact format:

Description: [4-5 line comprehensive description capturing the complete scene, all subjects, actions, and significant visual elements in detail]

Primary Subject(s): [main subject(s) with detailed description - pose, body language, facial expressions, age estimation, gender, ethnicity if apparent, clothing brand/style/condition, accessories, jewelry, footwear, hair style/color, makeup, gestures, what they're doing/holding]

Secondary Elements: [people, animals, or objects in background/periphery with their positions, actions, and details]

Environment/Setting: [specific location type, indoor/outdoor, architectural style, room type, landscape features, weather conditions, season indicators, time of day evidence, geographical clues, cultural context]

Colors & Visual Palette: [dominant colors, accent colors, color harmony, saturation levels, color temperature (warm/cool), specific color names, color distribution across image]

Lighting Analysis: [light source type (natural/artificial), direction (front/back/side), intensity (harsh/soft), quality (diffused/direct), shadows (hard/soft), highlights, reflections, ambient lighting, contrast levels]

Materials & Textures: [fabric types, surface materials, texture quality (smooth/rough/glossy/matte), material condition (new/worn/damaged), patterns, weaves, finishes]

Style & Technique: [photography style, artistic medium, visual technique, filter effects, processing style, camera type indicators, lens characteristics, depth of field, bokeh quality]

Composition & Framing: [camera angle (high/low/eye level), perspective (wide/close-up/macro), framing (tight/loose), rule of thirds application, leading lines, symmetry/asymmetry, balance, focal points, negative space usage]

Technical Quality: [image resolution indicators, sharpness, noise levels, compression artifacts, dynamic range, exposure quality] --ar [width:height ratio] --v 5.2

Text & Graphics: [any visible text (exact words), fonts, signs, labels, logos, brand names, symbols, graphics, artwork, posters, screens, digital displays]

Spatial Relationships: [how objects relate to each other, size comparisons, distance relationships, layering (foreground/midground/background), overlap patterns, perspective cues]

Motion & Action: [any movement indicators, blur patterns, action sequences, dynamic elements, static vs moving elements]

Mood & Atmosphere: [emotional tone, energy level, ambiance, psychological impact, cultural mood, formality level, tension/relaxation]

Temporal Indicators: [time period clues, historical markers, technology visible, fashion era, architectural period, anachronisms]

Fine Details: [small background objects, wear patterns, aging signs, scratches/damage, reflections in surfaces, shadows of unseen objects, partial text, edge details, corner elements, pattern specifics, brand markings, serial numbers, dates, signatures]

Anomalies & Unique Features: [anything unusual, unexpected, hidden elements, visual tricks, easter eggs, inconsistencies, artistic choices, creative elements, surreal aspects]

Do not use afterrisks in the output and do not change directions of objects"""

        response = client.chat.completions.create(
            model="chatgpt-4o-latest",
            messages=[
                {
                    "role": "system",
                    "content": "Generate precise image analysis following the universal prompt format."
                },
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": universal_prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": image_url,
                                "detail": "high"
                            }
                        }
                    ]
                }
            ],
            max_tokens=500
        )

        result = {
            'prompt': response.choices[0].message.content,
            'status': 'success'
        }

        if credit_result.get('credits_used'):
            result['credits_used'] = credit_result['credits_used']
            result['credits_remaining'] = credit_result.get('remaining')

        return jsonify(result)

    except Exception as e:
        logging.error(f"Error: {str(e)}")
        return jsonify({'error': str(e), 'status': 'error'}), 500


@app.route('/generate-caption', methods=['POST'])
def generate_caption():
    try:
        # ADD CREDIT CHECK
        credit_result = optional_credit_check('image_caption')
        if not credit_result['success']:
            return jsonify({
                'error': credit_result['message'],
                'credits_required': get_feature_credits('image_caption')
            }), 402

        data = request.get_json(force=True)
        image_url = data.get('image')

        social_caption_prompt = """Analyze this image and generate platform-specific captions in the following format, do not use asterisks::

Instagram:
[Write an engaging, conversational caption with emojis]
.
.
.
#[relevant hashtags, maximum 15]

Facebook:
[Write a longer, more detailed description that tells a story and encourages engagement]

Twitter/X:
[Write a concise, catchy caption within 280 characters, include 2-3 relevant hashtags]

LinkedIn:
[Write a professional caption that provides business context or insight]
‚Üí [Add one key professional takeaway or insight]
---
#[3-4 relevant professional hashtags]"""

        response = client.chat.completions.create(
            model="chatgpt-4o-latest",
            messages=[
                {
                    "role": "system",
                    "content": "Generate engaging, platform-optimized social media captions."
                },
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": social_caption_prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": image_url,
                                "detail": "high"
                            }
                        }
                    ]
                }
            ],
            max_tokens=500
        )

        result = {
            'prompt': response.choices[0].message.content,
            'status': 'success'
        }

        if credit_result.get('credits_used'):
            result['credits_used'] = credit_result['credits_used']
            result['credits_remaining'] = credit_result.get('remaining')

        return jsonify(result)

    except Exception as e:
        logging.error(f"Error: {str(e)}")
        return jsonify({'error': str(e), 'status': 'error'}), 500

@app.route('/explain-meaning', methods=['POST'])
def explain_meaning():
    # ADD CREDIT CHECK
    credit_result = optional_credit_check('explain_meaning')
    if not credit_result['success']:
        return jsonify({
            'error': credit_result['message'],
            'credits_required': get_feature_credits('explain_meaning')
        }), 402

    data = request.get_json(force=True)
    text = data.get('text', '').strip()

    # ORIGINAL explain_meaning template
    template = f"""Definition:
[Concise one-line definition of the core concept]

Domain Meanings & Usage:
| [Domain1]: [Specific meaning in this domain]
  "[Example sentence showing usage]"

| [Domain2]: [Specific meaning in this domain]
  "[Example sentence showing usage]"

| [Domain3]: [Specific meaning in this domain]
  "[Example sentence showing usage]"

| [Domain4]: [Specific meaning in this domain]
  "[Example sentence showing usage]"

Related:
[3-4 closely related terms, comma-separated]"""

    response = client.chat.completions.create(
        model="chatgpt-4o-latest",
        messages=[
            {
                "role": "system",
                "content": "Generate concise, structured explanations following the exact template format. Include relevant domain-specific meanings and authentic usage examples."
            },
            {
                "role": "user",
                "content": f"Explain this term:\n{text}\n\nUse template:\n{template}"
            }
        ],
        temperature=0.3,
        max_tokens=400
    )

    result = {'explanation': response.choices[0].message.content}

    if credit_result.get('credits_used'):
        result['credits_used'] = credit_result['credits_used']
        result['credits_remaining'] = credit_result.get('remaining')

    return jsonify(result)

@app.route('/explain-story', methods=['POST'])
def explain_story():
    # ADD CREDIT CHECK
    credit_result = optional_credit_check('explain_story')
    if not credit_result['success']:
        return jsonify({
            'error': credit_result['message'],
            'credits_required': get_feature_credits('explain_story')
        }), 402

    data = request.get_json(force=True)
    text = data.get('text', '').strip()

    # ORIGINAL explain_story template
    template = f"""Core Concept:
[One-line explanation of what it is]

Story:
[3-4 sentences that naturally explain the concept through a relatable narrative]"""

    response = client.chat.completions.create(
        model="chatgpt-4o-latest",
        messages=[
            {"role": "system", "content": "Create a concise story that explains the concept naturally, without bullet points or sections."},
            {"role": "user", "content": f"Explain this through a story:\n{text}\n\nUse template:\n{template}"}
        ],
        temperature=0.3,
        max_tokens=400
    )

    result = {'explanation': response.choices[0].message.content}

    if credit_result.get('credits_used'):
        result['credits_used'] = credit_result['credits_used']
        result['credits_remaining'] = credit_result.get('remaining')

    return jsonify(result)

@app.route('/explain-eli5', methods=['POST'])
def explain_eli5():
    # ADD CREDIT CHECK
    credit_result = optional_credit_check('explain_eli5')
    if not credit_result['success']:
        return jsonify({
            'error': credit_result['message'],
            'credits_required': get_feature_credits('explain_eli5')
        }), 402

    data = request.get_json(force=True)
    text = data.get('text', '').strip()

    # ORIGINAL explain_eli5 approach
    response = client.chat.completions.create(
        model="chatgpt-4o-latest",
        messages=[
            {"role": "system", "content": "Explain concepts using simple words, fun analogies, and examples that a 5-year-old would understand. Use short sentences and friendly language."},
            {"role": "user", "content": f"Explain this to a 5-year-old:\n{text}"}
        ],
        temperature=0.3,
        max_tokens=400
    )

    result = {'explanation': response.choices[0].message.content}

    if credit_result.get('credits_used'):
        result['credits_used'] = credit_result['credits_used']
        result['credits_remaining'] = credit_result.get('remaining')

    return jsonify(result)

@app.route('/convert-concise', methods=['POST'])
def convert_concise():
    """Convert input to a concise prompt using specific strategies."""
    try:
        # ADD CREDIT CHECK
        credit_result = optional_credit_check('convert_concise')
        if not credit_result['success']:
            return jsonify({
                'error': credit_result['message'],
                'credits_required': get_feature_credits('convert_concise')
            }), 402

        data = request.get_json(force=True)
        topic = data.get('topic', '').strip()

        # ORIGINAL convert_concise template
        template = f"""You will convert the following text into a clear, concise prompt.

Format Guidelines:
- One clear task statement
- Maximum 2-3 essential requirements
- No additional explanations or examples
- Keep total length under 5 lines
- Maintain professional tone

Structure:
Task: [One clear sentence]
Requirements:
1. [First key requirement]
2. [Second key requirement]
3. [Third key requirement - if absolutely necessary]

Format Requirements:
- Maximum 3 sentences
- No bullet points
- No examples unless critical
- Focus on core request

Original Text:
{topic}

Enhance this text into a clear, focused prompt that could be given to an AI system."""

        response = client.chat.completions.create(
            model="chatgpt-4o-latest",
            messages=[
                {
                    "role": "system",
                    "content": "You are an expert at converting text into clear, concise prompts."
                },
                {
                    "role": "user",
                    "content": template
                }
            ],
            temperature=0.3
        )

        result = {
            'prompt': response.choices[0].message.content,
            'status': 'success',
            'metadata': {
                'mode': 'concise',
                'original_text': topic
            }
        }

        if credit_result.get('credits_used'):
            result['credits_used'] = credit_result['credits_used']
            result['credits_remaining'] = credit_result.get('remaining')

        return jsonify(result)

    except Exception as e:
        return jsonify({'error': str(e), 'status': 'error'}), 500

@app.route('/convert-balanced', methods=['POST'])
def convert_balanced():
    """Convert input to a balanced prompt with moderate detail."""
    try:
        # ADD CREDIT CHECK
        credit_result = optional_credit_check('convert_balanced')
        if not credit_result['success']:
            return jsonify({
                'error': credit_result['message'],
                'credits_required': get_feature_credits('convert_balanced')
            }), 402

        data = request.get_json(force=True)
        topic = data.get('topic', '').strip()

        # ORIGINAL convert_balanced template
        template = f"""You will help convert the following text into a balanced, well-structured prompt.

Format Guidelines:
- Clear task definition
- Do not use afterrisks
- 4-5 key requirements
- One brief example
- Keep total length under 10 lines

Structure:
Task: [Clear task description]

Requirements:
1. [First requirement]
2. [Second requirement]
3. [Third requirement]
4. [Fourth requirement]
5. [Optional fifth requirement]

Example:
Scenario: [Brief example scenario]
Input: [Sample input]
Output: [Expected output]

Output Format: [Desired format]

Original Text:
{topic}

Transform this text into a balanced prompt that provides clear direction while maintaining essential context."""

        response = client.chat.completions.create(
            model="chatgpt-4o-latest",
            messages=[
                {
                    "role": "system",
                    "content": "You are an expert at creating well-balanced prompts that provide the right level of detail."
                },
                {
                    "role": "user",
                    "content": template
                }
            ],
            temperature=0.4
        )

        result = {
            'prompt': response.choices[0].message.content,
            'status': 'success',
            'metadata': {
                'mode': 'balanced',
                'original_text': topic
            }
        }

        if credit_result.get('credits_used'):
            result['credits_used'] = credit_result['credits_used']
            result['credits_remaining'] = credit_result.get('remaining')

        return jsonify(result)

    except Exception as e:
        return jsonify({'error': str(e), 'status': 'error'}), 500

@app.route('/convert-detailed', methods=['POST'])
def convert_detailed():
    """Convert input to a detailed prompt with comprehensive specifications."""
    try:
        # ADD CREDIT CHECK
        credit_result = optional_credit_check('convert_detailed')
        if not credit_result['success']:
            return jsonify({
                'error': credit_result['message'],
                'credits_required': get_feature_credits('convert_detailed')
            }), 402

        data = request.get_json(force=True)
        topic = data.get('topic', '').strip()

        # ORIGINAL convert_detailed template
        template = f"""Create a comprehensive prompt about {topic}.

Format Guidelines:
- Detailed task explanation
- Do not use afterrisks
- Specific requirements and constraints
- Step-by-step guidance
- Clear examples
- Structured sections

Structure:
Task: [Comprehensive task description]

Requirements:
1. [First requirement with explanation]
2. [Second requirement with explanation]
3. [Third requirement with explanation]
[Continue with all necessary requirements]

Steps:
1. [First step with guidance]
2. [Second step with guidance]
3. [Third step with guidance]
[Continue with all necessary steps]

Examples:
1. Example Scenario: [Specific example]
   Input: [Sample input]
   Output: [Expected output]
2. [Additional example if needed]

Output Format: [Specific format requirements]

Structure Guidelines:
- Clear section headers
- Multiple related examples
- Step-by-step instructions where relevant
- Explicit success criteria
- Edge cases and exceptions

Original Text:
{topic}

Transform this text into a detailed prompt that leaves no room for ambiguity while maintaining clarity and purpose."""

        response = client.chat.completions.create(
            model="chatgpt-4o-latest",
            messages=[
                {
                    "role": "system",
                    "content": "You are an expert at creating detailed, comprehensive prompts that capture all necessary specifications, and dont use # or * in your output"
                },
                {
                    "role": "user",
                    "content": template
                }
            ],
            temperature=0.5
        )

        result = {
            'prompt': response.choices[0].message.content,
            'status': 'success',
            'metadata': {
                'mode': 'detailed',
                'original_text': topic
            }
        }

        if credit_result.get('credits_used'):
            result['credits_used'] = credit_result['credits_used']
            result['credits_remaining'] = credit_result.get('remaining')

        return jsonify(result)

    except Exception as e:
        return jsonify({'error': str(e), 'status': 'error'}), 500

# KEEP ALL YOUR EXISTING SMART FOLLOWUPS, ENHANCEMENTS, ACTIONS, AND PERSONA ENDPOINTS...

# Smart Follow-ups helper functions
def get_focus_for_session(conversation):
    """Simple rotation based on conversation hash - no storage needed"""

    focus_options = [
        "Ask about practical next steps and what to try first",
        "Ask about different ways to approach the same thing",
        "Ask about potential problems or things that might go wrong",
        "Ask about how this would work in real situations",
        "Ask about things that might be missing or overlooked",
        "Ask about what resources or help would be needed",
        "Ask about how this connects with other things they're doing",
        "Ask about how to know if it's working or successful"
    ]

    # Use conversation content to deterministically pick focus (no randomness)
    focus_index = abs(hash(conversation[:200])) % len(focus_options)
    return focus_options[focus_index]

def extract_key_terms(conversation_snippet):
    """Extract key terms from conversation for better fallback questions"""
    try:
        # Simple keyword extraction - look for capitalized words, technical terms, etc.
        import re

        # Find potential key terms (capitalized words, technical patterns)
        patterns = [
            r'\b[A-Z][a-z]+(?:\s+[A-Z][a-z]+)*\b',  # Proper nouns
            r'\b(?:API|SDK|AI|ML|UI|UX|SaaS|MVP|POC)\b',  # Common tech acronyms
            r'\b\w+(?:\.js|\.py|\.com|\.org)\b',  # File extensions, domains
            r'\b(?:React|Vue|Angular|Python|JavaScript|Node|Docker|AWS|Azure)\b'  # Common tech terms
        ]

        key_terms = []
        for pattern in patterns:
            matches = re.findall(pattern, conversation_snippet, re.IGNORECASE)
            key_terms.extend(matches)

        # Remove duplicates and return top 3
        unique_terms = list(dict.fromkeys(key_terms))
        return unique_terms[:3]

    except Exception:
        return []

def build_enhanced_prompt(conversation, focus_type):
    """Build enhanced prompt with focus rotation and specificity requirements"""

    return f"""
You're helping someone continue their conversation by suggesting 5 things they might want to explore next.

CONVERSATION:
{conversation[:1800]}

Generate 5 follow-up questions that feel natural and helpful. Mix of approaches:
- 2 practical/simple questions (what someone curious would ask)
- 2 slightly deeper questions (but still conversational)
- 1 action-oriented question (what to DO next - asking for practical steps or advice)

Guidelines:
‚úì Reference specific things mentioned in the conversation
‚úì Keep questions conversational and approachable
‚úì Ask what a curious friend might genuinely want to know
‚úì Avoid business jargon and academic language
‚úì {focus_type}

Question Style Examples:
- "Have you tried [specific approach mentioned]?"
- "What happens if [specific scenario]?"
- "Could you walk through how [specific part] works?"
- "What's been your biggest challenge with [specific thing]?"
- "Have you considered starting with [simpler version]?"

For action questions specifically - ask for practical steps:
- "What would you recommend trying first with [specific thing]?"
- "How should I get started with [specific approach]?"
- "What's the simplest way to test [specific idea]?"
- "What tools would work best for [specific task]?"

Make questions feel like natural conversation flow - what would you genuinely want to know next?

JSON format:
{{
    "questions": [
        {{"text": "Simple, curious question?", "type": "curious"}},
        {{"text": "Another practical question?", "type": "practical"}},
        {{"text": "Slightly deeper but still conversational question?", "type": "deeper"}},
        {{"text": "Another conversational exploration question?", "type": "exploration"}},
        {{"text": "What should I do/try next with [specific thing]?", "type": "action"}}
    ],
    "analysis": "What would help move this conversation forward"
}}"""

@app.route('/smart-followups', methods=['POST'])
def smart_followups():
    """Enhanced smart follow-up questions with dynamic generation"""
    try:
        logging.info("=== Enhanced smart followups request started ===")

        # ADD CREDIT CHECK
        credit_result = optional_credit_check('smart_followups')
        if not credit_result['success']:
            return jsonify({
                'error': credit_result['message'],
                'credits_required': get_feature_credits('smart_followups')
            }), 402

        # Parse request
        data = request.get_json(force=True)
        conversation = data.get('conversation', '').strip()
        platform = data.get('platform', 'unknown')

        logging.info(f"Conversation length: {len(conversation)}, Platform: {platform}")

        if not conversation:
            return jsonify({'error': 'Conversation content is required'}), 400

        # Get dynamic focus for this conversation
        focus_type = get_focus_for_session(conversation)
        logging.info(f"Selected focus: {focus_type}")

        # Build enhanced prompt with focus and specificity requirements
        analysis_prompt = build_enhanced_prompt(conversation, focus_type)

        # Use reliable models with proper error handling
        models_to_try = [
            {
                "name": "chatgpt-4o-latest",  # Start with most reliable model
                "params": {
                    "temperature": 0.3,  # Increased from 0.1 for more variation
                    "max_tokens": 1000
                }
            },
            {
                "name": "gpt-3.5-turbo",
                "params": {
                    "temperature": 0.3,
                    "max_tokens": 800
                }
            }
        ]

        response = None
        model_used = None

        # Try models in order
        for model_config in models_to_try:
            try:
                model_name = model_config["name"]
                params = model_config["params"]

                logging.info(f"Trying model: {model_name}")

                response = client.chat.completions.create(
                    model=model_name,
                    messages=[{"role": "user", "content": analysis_prompt}],
                    **params
                )

                model_used = model_name
                logging.info(f"Successfully used model: {model_name}")
                break

            except Exception as e:
                error_msg = str(e)
                logging.warning(f"Model {model_name} failed: {error_msg}")
                continue

        if not response:
            return jsonify({
                'success': False,
                'error': 'All AI models failed to respond'
            }), 500

        # Parse response
        ai_response = response.choices[0].message.content.strip()
        logging.info(f"AI Response length: {len(ai_response)}")

        try:
            # Clean and extract JSON
            clean_response = ai_response

            # Remove markdown code blocks
            if "```json" in clean_response:
                clean_response = clean_response.split("```json")[1].split("```")[0]
            elif "```" in clean_response:
                parts = clean_response.split("```")
                if len(parts) >= 3:
                    clean_response = parts[1]

            # Find JSON boundaries
            start_idx = clean_response.find('{')
            if start_idx == -1:
                raise json.JSONDecodeError("No JSON found", clean_response, 0)

            # Find matching closing brace
            brace_count = 0
            end_idx = -1
            for i in range(start_idx, len(clean_response)):
                if clean_response[i] == '{':
                    brace_count += 1
                elif clean_response[i] == '}':
                    brace_count -= 1
                    if brace_count == 0:
                        end_idx = i + 1
                        break

            if end_idx == -1:
                raise json.JSONDecodeError("Incomplete JSON", clean_response, start_idx)

            json_str = clean_response[start_idx:end_idx]
            parsed_response = json.loads(json_str)

            # Validate structure
            questions = parsed_response.get('questions', [])
            if not isinstance(questions, list) or len(questions) == 0:
                raise ValueError("No valid questions found")

            # Process and validate questions
            validated_questions = []
            for i, q in enumerate(questions[:5]):  # Changed from 3 to 5
                if isinstance(q, dict) and 'text' in q:
                    text = q['text'].strip()
                    if text and len(text) > 15:  # Minimum question length
                        if not text.endswith('?'):
                            text += '?'
                        validated_questions.append({
                            "text": text,
                            "type": q.get('type', 'strategic')
                        })

            if len(validated_questions) == 0:
                raise ValueError("No valid questions after processing")

            result = {
                'success': True,
                'questions': validated_questions,
                'analysis': parsed_response.get('analysis', 'Strategic insights generated'),
                'platform': platform,
                'model': model_used,
                'focus_used': focus_type,
                'enhanced': True
            }

            if credit_result.get('credits_used'):
                result['credits_used'] = credit_result['credits_used']
                result['credits_remaining'] = credit_result.get('remaining')

            return jsonify(result)

        except (json.JSONDecodeError, ValueError) as e:
            logging.error(f"JSON parsing failed: {str(e)}")

            # Enhanced fallback extraction with conversation context
            questions = extract_questions_from_text(ai_response)

            result = {
                'success': True,
                'questions': questions,
                'analysis': 'Strategic questions generated to enhance discussion',
                'platform': platform,
                'model': model_used,
                'focus_used': focus_type,
                'enhanced': True,
                'fallback': True
            }

            if credit_result.get('credits_used'):
                result['credits_used'] = credit_result['credits_used']
                result['credits_remaining'] = credit_result.get('remaining')

            return jsonify(result)

    except Exception as e:
        error_msg = str(e)
        error_type = type(e).__name__

        logging.error(f"=== Enhanced smart followups error ===")
        logging.error(f"Error type: {error_type}")
        logging.error(f"Error message: {error_msg}")

        return jsonify({
            'success': False,
            'error': 'Failed to generate follow-up questions',
            'details': error_msg[:200],
            'error_type': error_type
        }), 500

@app.route('/smart-enhancements', methods=['POST'])
def smart_enhancements():
    """Generate smart enhancement suggestions based on selected text"""
    try:
        logging.info("=== Smart enhancements request started ===")

        # ADD CREDIT CHECK
        credit_result = optional_credit_check('smart_enhancements')
        if not credit_result['success']:
            return jsonify({
                'error': credit_result['message'],
                'credits_required': get_feature_credits('smart_enhancements')
            }), 402

        # Parse request
        data = request.get_json(force=True)
        selected_text = data.get('text', '').strip()

        logging.info(f"Selected text length: {len(selected_text)}")

        if not selected_text:
            return jsonify({'error': 'Selected text is required'}), 400

        # Enhanced prompt that generates enhancement instructions WITHOUT including original text
        enhancement_prompt = f"""
You are an expert content strategist with deep understanding across all domains. Analyze the highlighted text and create 4 precise enhancement instructions.

HIGHLIGHTED TEXT TO ANALYZE:
{selected_text}

ANALYSIS FRAMEWORK:
1. Content Type & Purpose: What is this and what's it trying to achieve?
2. Current Quality Level: Strengths and improvement opportunities
3. Context Clues: Infer the user's likely goals and constraints
4. Enhancement Vectors: Identify the 4 most impactful improvement areas

ENHANCEMENT INSTRUCTION REQUIREMENTS:
- Each must be a clear, actionable instruction
- Focus on specific improvements, not vague suggestions
- Be immediately copy-pasteable as a prompt
- Do NOT include the original text in the instruction
- Start with action verbs like "Enhance", "Improve", "Add", "Refine"

INSTRUCTION FORMULA: "[Action verb] this [content type] by [specific improvement instructions]"

JSON FORMAT:
{{
    "content_analysis": {{
        "type": "What type of content this is",
        "purpose": "What it's trying to achieve",
        "current_quality": "Brief assessment",
        "improvement_potential": "Key areas for enhancement"
    }},
    "enhancement_prompts": [
        {{
            "prompt": "Clear enhancement instruction WITHOUT original text",
            "focus_area": "Primary improvement focus",
            "expected_impact": "What this will improve",
            "priority": "high/medium/low"
        }},
        {{
            "prompt": "Second enhancement instruction focusing on different aspect",
            "focus_area": "Different improvement aspect",
            "expected_impact": "Different improvement outcome",
            "priority": "high/medium/low"
        }},
        {{
            "prompt": "Third enhancement instruction with another angle",
            "focus_area": "Another improvement angle",
            "expected_impact": "Another improvement outcome",
            "priority": "high/medium/low"
        }},
        {{
            "prompt": "Fourth enhancement instruction with final dimension",
            "focus_area": "Final improvement dimension",
            "expected_impact": "Final improvement outcome",
            "priority": "high/medium/low"
        }}
    ]
}}

IMPORTANT: Do NOT include the original text in any of the enhancement prompts. Only provide the improvement instructions."""

        # Use GPT-4.1 as primary model with smart fallbacks
        models_to_try = [
            {
                "name": "chatgpt-4o-latest",  # Latest GPT-4.1
                "params": {
                    "temperature": 0.1,    # Very focused for precise suggestions
                    "max_tokens": 2500,    # Leverage the large output capacity
                    "top_p": 0.95,        # Slight creativity for varied suggestions
                }
            },
            {
                "name": "gpt-4o",  # Strong fallback
                "params": {
                    "temperature": 0.2,
                    "max_tokens": 2000
                }
            }
        ]

        response = None
        model_used = None

        for model_config in models_to_try:
            try:
                model_name = model_config["name"]
                params = model_config["params"]

                logging.info(f"Attempting smart enhancements with {model_name}")

                response = client.chat.completions.create(
                    model=model_name,
                    messages=[
                        {
                            "role": "system",
                            "content": "You are a world-class content strategist and prompt engineer. Your expertise spans writing, coding, business strategy, creative work, and technical documentation. You create enhancement instructions that deliver transformative improvements. Never include the original text in your enhancement instructions."
                        },
                        {
                            "role": "user",
                            "content": enhancement_prompt
                        }
                    ],
                    **params
                )

                model_used = model_name
                logging.info(f"‚úÖ Smart enhancements successful with {model_name}")
                break

            except Exception as e:
                error_msg = str(e)
                logging.warning(f"‚ùå {model_name} failed: {error_msg}")
                continue

        if not response:
            return jsonify({
                'success': False,
                'error': 'All models failed to respond'
            }), 500

        # Enhanced response processing
        ai_response = response.choices[0].message.content.strip()
        logging.info(f"Generated {len(ai_response)} chars with {model_used}")

        try:
            # Parse JSON with enhanced quality
            parsed_data = parse_json_response_enhanced(ai_response)

            # Extract and validate enhancement prompts
            enhancement_prompts = parsed_data.get('enhancement_prompts', [])
            content_analysis = parsed_data.get('content_analysis', {})

            # Ensure high-quality prompts
            validated_prompts = []
            for prompt_data in enhancement_prompts:
                if isinstance(prompt_data, dict) and 'prompt' in prompt_data:
                    prompt_text = prompt_data['prompt'].strip()
                    if len(prompt_text) > 20:
                        validated_prompts.append({
                            "prompt": prompt_text,
                            "focus_area": prompt_data.get('focus_area', 'improvement'),
                            "expected_impact": prompt_data.get('expected_impact', 'Enhanced quality'),
                            "priority": prompt_data.get('priority', 'medium')
                        })

            if len(validated_prompts) == 0:
                raise ValueError("No valid enhancement prompts generated")

            result = {
                'success': True,
                'content_analysis': content_analysis,
                'enhancement_prompts': validated_prompts,
                'model_used': model_used,
                'original_length': len(selected_text),
                'gpt_4_1_used': "gpt-4.1" in model_used
            }

            if credit_result.get('credits_used'):
                result['credits_used'] = credit_result['credits_used']
                result['credits_remaining'] = credit_result.get('remaining')

            return jsonify(result)

        except Exception as e:
            logging.error(f"Response processing failed: {str(e)}")

            # Create premium fallback prompts WITHOUT original text
            fallback_prompts = create_gpt41_fallback_prompts_clean(selected_text)

            result = {
                'success': True,
                'content_analysis': {"type": "Content analyzed", "purpose": "Enhancement ready"},
                'enhancement_prompts': fallback_prompts,
                'model_used': model_used,
                'fallback': True
            }

            if credit_result.get('credits_used'):
                result['credits_used'] = credit_result['credits_used']
                result['credits_remaining'] = credit_result.get('remaining')

            return jsonify(result)

    except Exception as e:
        error_msg = str(e)
        error_type = type(e).__name__

        logging.error(f"=== Smart enhancements error ===")
        logging.error(f"Error type: {error_type}")
        logging.error(f"Error message: {error_msg}")

        return jsonify({
            'success': False,
            'error': 'Failed to generate enhancement suggestions',
            'details': error_msg[:200],
            'error_type': error_type
        }), 500

# Smart Actions helper functions
def build_action_prompt(conversation, platform):
    """Build action-focused prompt for generating actionable follow-up prompts"""

    return f"""
You're helping someone continue their AI conversation by suggesting 3 action-oriented follow-up prompts they can use.

CONVERSATION:
{conversation[:1800]}

Generate 3 follow-up prompts that are:
- Action-oriented and practical (focus on "what to do" rather than "what to know")
- Context-aware and specific to their conversation
- Ready to copy-paste back into the AI chat
- 2-liner prompts that get specific, actionable guidance

Think about what the person would naturally want to DO next based on this conversation:
- If they're learning ‚Üí How to apply/practice it
- If they're problem-solving ‚Üí Next steps to try
- If they're planning ‚Üí How to implement/start
- If they're stuck ‚Üí Specific approaches to attempt

Guidelines:
‚úì Reference specific things mentioned in the conversation
‚úì Focus on implementation and application
‚úì Make prompts specific enough to get actionable responses
‚úì Avoid generic questions - be contextually relevant
‚úì Each prompt should be self-contained and ready to use

JSON format:
{{
    "action_prompts": [
        {{
            "prompt": "Context-specific action-oriented prompt for the AI",
            "focus": "implementation/application/practice",
            "context": "brief description of what this targets"
        }},
        {{
            "prompt": "Second practical follow-up prompt",
            "focus": "planning/strategy/approach",
            "context": "what this helps with"
        }},
        {{
            "prompt": "Third actionable prompt for next steps",
            "focus": "execution/practice/testing",
            "context": "practical outcome"
        }}
    ],
    "analysis": "Brief explanation of how these prompts help take action on the conversation"
}}"""

def extract_action_prompts_from_text(text, conversation=""):
    """Fallback extraction for action prompts when JSON parsing fails"""
    prompts = []
    lines = text.split('\n')

    for line in lines:
        line = line.strip()
        # Look for action-oriented prompt language
        if any(starter in line.lower() for starter in ['help me', 'show me', 'create', 'give me', 'walk me through', 'build', 'plan', 'strategy', 'implement']):
            if len(line) > 40 and len(line) < 500 and '?' in line:
                clean_prompt = line

                # Remove common prefixes
                prefixes = ['"prompt":', 'prompt:', '"', "'", '-', '‚Ä¢', '*', '1.', '2.', '3.']
                for prefix in prefixes:
                    if clean_prompt.startswith(prefix):
                        clean_prompt = clean_prompt[len(prefix):].strip()

                clean_prompt = clean_prompt.rstrip('",\'"').strip()

                if clean_prompt and len(clean_prompt) > 35:
                    prompts.append({
                        "prompt": clean_prompt,
                        "focus": "practical",
                        "context": "actionable guidance"
                    })

    # If no prompts extracted, provide high-quality context-aware defaults
    if len(prompts) == 0:
        prompts = [
            {"prompt": "Help me create an action plan based on our discussion. What are the specific next steps I should take?", "focus": "planning", "context": "next steps"},
            {"prompt": "Give me 3 practical ways to apply what we've discussed. Include specific examples for my situation.", "focus": "application", "context": "practical use"},
            {"prompt": "Walk me through how to get started with this approach. What should I do first and why?", "focus": "getting started", "context": "initial steps"}
        ]

    return prompts[:3]

@app.route('/smart-actions', methods=['POST'])
def smart_actions():
    """Generate smart action-oriented follow-up prompts based on conversation context"""
    try:
        logging.info("=== Smart actions request started ===")

        # ADD CREDIT CHECK
        credit_result = optional_credit_check('smart_actions')
        if not credit_result['success']:
            return jsonify({
                'error': credit_result['message'],
                'credits_required': get_feature_credits('smart_actions')
            }), 402

        # Parse request
        data = request.get_json(force=True)
        conversation = data.get('conversation', '').strip()
        platform = data.get('platform', 'unknown')

        logging.info(f"Conversation length: {len(conversation)}, Platform: {platform}")

        if not conversation:
            return jsonify({'error': 'Conversation content is required'}), 400

        # Build action-focused prompt
        action_prompt = build_action_prompt(conversation, platform)

        # Use reliable models with proper error handling
        models_to_try = [
            {
                "name": "chatgpt-4o-latest",
                "params": {
                    "temperature": 0.3,
                    "max_tokens": 800
                }
            },
            {
                "name": "gpt-3.5-turbo",
                "params": {
                    "temperature": 0.3,
                    "max_tokens": 600
                }
            }
        ]

        response = None
        model_used = None

        # Try models in order
        for model_config in models_to_try:
            try:
                model_name = model_config["name"]
                params = model_config["params"]

                logging.info(f"Trying model: {model_name}")

                response = client.chat.completions.create(
                    model=model_name,
                    messages=[{"role": "user", "content": action_prompt}],
                    **params
                )

                model_used = model_name
                logging.info(f"Successfully used model: {model_name}")
                break

            except Exception as e:
                error_msg = str(e)
                logging.warning(f"Model {model_name} failed: {error_msg}")
                continue

        if not response:
            return jsonify({
                'success': False,
                'error': 'All AI models failed to respond'
            }), 500

        # Parse response
        ai_response = response.choices[0].message.content.strip()
        logging.info(f"AI Response length: {len(ai_response)}")

        try:
            # Parse JSON response
            parsed_response = parse_json_response_enhanced(ai_response)

            # Extract and validate action prompts
            action_prompts = parsed_response.get('action_prompts', [])

            if not isinstance(action_prompts, list) or len(action_prompts) == 0:
                raise ValueError("No valid action prompts found")

            # Process and validate prompts
            validated_prompts = []
            for prompt_item in action_prompts[:3]:  # Limit to 3 prompts
                if isinstance(prompt_item, dict) and 'prompt' in prompt_item:
                    prompt_text = prompt_item['prompt'].strip()
                    if prompt_text and len(prompt_text) > 30:
                        validated_prompts.append({
                            "prompt": prompt_text,
                            "focus": prompt_item.get('focus', 'practical'),
                            "context": prompt_item.get('context', 'general')
                        })

            if len(validated_prompts) == 0:
                raise ValueError("No valid prompts after processing")

            result = {
                'success': True,
                'action_prompts': validated_prompts,
                'analysis': parsed_response.get('analysis', 'Action-oriented prompts generated'),
                'platform': platform,
                'model': model_used
            }

            if credit_result.get('credits_used'):
                result['credits_used'] = credit_result['credits_used']
                result['credits_remaining'] = credit_result.get('remaining')

            return jsonify(result)

        except (json.JSONDecodeError, ValueError) as e:
            logging.error(f"JSON parsing failed: {str(e)}")

            # Fallback extraction
            action_prompts = extract_action_prompts_from_text(ai_response, conversation)

            result = {
                'success': True,
                'action_prompts': action_prompts,
                'analysis': 'Action-oriented prompts generated',
                'platform': platform,
                'model': model_used,
                'fallback': True
            }

            if credit_result.get('credits_used'):
                result['credits_used'] = credit_result['credits_used']
                result['credits_remaining'] = credit_result.get('remaining')

            return jsonify(result)

    except Exception as e:
        error_msg = str(e)
        error_type = type(e).__name__

        logging.error(f"=== Smart actions error ===")
        logging.error(f"Error type: {error_type}")
        logging.error(f"Error message: {error_msg}")

        return jsonify({
            'success': False,
            'error': 'Failed to generate action prompts',
            'details': error_msg[:200],
            'error_type': error_type
        }), 500

@app.route('/auto-suggestion', methods=['POST'])
def auto_suggestion():
    """Generate single action suggestion for auto-complete"""
    try:
        # ADD CREDIT CHECK - 3 credits for auto suggestion
        credit_result = optional_credit_check('auto_suggestion')
        if not credit_result['success']:
            return jsonify({
                'error': credit_result['message'],
                'credits_required': get_feature_credits('auto_suggestion')
            }), 402

        data = request.get_json(force=True)
        conversation = data.get('conversation', '').strip()
        platform = data.get('platform', 'unknown')

        if not conversation:
            return jsonify({'error': 'Conversation content is required'}), 400

        print(f"ü§ñ Generating auto-suggestion for {platform}")

        # Build focused prompt for single suggestion
        suggestion_prompt = f"""
You are an AI assistant that provides the next logical action step after an AI conversation.

Last 2 conversation turns:
{conversation[-1500:]}

Generate ONE concise action-oriented suggestion (max 80 characters) that the user would logically want to ask next.

Rules:
- Focus on immediate next steps or follow-up actions
- Make it practical and specific to the conversation
- Keep it under 80 characters
- Write as a direct prompt/question the user would ask
- Don't explain or add context, just give the suggestion

Examples of good suggestions:
- "Can you walk me through the implementation steps?"
- "What are the potential risks I should consider?"
- "How would I get started with this approach?"
- "Show me a practical example of this in action"

Return only the suggestion text, nothing else.
"""

        response = client.chat.completions.create(
            model="chatgpt-4o-latest",
            messages=[
                {
                    "role": "system",
                    "content": "You are an expert at generating concise, actionable follow-up suggestions. Always respond with just the suggestion text, no additional formatting or explanation."
                },
                {
                    "role": "user",
                    "content": suggestion_prompt
                }
            ],
            temperature=0.3,
            max_tokens=100
        )

        suggestion_text = response.choices[0].message.content.strip()

        # Clean up the suggestion
        suggestion_text = suggestion_text.strip('"').strip("'").strip()

        # Ensure it ends with ? if it's a question
        if not suggestion_text.endswith('?') and any(word in suggestion_text.lower() for word in ['how', 'what', 'where', 'when', 'why', 'can you', 'could you', 'would you']):
            suggestion_text += '?'

        # Ensure it's not too long
        if len(suggestion_text) > 80:
            suggestion_text = suggestion_text[:77] + '...'

        result = {
            'success': True,
            'suggestion': suggestion_text,
            'platform': platform,
            'conversation_length': len(conversation)
        }

        if credit_result.get('credits_used'):
            result['credits_used'] = credit_result['credits_used']
            result['credits_remaining'] = credit_result.get('remaining')

        print(f"‚úÖ Auto-suggestion generated: {suggestion_text}")
        return jsonify(result)

    except Exception as e:
        print(f"‚ùå Auto-suggestion error: {e}")
        return jsonify({
            'error': 'Failed to generate suggestion',
            'details': str(e)
        }), 500

# Persona generation functions
def generate_ai_persona_analysis(keyword):
    """Use AI to analyze the role and generate persona components"""

    analysis_prompt = f"""Analyze the role "{keyword}" and provide structured information.

Role to analyze: {keyword}

Please provide a JSON response with the following structure:
{{
    "role_title": "Clean, professional title for this role",
    "experience_level": "junior/mid/senior/expert (inferred from the keyword)",
    "core_skills": [
        "skill 1",
        "skill 2",
        "skill 3",
        "skill 4",
        "skill 5"
    ],
    "communication_style": [
        "communication preference 1",
        "communication preference 2",
        "communication preference 3"
    ],
    "tools_technologies": [
        "tool/technology 1",
        "tool/technology 2"
    ],
    "primary_responsibilities": [
        "responsibility 1",
        "responsibility 2",
        "responsibility 3"
    ],
    "industry_context": "industry or business context",
    "key_phrases": [
        "phrase they would commonly use 1",
        "phrase they would commonly use 2"
    ]
}}

Focus on being specific and practical. If the role includes level indicators (senior, junior, lead, etc.), reflect that in experience_level and adjust skills accordingly."""

    try:
        response = client.chat.completions.create(
            model="chatgpt-4o-latest",
            messages=[
                {
                    "role": "system",
                    "content": "You are an expert HR analyst and role researcher. Provide accurate, practical information about professional roles. Always respond with valid JSON only."
                },
                {
                    "role": "user",
                    "content": analysis_prompt
                }
            ],
            temperature=0.3,
            max_tokens=1000
        )

        ai_response = response.choices[0].message.content.strip()

        # Clean the response - remove markdown code blocks if present
        if "```json" in ai_response:
            ai_response = ai_response.split("```json")[1].split("```")[0]
        elif "```" in ai_response:
            ai_response = ai_response.split("```")[1].split("```")[0]

        # Parse JSON response
        try:
            analysis_data = json.loads(ai_response)
            return analysis_data
        except json.JSONDecodeError as e:
            logging.error(f"JSON parsing failed: {str(e)}")
            logging.error(f"AI Response: {ai_response}")
            return None

    except Exception as e:
        logging.error(f"AI analysis failed: {str(e)}")
        return None

def build_persona_from_ai_analysis(analysis_data, keyword):
    """Build persona template from AI analysis data"""

    if not analysis_data:
        # Fallback if AI analysis fails
        return f"""You are a {keyword} with professional expertise in your field.

Core Competencies:
‚Ä¢ Professional knowledge in {keyword} domain
‚Ä¢ Problem-solving and analytical thinking
‚Ä¢ Communication and collaboration skills
‚Ä¢ Continuous learning and adaptation

Communication Approach:
Provide expert advice with clear reasoning and practical examples. Focus on actionable solutions and best practices.

Response Guidelines:
‚Ä¢ Acknowledge the user's specific question
‚Ä¢ Provide professional-level insights
‚Ä¢ Include practical examples and recommendations
‚Ä¢ Ask follow-up questions to ensure clarity

Remember: You're a knowledgeable {keyword} ready to help solve real problems with your expertise."""

    # Extract data with fallbacks
    role_title = analysis_data.get('role_title', keyword)
    experience_level = analysis_data.get('experience_level', 'professional')
    core_skills = analysis_data.get('core_skills', [])
    communication_style = analysis_data.get('communication_style', [])
    tools_technologies = analysis_data.get('tools_technologies', [])
    primary_responsibilities = analysis_data.get('primary_responsibilities', [])
    industry_context = analysis_data.get('industry_context', '')
    key_phrases = analysis_data.get('key_phrases', [])

    # Build introduction
    intro = f"You are a {experience_level} {role_title}"
    if industry_context:
        intro += f" working in {industry_context}"
    intro += ". You bring specialized expertise and practical experience to solve complex challenges in your field."

    # Build skills section
    skills_section = "Core Competencies:"
    if core_skills:
        for skill in core_skills:
            skills_section += f"\n‚Ä¢ {skill}"
    else:
        skills_section += f"\n‚Ä¢ Professional expertise in {keyword}"

    # Build responsibilities section
    responsibilities_section = ""
    if primary_responsibilities:
        responsibilities_section = "\nPrimary Responsibilities:"
        for responsibility in primary_responsibilities:
            responsibilities_section += f"\n‚Ä¢ {responsibility}"

    # Build communication section
    communication_section = "Communication Approach:"
    if communication_style:
        communication_text = " ".join(communication_style)
        communication_section += f"\n{communication_text}"
    else:
        communication_section += "\nProvide expert advice with clear reasoning and practical examples."

    # Build tools section
    tools_section = ""
    if tools_technologies:
        tools_section = "\nTools & Technologies:"
        for tool in tools_technologies:
            tools_section += f"\n‚Ä¢ {tool}"

    # Build key phrases section
    phrases_section = ""
    if key_phrases:
        phrases_section = "\nKey Phrases You Use:"
        for phrase in key_phrases[:3]:  # Limit to 3 phrases
            phrases_section += f"\n‚Ä¢ \"{phrase}\""

    # Experience level specific additions
    experience_additions = ""
    if experience_level in ['senior', 'expert', 'lead']:
        experience_additions = """
Leadership Qualities:
‚Ä¢ Mentor and guide team members
‚Ä¢ Make strategic decisions and provide direction
‚Ä¢ Drive best practices and innovation
‚Ä¢ Collaborate across departments and stakeholders"""

    # Build final template
    template = f"""{intro}

{skills_section}{responsibilities_section}{experience_additions}

{communication_section}{tools_section}{phrases_section}

Response Guidelines:
‚Ä¢ Start by understanding the specific challenge or question
‚Ä¢ Provide {experience_level}-level insights appropriate to a {role_title}
‚Ä¢ Draw from your professional experience and industry knowledge
‚Ä¢ Include specific examples and actionable recommendations
‚Ä¢ End with clarifying questions to ensure you're addressing core needs

Professional Identity:
"As a {experience_level} {role_title}, I bring {len(core_skills)} key competencies to help solve your challenges effectively."

Remember: You're not just providing information - you're a {experience_level} {role_title} ready to apply your specialized knowledge to solve real problems."""

    return template

def create_dynamic_persona_template(context):
    """Main function to create AI-powered dynamic persona"""
    keyword = context['keyword']

    logging.info(f"Generating AI-powered persona for: {keyword}")

    # Get AI analysis of the role
    analysis_data = generate_ai_persona_analysis(keyword)

    # Build persona template from AI analysis
    persona_template = build_persona_from_ai_analysis(analysis_data, keyword)

    return persona_template

def detect_domain_context(text):
    """Enhanced domain and context detection for persona generation"""
    text_lower = text.lower()

    # More comprehensive domain patterns with better keyword matching
    domain_patterns = {
        'technology': {
            'keywords': ['python', 'javascript', 'react', 'node', 'developer', 'programmer', 'software', 'coding', 'programming', 'ai', 'machine learning', 'data science', 'cybersecurity', 'cloud', 'devops', 'blockchain', 'api', 'database', 'frontend', 'backend', 'fullstack', 'web development', 'mobile development', 'ios', 'android', 'java', 'c++', 'php', 'ruby', 'go', 'rust', 'typescript', 'vue', 'angular'],
            'weight': 1.0
        },
        'business': {
            'keywords': ['marketing', 'sales', 'business', 'strategy', 'management', 'leadership', 'finance', 'consulting', 'entrepreneur', 'startup', 'revenue', 'profit', 'roi', 'kpi', 'analytics', 'growth hacking', 'digital marketing', 'social media', 'seo', 'ppc', 'content marketing', 'email marketing', 'brand', 'branding'],
            'weight': 1.0
        },
        'creative': {
            'keywords': ['design', 'designer', 'art', 'artist', 'creative', 'writing', 'writer', 'content', 'video', 'photography', 'photographer', 'graphics', 'ui', 'ux', 'storytelling', 'music', 'animation', 'illustration', 'copywriter', 'creative director'],
            'weight': 1.0
        },
        'education': {
            'keywords': ['teacher', 'teaching', 'education', 'training', 'trainer', 'learning', 'curriculum', 'academic', 'research', 'researcher', 'science', 'professor', 'tutor', 'course', 'study', 'instructor'],
            'weight': 1.0
        },
        'healthcare': {
            'keywords': ['medical', 'health', 'doctor', 'nurse', 'therapy', 'therapist', 'wellness', 'fitness', 'nutrition', 'psychology', 'psychologist', 'mental health', 'patient', 'healthcare', 'physician'],
            'weight': 1.0
        },
        'legal': {
            'keywords': ['legal', 'law', 'lawyer', 'attorney', 'court', 'contract', 'compliance', 'regulation', 'policy', 'rights', 'paralegal', 'legal counsel'],
            'weight': 1.0
        },
        'finance': {
            'keywords': ['finance', 'financial', 'accountant', 'accounting', 'investment', 'investor', 'banking', 'fintech', 'cryptocurrency', 'trading', 'analyst', 'cfo', 'bookkeeper'],
            'weight': 1.0
        }
    }

    domain_scores = {}

    # Score each domain based on keyword matches
    for domain, config in domain_patterns.items():
        score = 0
        for keyword in config['keywords']:
            if keyword in text_lower:
                score += config['weight']
                # Bonus for exact matches
                if keyword == text_lower.strip():
                    score += 2
        domain_scores[domain] = score

    # Find the domain with highest score
    detected_domain = max(domain_scores, key=domain_scores.get) if max(domain_scores.values()) > 0 else 'general'

    # Detect communication tone
    tone_patterns = {
        'expert': ['senior', 'lead', 'principal', 'expert', 'specialist', 'advanced', 'architect'],
        'casual': ['friendly', 'casual', 'relaxed', 'informal', 'conversational', 'buddy'],
        'creative': ['creative', 'innovative', 'artistic', 'imaginative', 'original', 'visionary'],
        'professional': ['professional', 'business', 'corporate', 'executive', 'formal']  # default
    }

    detected_tone = 'professional'  # default
    for tone, keywords in tone_patterns.items():
        if any(keyword in text_lower for keyword in keywords):
            detected_tone = tone
            break

    return {
        'domain': detected_domain,
        'tone': detected_tone,
        'keyword': text.strip()
    }

@app.route('/generate-persona', methods=['POST'])
def generate_persona():
    """Generate AI-powered dynamic persona template"""
    try:
        # ADD CREDIT CHECK
        credit_result = optional_credit_check('persona_generator')
        if not credit_result['success']:
            return jsonify({
                'error': credit_result['message'],
                'credits_required': get_feature_credits('persona_generator')
            }), 402

        data = request.get_json(force=True)
        keyword = data.get('text', '').strip()

        if not keyword:
            return jsonify({'error': 'Keyword is required'}), 400

        logging.info(f"=== AI Persona Generation Started ===")
        logging.info(f"Input keyword: {keyword}")

        # Detect basic context (keeping existing function for metadata)
        context = detect_domain_context(keyword)
        logging.info(f"Detected domain: {context['domain']}, tone: {context['tone']}")

        # Generate AI-powered persona
        persona_template = create_dynamic_persona_template(context)

        if not persona_template:
            raise Exception("Failed to generate persona template")

        logging.info(f"=== AI Persona Generation Completed ===")

        result = {
            'prompt': persona_template,
            'status': 'success',
            'metadata': {
                'keyword': keyword,
                'domain': context['domain'],
                'tone': context['tone'],
                'mode': 'ai_powered_persona',
                'ai_analyzed': True
            }
        }

        if credit_result.get('credits_used'):
            result['credits_used'] = credit_result['credits_used']
            result['credits_remaining'] = credit_result.get('remaining')

        return jsonify(result)

    except Exception as e:
        logging.error(f"=== AI Persona Generation Failed ===")
        logging.error(f"Error: {str(e)}")
        logging.error(f"Error type: {type(e).__name__}")

        return jsonify({
            'error': 'Failed to generate AI-powered persona',
            'details': str(e),
            'metadata': {
                'fallback_used': True,
                'ai_analyzed': False
            }
        }), 500

# MAILGUN TEST ENDPOINT - ADD THIS
@app.route('/test-mailgun-config', methods=['GET'])
def test_mailgun_config():
    """Test Mailgun configuration"""
    try:
        return jsonify({
            'status': 'success',
            'mailgun_domain': MAILGUN_DOMAIN,
            'api_key_present': bool(MAILGUN_API_KEY),
            'api_key_length': len(MAILGUN_API_KEY) if MAILGUN_API_KEY else 0,
            'frontend_url': FRONTEND_BASE_URL,
            'verification_url': VERIFICATION_BASE_URL,
            'environment_loaded': 'Environment variables loaded successfully'
        })
    except Exception as e:
        return jsonify({
            'status': 'error',
            'error': str(e),
            'message': 'Environment variables not loaded properly'
        }), 500

# ============================================
# MAILGUN EMAIL ENDPOINTS - ADD THESE
# ============================================

@app.route('/send-verification-email', methods=['POST'])
def send_verification_email():
    """Send custom verification email via Mailgun"""
    try:
        data = request.get_json()
        email = data.get('email', '').strip().lower()
        first_name = data.get('firstName', '').strip()

        if not email:
            return jsonify({'error': 'Email is required'}), 400

        print(f"üìß Sending verification email to: {email}")

        # Send via Mailgun
        result = send_verification_email_mailgun(email, first_name)

        if result["success"]:
            return jsonify({
                'success': True,
                'message': 'Verification email sent successfully',
                'provider': 'mailgun',
                'delivered_via': 'Mailgun (95%+ inbox rate)'
            })
        else:
            return jsonify({
                'success': False,
                'message': 'Failed to send verification email',
                'error': result["message"],
                'use_firebase_fallback': True
            }), 500

    except Exception as e:
        print(f"‚ùå Send verification error: {e}")
        return jsonify({
            'error': 'Failed to send verification email',
            'details': str(e)
        }), 500

@app.route('/verify-email', methods=['GET'])
def verify_email():
    """Verify email using token and update Firebase user"""
    try:
        email = request.args.get('email', '').strip().lower()
        token = request.args.get('token', '').strip()

        if not email or not token:
            return f"""
            <html><body style="font-family: Arial; text-align: center; padding: 50px;">
            <h1 style="color: red;">‚ùå Invalid Verification Link</h1>
            <p>The verification link is missing required parameters.</p>
            <a href="{FRONTEND_BASE_URL}/login" style="background: #ffff00; padding: 10px 20px; text-decoration: none; color: black; border-radius: 5px;">Back to Login</a>
            </body></html>
            """

        print(f"üîê Verifying email: {email}")

        # Verify token
        if not verify_token_v2(email, token):
            print(f"‚ùå Invalid or expired token for {email}")
            return f"""
            <html><body style="font-family: Arial; text-align: center; padding: 50px;">
            <h1 style="color: red;">‚ùå Verification Link Expired</h1>
            <p>This verification link has expired. Please request a new one.</p>
            <a href="{FRONTEND_BASE_URL}/login" style="background: #ffff00; padding: 10px 20px; text-decoration: none; color: black; border-radius: 5px;">Back to Login</a>
            </body></html>
            """

        # Update Firebase user as verified
        if FIREBASE_ENABLED:
            try:
                # Get user by email
                user = auth.get_user_by_email(email)

                # Update user as verified
                auth.update_user(
                    user.uid,
                    email_verified=True
                )

                print(f"‚úÖ Email verified for user: {email}")

                # Success page
                return f"""
                <html><body style="font-family: Arial; text-align: center; padding: 50px;">
                <h1 style="color: green;">‚úÖ Email Verified Successfully!</h1>
                <p>Great! Your email address has been verified. You can now log in to your Solthron account.</p>
                <div style="margin: 30px 0;">
                    <h3>üéØ What's Next?</h3>
                    <ol style="text-align: left; display: inline-block;">
                        <li>Log in to your account</li>
                        <li>Install the Chrome extension</li>
                        <li>Start optimizing your AI prompts</li>
                    </ol>
                </div>
                <a href="{FRONTEND_BASE_URL}/login" style="background: #ffff00; padding: 15px 30px; text-decoration: none; color: black; border-radius: 5px; font-weight: bold; margin: 10px;">Login Now</a>
                <p style="margin-top: 30px; color: #666; font-size: 14px;">Redirecting to login in 5 seconds...</p>
                <script>setTimeout(function(){{ window.location.href = '{FRONTEND_BASE_URL}/login'; }}, 5000);</script>
                </body></html>
                """

            except auth.UserNotFoundError:
                print(f"‚ùå User not found: {email}")
                return f"""
                <html><body style="font-family: Arial; text-align: center; padding: 50px;">
                <h1 style="color: red;">‚ùå User Not Found</h1>
                <p>No account found with this email address.</p>
                <a href="{FRONTEND_BASE_URL}/signup" style="background: #ffff00; padding: 10px 20px; text-decoration: none; color: black; border-radius: 5px;">Create Account</a>
                </body></html>
                """
            except Exception as firebase_error:
                print(f"‚ùå Firebase error: {firebase_error}")
                return f"""
                <html><body style="font-family: Arial; text-align: center; padding: 50px;">
                <h1 style="color: red;">‚ùå Verification Error</h1>
                <p>There was an issue verifying your account. Please try again or contact support.</p>
                <a href="{FRONTEND_BASE_URL}/login" style="background: #ffff00; padding: 10px 20px; text-decoration: none; color: black; border-radius: 5px;">Back to Login</a>
                </body></html>
                """
        else:
            return f"""
            <html><body style="font-family: Arial; text-align: center; padding: 50px;">
            <h1 style="color: red;">‚ùå Service Unavailable</h1>
            <p>Email verification service is temporarily unavailable.</p>
            <a href="{FRONTEND_BASE_URL}/login" style="background: #ffff00; padding: 10px 20px; text-decoration: none; color: black; border-radius: 5px;">Back to Login</a>
            </body></html>
            """

    except Exception as e:
        print(f"‚ùå Verification error: {e}")
        return f"""
        <html><body style="font-family: Arial; text-align: center; padding: 50px;">
        <h1 style="color: red;">‚ùå Server Error</h1>
        <p>An unexpected error occurred during verification.</p>
        <a href="{FRONTEND_BASE_URL}/login" style="background: #ffff00; padding: 10px 20px; text-decoration: none; color: black; border-radius: 5px;">Back to Login</a>
        </body></html>
        """

@app.route('/analyze-context', methods=['POST'])
def analyze_context():
    """Analyze user's input context for auto suggestion mode"""
    try:
        # ADD CREDIT CHECK
        credit_result = optional_credit_check('auto_suggestion')
        if not credit_result['success']:
            return jsonify({
                'error': credit_result['message'],
                'credits_required': get_feature_credits('auto_suggestion')
            }), 402

        data = request.get_json(force=True)
        input_text = data.get('input_text', '').strip()
        platform = data.get('platform', 'unknown')
        timestamp = data.get('timestamp', 0)

        if not input_text:
            return jsonify({'error': 'Input text is required'}), 400

        print(f"ü§ñ Analyzing context for: {input_text[:50]}...")

        # Analyze the user's input context
        analysis_result = analyze_user_context_with_ai(input_text, platform)

        result = {
            'success': True,
            'warm_message': analysis_result['warm_message'],
            'detected_context': analysis_result['detected_context'],
            'confidence': analysis_result['confidence'],
            'platform': platform,
            'analysis_timestamp': timestamp
        }

        if credit_result.get('credits_used'):
            result['credits_used'] = credit_result['credits_used']
            result['credits_remaining'] = credit_result.get('remaining')

        print(f"‚úÖ Context analysis complete: {analysis_result['detected_context']}")
        return jsonify(result)

    except Exception as e:
        print(f"‚ùå Context analysis error: {e}")
        return jsonify({
            'error': 'Failed to analyze context',
            'details': str(e)
        }), 500

@app.route('/synthesize-conversation', methods=['POST'])
def synthesize_conversation():
    """Synthesize multiple conversation inputs into a better prompt"""
    try:
        # ADD CREDIT CHECK
        credit_result = optional_credit_check('smart_enhancements')
        if not credit_result['success']:
            return jsonify({
                'error': credit_result['message'],
                'credits_required': get_feature_credits('smart_enhancements')
            }), 402

        data = request.get_json()
        inputs = data.get('inputs', [])
        platform = data.get('platform', 'unknown')
        session_id = data.get('sessionId', '')

        if not inputs or len(inputs) < 2:
            return jsonify({'error': 'At least 2 inputs required for synthesis'}), 400

        print(f"üîÑ Synthesizing {len(inputs)} inputs for session: {session_id}")

        # Build synthesis prompt
        input_texts = [inp.get('text', '') for inp in inputs]
        conversation_flow = '\n'.join([f"Input {i+1}: {text}" for i, text in enumerate(input_texts)])

        synthesis_prompt = f"""You are an expert prompt engineer creating "practical magic" - prompts that give users helpful details they wouldn't think of, without overwhelming them.

User's conversation flow:
{conversation_flow}

ANALYSIS FRAMEWORK:
1. What type of work is in progress? (writing, coding, planning, etc.)
2. What's the user's apparent skill level? (beginner asking for simple things vs advanced requests)
3. What practical improvements would genuinely help but they wouldn't think to ask for?

PRACTICAL MAGIC PRINCIPLES:
‚úÖ Add helpful specifics they wouldn't consider
‚úÖ Include real-world examples and use cases
‚úÖ Suggest common pitfalls to avoid
‚úÖ Add user-focused improvements that matter
‚úÖ Keep it practical and actionable
‚úÖ Create an OPTIMIZED PROMPT, not an answer
‚úÖ Refine their request to be more specific and effective
‚úÖ Help them ask better questions, don't provide solutions
‚ùå No overwhelming technical jargon
‚ùå No over-engineering or complex frameworks
‚ùå Don't change their core intent

EXAMPLES BY DOMAIN:

WRITING (Blog/Content):
‚ùå Basic: "Make the blog more engaging"
‚ùå Overwhelming: "Implement AIDA framework with conversion funnels and behavioral psychology"
‚úÖ Practical Magic: "Add personal anecdotes, include specific examples readers can relate to, address common objections people have about this topic, and end with actionable next steps"

CODING:
‚ùå Basic: "Add error handling to the component"
‚ùå Overwhelming: "Implement enterprise architecture with dependency injection and observer patterns"
‚úÖ Practical Magic: "Add helpful error messages users can understand, loading states so users know something's happening, and simple validation to prevent common mistakes"

CREATIVE (Poems/Stories):
‚ùå Basic: "Make the character description more detailed"
‚ùå Overwhelming: "Apply literary theory with metaphysical conceits and postmodern narrative techniques"
‚úÖ Practical Magic: "Add sensory details like sounds and textures, include emotional reactions that make readers connect with the character, and create a vivid setting that feels real"

BUSINESS:
‚ùå Basic: "Improve the marketing plan"
‚ùå Overwhelming: "Create omnichannel attribution models with predictive analytics and behavioral segmentation"
‚úÖ Practical Magic: "Include specific budget numbers, realistic timelines with milestones, ways to measure if it's working, and backup plans if the first approach doesn't work"

YOUR TASK:
Create ONE continuation prompt that enhances existing work with practical details that create an "aha moment" - things that are genuinely helpful but the user wouldn't think to ask for and just give the prompt as the output - dont ask a question - the prompt will be directly copy pasted by the user.

Take their basic request and make it more detailed and effective while keeping the same intent, refer to the Practical magical example for the length of the prompt

Enhanced continuation prompt:"""

        response = client.chat.completions.create(
            model="chatgpt-4o-latest",
            messages=[
                {
                    "role": "system",
                    "content": "You are an expert at creating 'practical magic' prompts - enhancements that give users helpful details they wouldn't think of, without overwhelming them. Focus on genuinely useful improvements that create 'aha moments'."
                },
                {
                    "role": "user",
                    "content": synthesis_prompt
                }
            ],
            temperature=0.3,
            max_tokens=800
        )

        synthesized_prompt = response.choices[0].message.content.strip()

        # Clean up the response - remove any meta text
        if synthesized_prompt.startswith("Optimized continuation prompt:"):
            synthesized_prompt = synthesized_prompt.replace("Optimized continuation prompt:", "").strip()
        if synthesized_prompt.startswith("Here's"):
            lines = synthesized_prompt.split('\n')
            synthesized_prompt = '\n'.join(lines[1:]).strip()

        result = {
            'success': True,
            'synthesized_prompt': synthesized_prompt,
            'input_count': len(inputs),
            'session_id': session_id,
            'platform': platform
        }

        if credit_result.get('credits_used'):
            result['credits_used'] = credit_result['credits_used']
            result['credits_remaining'] = credit_result.get('remaining')

        print(f"‚úÖ Synthesis complete for session: {session_id}")
        return jsonify(result)

    except Exception as e:
        print(f"‚ùå Synthesis error: {e}")
        return jsonify({
            'error': 'Failed to synthesize conversation',
            'details': str(e)
        }), 500

@app.route('/analyze-intervention', methods=['POST'])
def analyze_intervention():
    """Analyze conversation progression for personalized intervention message"""
    try:
        # ADD CREDIT CHECK (same as auto suggestion - 3 credits)
        credit_result = optional_credit_check('auto_suggestion')
        if not credit_result['success']:
            return jsonify({
                'error': credit_result['message'],
                'credits_required': get_feature_credits('auto_suggestion')
            }), 402

        data = request.get_json()
        inputs = data.get('inputs', [])
        platform = data.get('platform', 'unknown')

        if not inputs or len(inputs) < 2:
            return jsonify({'error': 'At least 2 inputs required for intervention analysis'}), 400

        print(f"üîç Analyzing intervention for {len(inputs)} inputs...")

        # Get the last 2-3 inputs for better context
        recent_inputs = inputs[-3:] if len(inputs) >= 3 else inputs[-2:]
        input_1 = recent_inputs[0].get('text', '')
        input_2 = recent_inputs[1].get('text', '')
        input_3 = recent_inputs[2].get('text', '') if len(recent_inputs) >= 3 else ''

        analysis_prompt = f"""Analyze this conversation progression to create a personalized intervention message.

Input 1 (Original): "{input_1}"
Input 2 (Modification): "{input_2}"
{f'Input 3 (Additional): "{input_3}"' if input_3 else ''}

The user made an original request, then tried to refine/modify it{' multiple times' if input_3 else ''}. I need to show them a helpful popup.

Create a short, personalized message (max 12 words) that:
1. Shows I understand their original intent AND their modification
2. Offers to help them craft a better prompt
3. Uses the specific topics/concepts they mentioned
4. Sounds encouraging and helpful

Examples of good intervention messages:
- "I see you want a shorter crypto blog. Let me help!"
- "Marketing strategy with social media focus - I'll craft it better!"
- "React component but simpler - let me optimize that prompt!"
- "Professional email that's more casual - I can combine these!"
- "Crypto blog that's shorter + includes dogecoin - let me merge these!"
- "Marketing plan with budget constraints + social focus - I'll optimize!"

JSON Format:
{{
    "intervention_message": "personalized message here",
    "detected_intent": "what they're trying to achieve",
    "detected_modification": "how they're trying to change it",
    "confidence": 0.0-1.0
}}

Keep the intervention_message under 12 words and make it specific to their actual requests."""

        response = client.chat.completions.create(
            model="chatgpt-4o-latest",
            messages=[
                {
                    "role": "system",
                    "content": "You are an intelligent conversation assistant that creates personalized, encouraging intervention messages. Always respond with valid JSON only."
                },
                {
                    "role": "user",
                    "content": analysis_prompt
                }
            ],
            temperature=0.3,
            max_tokens=300
        )

        ai_response = response.choices[0].message.content.strip()

        # Clean and parse JSON response
        if "```json" in ai_response:
            ai_response = ai_response.split("```json")[1].split("```")[0]
        elif "```" in ai_response:
            ai_response = ai_response.split("```")[1].split("```")[0]

        # Find JSON boundaries
        start_idx = ai_response.find('{')
        end_idx = ai_response.rfind('}') + 1

        if start_idx != -1 and end_idx > start_idx:
            json_str = ai_response[start_idx:end_idx]
            analysis_data = json.loads(json_str)

            result = {
                'success': True,
                'intervention_message': analysis_data.get('intervention_message', 'I can help craft a better prompt combining everything!'),
                'detected_intent': analysis_data.get('detected_intent', 'general'),
                'detected_modification': analysis_data.get('detected_modification', 'refinement'),
                'confidence': float(analysis_data.get('confidence', 0.8)),
                'platform': platform,
                'input_count': len(inputs)
            }

            if credit_result.get('credits_used'):
                result['credits_used'] = credit_result['credits_used']
                result['credits_remaining'] = credit_result.get('remaining')

            print(f"‚úÖ Intervention analysis complete: {result['intervention_message']}")
            return jsonify(result)

        else:
            # Fallback if JSON parsing fails
            result = {
                'success': True,
                'intervention_message': 'I can help craft a better prompt combining everything!',
                'detected_intent': 'general',
                'detected_modification': 'refinement',
                'confidence': 0.5,
                'platform': platform,
                'input_count': len(inputs)
            }

            if credit_result.get('credits_used'):
                result['credits_used'] = credit_result['credits_used']
                result['credits_remaining'] = credit_result.get('remaining')

            return jsonify(result)

    except Exception as e:
        print(f"‚ùå Intervention analysis error: {e}")
        return jsonify({
            'error': 'Failed to analyze intervention',
            'details': str(e)
        }), 500

@app.route('/analyze-motivation', methods=['POST'])
def analyze_motivation():
    """Generate personalized motivational message for 5th prompt"""
    try:
        # ADD CREDIT CHECK (same as auto suggestion - 3 credits)
        credit_result = optional_credit_check('auto_suggestion')
        if not credit_result['success']:
            return jsonify({
                'error': credit_result['message'],
                'credits_required': get_feature_credits('auto_suggestion')
            }), 402

        data = request.get_json()
        inputs = data.get('inputs', [])
        platform = data.get('platform', 'unknown')

        if not inputs or len(inputs) < 5:
            return jsonify({'error': 'Need at least 5 inputs for motivational analysis'}), 400

        print(f"üí™ Analyzing motivation for {len(inputs)} inputs...")

        # Get the user's journey context
        input_texts = [inp.get('text', '') for inp in inputs]
        conversation_context = ' | '.join(input_texts)

        motivation_prompt = f"""You are an encouraging AI assistant analyzing a user's conversation journey to provide personalized motivation.

User's conversation journey (5 prompts):
{conversation_context}

Create a short, personalized motivational message (max 15 words) that:
1. Shows you understand their specific topic/project
2. Acknowledges their progress and persistence
3. Sounds genuinely encouraging and supportive
4. References their actual work/topic specifically
5. Feels personal and warm

Examples of good motivational messages:
- "Your marketing strategy is really taking shape - the research depth shows!"
- "This React component is getting more sophisticated with each iteration!"
- "Your crypto blog concept is becoming really compelling and unique!"
- "The way you're refining this business plan shows real strategic thinking!"

JSON Format:
{{
    "motivational_message": "personalized encouraging message here",
    "detected_topic": "what they're working on",
    "progress_observed": "what progress you noticed",
    "confidence": 0.0-1.0
}}

Keep the motivational_message under 15 words and make it specific to their actual work."""

        response = client.chat.completions.create(
            model="chatgpt-4o-latest",
            messages=[
                {
                    "role": "system",
                    "content": "You are a supportive AI coach that provides personalized encouragement. Always respond with valid JSON only."
                },
                {
                    "role": "user",
                    "content": motivation_prompt
                }
            ],
            temperature=0.4,
            max_tokens=300
        )

        ai_response = response.choices[0].message.content.strip()

        # Clean and parse JSON response
        if "```json" in ai_response:
            ai_response = ai_response.split("```json")[1].split("```")[0]
        elif "```" in ai_response:
            ai_response = ai_response.split("```")[1].split("```")[0]

        # Find JSON boundaries
        start_idx = ai_response.find('{')
        end_idx = ai_response.rfind('}') + 1

        if start_idx != -1 and end_idx > start_idx:
            json_str = ai_response[start_idx:end_idx]
            analysis_data = json.loads(json_str)

            result = {
                'success': True,
                'motivational_message': analysis_data.get('motivational_message', 'You\'re making excellent progress - keep going!'),
                'detected_topic': analysis_data.get('detected_topic', 'your project'),
                'progress_observed': analysis_data.get('progress_observed', 'steady improvement'),
                'confidence': float(analysis_data.get('confidence', 0.8)),
                'platform': platform,
                'input_count': len(inputs)
            }

            if credit_result.get('credits_used'):
                result['credits_used'] = credit_result['credits_used']
                result['credits_remaining'] = credit_result.get('remaining')

            print(f"‚úÖ Motivational analysis complete: {result['motivational_message']}")
            return jsonify(result)

        else:
            # Fallback if JSON parsing fails
            result = {
                'success': True,
                'motivational_message': 'You\'re making excellent progress with your conversation!',
                'detected_topic': 'your project',
                'progress_observed': 'steady improvement',
                'confidence': 0.5,
                'platform': platform,
                'input_count': len(inputs)
            }

            if credit_result.get('credits_used'):
                result['credits_used'] = credit_result['credits_used']
                result['credits_remaining'] = credit_result.get('remaining')

            return jsonify(result)

    except Exception as e:
        print(f"‚ùå Motivational analysis error: {e}")
        return jsonify({
            'error': 'Failed to analyze motivation',
            'details': str(e)
        }), 500

@app.route('/resend-verification', methods=['POST'])
def resend_verification():
    """Resend verification email"""
    try:
        data = request.get_json()
        email = data.get('email', '').strip().lower()
        first_name = data.get('firstName', '').strip()

        if not email:
            return jsonify({'error': 'Email is required'}), 400

        print(f"üîÑ Resending verification email to: {email}")

        # Send verification email
        result = send_verification_email_mailgun(email, first_name)

        if result["success"]:
            return jsonify({
                'success': True,
                'message': 'Verification email resent successfully'
            })
        else:
            return jsonify({
                'success': False,
                'message': 'Failed to resend verification email',
                'use_firebase_fallback': True
            }), 500

    except Exception as e:
        print(f"‚ùå Resend verification error: {e}")
        return jsonify({
            'error': 'Failed to resend verification email',
            'details': str(e)
        }), 500

@app.route('/summarize-ai-responses', methods=['POST'])
def summarize_ai_responses():
    """Summarize AI responses for context memory"""
    try:
        # ADD CREDIT CHECK
        credit_result = optional_credit_check('auto_suggestion')  # 3 credits like other auto features
        if not credit_result['success']:
            return jsonify({
                'error': credit_result['message'],
                'credits_required': get_feature_credits('auto_suggestion')
            }), 402

        data = request.get_json()
        responses = data.get('responses', [])
        platform = data.get('platform', 'unknown')

        if not responses:
            return jsonify({'error': 'No responses provided'}), 400

        print(f"üìù Summarizing {len(responses)} AI responses for platform: {platform}")

        # Create summarization prompt
        responses_text = ""
        for i, response in enumerate(responses):
            responses_text += f"Response {i+1}:\n{response.get('content', '')}\n\n"

        summarization_prompt = f"""You are an expert at creating concise, informative summaries of AI responses for conversation context.

AI Responses to Summarize:
{responses_text}

Create brief but informative summaries (2-3 sentences each) that capture:
- Main points or conclusions
- Key recommendations or advice given
- Important facts, numbers, or code mentioned
- Overall direction of the response

Return as JSON:
{{
    "summaries": [
        "Brief summary of response 1...",
        "Brief summary of response 2...",
        ...
    ]
}}"""

        response = client.chat.completions.create(
            model="chatgpt-4o-latest",
            messages=[
                {
                    "role": "system",
                    "content": "You are an expert at creating concise summaries. Always respond with valid JSON only."
                },
                {
                    "role": "user",
                    "content": summarization_prompt
                }
            ],
            temperature=0.3,
            max_tokens=800
        )

        ai_response = response.choices[0].message.content.strip()

        # Parse JSON response
        try:
            if "```json" in ai_response:
                ai_response = ai_response.split("```json")[1].split("```")[0]
            elif "```" in ai_response:
                ai_response = ai_response.split("```")[1].split("```")[0]

            start_idx = ai_response.find('{')
            end_idx = ai_response.rfind('}') + 1

            if start_idx != -1 and end_idx > start_idx:
                json_str = ai_response[start_idx:end_idx]
                summary_data = json.loads(json_str)

                result = {
                    'success': True,
                    'summaries': summary_data.get('summaries', []),
                    'platform': platform,
                    'count': len(responses)
                }

                if credit_result.get('credits_used'):
                    result['credits_used'] = credit_result['credits_used']
                    result['credits_remaining'] = credit_result.get('remaining')

                print(f"‚úÖ Successfully summarized {len(result['summaries'])} responses")
                return jsonify(result)

        except json.JSONDecodeError as e:
            print(f"‚ùå JSON parsing failed: {e}")
            # Fallback: create simple summaries
            fallback_summaries = []
            for response in responses:
                content = response.get('content', '')
                if len(content) > 200:
                    summary = content[:200] + "..."
                else:
                    summary = content
                fallback_summaries.append(summary)

            result = {
                'success': True,
                'summaries': fallback_summaries,
                'platform': platform,
                'count': len(responses),
                'fallback': True
            }

            if credit_result.get('credits_used'):
                result['credits_used'] = credit_result['credits_used']
                result['credits_remaining'] = credit_result.get('remaining')

            return jsonify(result)

    except Exception as e:
        print(f"‚ùå Summarization error: {e}")
        return jsonify({
            'error': 'Failed to summarize AI responses',
            'details': str(e)
        }), 500

@app.route('/generate-context-story', methods=['POST'])
def generate_context_story():
    """Generate comprehensive context story from conversation log"""
    try:
        # ADD CREDIT CHECK
        credit_result = optional_credit_check('auto_suggestion')  # 3 credits
        if not credit_result['success']:
            return jsonify({
                'error': credit_result['message'],
                'credits_required': get_feature_credits('auto_suggestion')
            }), 402

        data = request.get_json()
        conversation_log = data.get('conversationLog', [])
        platform = data.get('platform', 'unknown')
        session_id = data.get('sessionId', 'unknown')
        session_duration = data.get('sessionDuration', 0)

        if not conversation_log or len(conversation_log) < 2:
            return jsonify({'error': 'Insufficient conversation data for story generation'}), 400

        print(f"üìñ Generating context story from {len(conversation_log)} conversation entries")

        # Format conversation for analysis
        conversation_text = ""
        user_inputs = []
        ai_responses = []

        for entry in conversation_log:
            if entry.get('type') == 'user':
                conversation_text += f"User: {entry.get('content', '')}\n\n"
                user_inputs.append(entry.get('content', ''))
            elif entry.get('type') == 'ai':
                conversation_text += f"AI: {entry.get('content', '')}\n\n"
                ai_responses.append(entry.get('content', ''))

        # Calculate session info
        duration_minutes = round(session_duration / (1000 * 60), 1)

        story_generation_prompt = f"""You are an expert at creating comprehensive context stories from AI conversations.

Conversation Details:
- Platform: {platform}
- Duration: {duration_minutes} minutes
- Total exchanges: {len(conversation_log)//2} (approx)
- Session ID: {session_id}

Full Conversation:
{conversation_text}

Create a detailed context story that captures:

1. **Objective**: What was the user trying to accomplish?
2. **Journey**: How did the conversation progress step by step?
3. **Key Discoveries**: Important insights, solutions, or breakthroughs
4. **Current Status**: Where things stand at the end
5. **Context for Future**: Essential background info for continuing this work
6. **Topic/Theme**: Extract the main topic for the title

Format as a structured story that someone could use to continue this conversation in a future session.

Return as JSON:
{{
    "topic": "Extracted main topic (5-8 words max)",
    "story": "Detailed context story in structured format",
    "objective": "What user was trying to accomplish",
    "key_insights": ["insight 1", "insight 2", "insight 3"],
    "next_steps": ["suggested next step 1", "suggested next step 2"],
    "session_summary": {{
        "platform": "{platform}",
        "duration_minutes": {duration_minutes},
        "exchanges": {len(conversation_log)//2}
    }}
}}"""

        response = client.chat.completions.create(
            model="chatgpt-4o-latest",
            messages=[
                {
                    "role": "system",
                    "content": "You are an expert at analyzing conversations and creating detailed context stories. Always respond with valid JSON only."
                },
                {
                    "role": "user",
                    "content": story_generation_prompt
                }
            ],
            temperature=0.3,
            max_tokens=1500
        )

        ai_response = response.choices[0].message.content.strip()

        # Parse JSON response
        try:
            if "```json" in ai_response:
                ai_response = ai_response.split("```json")[1].split("```")[0]
            elif "```" in ai_response:
                ai_response = ai_response.split("```")[1].split("```")[0]

            start_idx = ai_response.find('{')
            end_idx = ai_response.rfind('}') + 1

            if start_idx != -1 and end_idx > start_idx:
                json_str = ai_response[start_idx:end_idx]
                story_data = json.loads(json_str)

                # Format the final story with metadata
                formatted_story = f"""üìñ CONTEXT STORY: {story_data.get('topic', 'AI Conversation')}

üéØ OBJECTIVE:
{story_data.get('objective', 'Not specified')}

üìù CONVERSATION JOURNEY:
{story_data.get('story', 'Story generation failed')}

üí° KEY INSIGHTS:
"""

                insights = story_data.get('key_insights', [])
                for i, insight in enumerate(insights, 1):
                    formatted_story += f"{i}. {insight}\n"

                formatted_story += f"""
üöÄ SUGGESTED NEXT STEPS:
"""

                next_steps = story_data.get('next_steps', [])
                for i, step in enumerate(next_steps, 1):
                    formatted_story += f"{i}. {step}\n"

                session_info = story_data.get('session_summary', {})
                formatted_story += f"""
üìä SESSION INFO:
- Platform: {session_info.get('platform', platform)}
- Duration: {session_info.get('duration_minutes', duration_minutes)} minutes
- Exchanges: {session_info.get('exchanges', len(conversation_log)//2)}
- Generated: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M')}

üíº HOW TO USE THIS CONTEXT:
Copy this entire context and paste it at the beginning of your next AI conversation to continue where you left off."""

                result = {
                    'success': True,
                    'story': formatted_story,
                    'topic': story_data.get('topic', f'Context Story - {datetime.datetime.now().strftime("%m/%d")}'),
                    'raw_data': story_data,
                    'session_info': {
                        'platform': platform,
                        'duration_minutes': duration_minutes,
                        'total_entries': len(conversation_log)
                    }
                }

                if credit_result.get('credits_used'):
                    result['credits_used'] = credit_result['credits_used']
                    result['credits_remaining'] = credit_result.get('remaining')

                print(f"‚úÖ Context story generated successfully: {story_data.get('topic', 'Unknown Topic')}")
                return jsonify(result)

        except json.JSONDecodeError as e:
            print(f"‚ùå JSON parsing failed: {e}")

            # Fallback: create basic story
            fallback_story = f"""üìñ CONTEXT STORY: AI Conversation Summary

üéØ OBJECTIVE:
The user engaged in a {duration_minutes}-minute conversation on {platform}.

üìù CONVERSATION SUMMARY:
User started with: "{user_inputs[0] if user_inputs else 'Unknown'}"

The conversation involved {len(conversation_log)//2} exchanges covering various topics and questions.

üí° KEY POINTS:
- Platform: {platform}
- Duration: {duration_minutes} minutes
- Total exchanges: {len(conversation_log)//2}

üìä SESSION INFO:
- Generated: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M')}
- Session ID: {session_id}

üíº HOW TO USE THIS CONTEXT:
Copy this context and reference it in future conversations to maintain continuity."""

            result = {
                'success': True,
                'story': fallback_story,
                'topic': f'Context Story - {datetime.datetime.now().strftime("%m/%d")}',
                'fallback': True,
                'session_info': {
                    'platform': platform,
                    'duration_minutes': duration_minutes,
                    'total_entries': len(conversation_log)
                }
            }

            if credit_result.get('credits_used'):
                result['credits_used'] = credit_result['credits_used']
                result['credits_remaining'] = credit_result.get('remaining')

            return jsonify(result)

    except Exception as e:
        print(f"‚ùå Context story generation error: {e}")
        return jsonify({
            'error': 'Failed to generate context story',
            'details': str(e)
        }), 500

# ========== COPY PASTE THIS BEFORE: if __name__ == '__main__': ==========

@app.route('/generate-context-summary', methods=['POST'])
def generate_context_summary():
    """Generate comprehensive context summary of the entire conversation"""
    try:
        logging.info("=== Context summary request started ===")

        # ADD CREDIT CHECK
        credit_result = optional_credit_check('smart_enhancements')  # Using same credits as smart enhancements
        if not credit_result['success']:
            return jsonify({
                'error': credit_result['message'],
                'credits_required': get_feature_credits('smart_enhancements')
            }), 402

        # Parse request
        data = request.get_json(force=True)
        conversation = data.get('conversation', '').strip()
        platform = data.get('platform', 'unknown')

        logging.info(f"Conversation length: {len(conversation)}, Platform: {platform}")

        if not conversation:
            return jsonify({'error': 'Conversation content is required'}), 400

        # Build context summary prompt
        summary_prompt = f"""You are an expert conversation analyst. Analyze this entire conversation and create a comprehensive context summary.

CONVERSATION TO ANALYZE:
{conversation[:2500]}

Create a structured summary that captures:

1. **CONVERSATION OVERVIEW**
   - Main purpose/goal of the conversation
   - Overall conversation type (planning, problem-solving, learning, etc.)
   - Key participants and their roles

2. **TOPICS DISCUSSED**
   - Primary topics covered
   - Secondary topics or tangents
   - Topic progression/flow

3. **DECISIONS & CONCLUSIONS**
   - Key decisions made
   - Conclusions reached
   - Agreements or consensus points

4. **ACTION ITEMS & OUTCOMES**
   - Specific actions planned or taken
   - Deliverables mentioned
   - Next steps identified

5. **KEY INSIGHTS & LEARNINGS**
   - Important insights discovered
   - Problems solved
   - Knowledge gained

6. **CONVERSATION DYNAMICS**
   - Communication style and tone
   - Level of engagement
   - Collaboration patterns

Provide the summary in JSON format:
{{
    "overview": {{
        "purpose": "Main purpose of conversation",
        "type": "conversation type",
        "duration_estimate": "estimated conversation length"
    }},
    "topics": [
        {{
            "topic": "topic name",
            "importance": "high/medium/low",
            "discussion_depth": "surface/moderate/deep"
        }}
    ],
    "decisions": [
        {{
            "decision": "decision made",
            "rationale": "reasoning behind decision",
            "impact": "expected impact"
        }}
    ],
    "action_items": [
        {{
            "action": "specific action",
            "priority": "high/medium/low",
            "timeline": "when to complete"
        }}
    ],
    "insights": [
        {{
            "insight": "key insight discovered",
            "significance": "why this matters",
            "application": "how to apply this"
        }}
    ],
    "summary_text": "2-3 paragraph comprehensive summary of the entire conversation",
    "key_takeaways": [
        "Most important takeaway 1",
        "Most important takeaway 2",
        "Most important takeaway 3"
    ]
}}

Focus on being comprehensive yet concise. Capture the essence of what happened in this conversation."""

        # Use reliable models with proper error handling
        models_to_try = [
            {
                "name": "chatgpt-4o-latest",
                "params": {
                    "temperature": 0.2,
                    "max_tokens": 1500
                }
            },
            {
                "name": "gpt-4o",
                "params": {
                    "temperature": 0.2,
                    "max_tokens": 1200
                }
            }
        ]

        response = None
        model_used = None

        # Try models in order
        for model_config in models_to_try:
            try:
                model_name = model_config["name"]
                params = model_config["params"]

                logging.info(f"Trying model: {model_name}")

                response = client.chat.completions.create(
                    model=model_name,
                    messages=[
                        {
                            "role": "system",
                            "content": "You are an expert conversation analyst who creates comprehensive, structured summaries. Always respond with valid JSON only."
                        },
                        {
                            "role": "user",
                            "content": summary_prompt
                        }
                    ],
                    **params
                )

                model_used = model_name
                logging.info(f"Successfully used model: {model_name}")
                break

            except Exception as e:
                error_msg = str(e)
                logging.warning(f"Model {model_name} failed: {error_msg}")
                continue

        if not response:
            return jsonify({
                'success': False,
                'error': 'All AI models failed to respond'
            }), 500

        # Parse response
        ai_response = response.choices[0].message.content.strip()
        logging.info(f"AI Response length: {len(ai_response)}")

        try:
            # Parse JSON response
            parsed_response = parse_json_response_enhanced(ai_response)

            # Validate required fields
            required_fields = ['overview', 'topics', 'decisions', 'action_items', 'insights', 'summary_text', 'key_takeaways']
            for field in required_fields:
                if field not in parsed_response:
                    parsed_response[field] = []

            # Ensure overview is a dict
            if not isinstance(parsed_response.get('overview'), dict):
                parsed_response['overview'] = {
                    "purpose": "Conversation analysis",
                    "type": "general discussion",
                    "duration_estimate": "unknown"
                }

            # Ensure summary_text exists
            if not parsed_response.get('summary_text'):
                parsed_response['summary_text'] = "This conversation covered various topics and included meaningful discussion between participants."

            result = {
                'success': True,
                'summary': parsed_response,
                'platform': platform,
                'model': model_used,
                'conversation_length': len(conversation)
            }

            if credit_result.get('credits_used'):
                result['credits_used'] = credit_result['credits_used']
                result['credits_remaining'] = credit_result.get('remaining')

            return jsonify(result)

        except (json.JSONDecodeError, ValueError) as e:
            logging.error(f"JSON parsing failed: {str(e)}")

            # Fallback summary if JSON parsing fails
            fallback_summary = {
                "overview": {
                    "purpose": "Conversation analysis",
                    "type": "general discussion",
                    "duration_estimate": "moderate"
                },
                "topics": [
                    {"topic": "Main discussion points", "importance": "high", "discussion_depth": "moderate"}
                ],
                "decisions": [
                    {"decision": "Various points discussed", "rationale": "Based on conversation flow", "impact": "positive"}
                ],
                "action_items": [
                    {"action": "Continue conversation as needed", "priority": "medium", "timeline": "ongoing"}
                ],
                "insights": [
                    {"insight": "Productive conversation held", "significance": "Good communication", "application": "Apply learnings"}
                ],
                "summary_text": f"This conversation involved detailed discussion across multiple topics. The participants engaged in meaningful dialogue covering various aspects of the subject matter. Key points were discussed and insights were shared throughout the conversation.",
                "key_takeaways": [
                    "Productive conversation took place",
                    "Multiple topics were covered",
                    "Meaningful insights were shared"
                ]
            }

            result = {
                'success': True,
                'summary': fallback_summary,
                'platform': platform,
                'model': model_used,
                'conversation_length': len(conversation),
                'fallback': True
            }

            if credit_result.get('credits_used'):
                result['credits_used'] = credit_result['credits_used']
                result['credits_remaining'] = credit_result.get('remaining')

            return jsonify(result)

    except Exception as e:
        error_msg = str(e)
        error_type = type(e).__name__

        logging.error(f"=== Context summary error ===")
        logging.error(f"Error type: {error_type}")
        logging.error(f"Error message: {error_msg}")

        return jsonify({
            'success': False,
            'error': 'Failed to generate context summary',
            'details': error_msg[:200],
            'error_type': error_type
        }), 500

@app.route('/magic-pill-enhance', methods=['POST'])
def magic_pill_enhance():
    """Magic pill enhancement for single input text using practical magic principles"""
    try:
        # ADD CREDIT CHECK - 10 credits for magic pill
        credit_result = optional_credit_check('magic_pill_enhance')
        if not credit_result['success']:
            return jsonify({
                'error': credit_result['message'],
                'credits_required': 10  # Magic pill costs 10 credits
            }), 402

        data = request.get_json()
        input_text = data.get('text', '').strip()
        platform = data.get('platform', 'unknown')

        if not input_text:
            return jsonify({'error': 'Input text is required'}), 400

        print(f"ü™Ñ Magic pill enhancement for: {input_text[:50]}...")

        # Build magic pill enhancement prompt (adapted from synthesize-conversation)
        enhancement_prompt = f"""You are an expert prompt engineer creating "practical magic" - prompts that give users helpful details they wouldn't think of, without overwhelming them.

CRITICAL FIRST STEP - ANALYZE THE INPUT TYPE:
Determine if the user's input is:
1. ACTUAL CONTENT (greeting, casual message, simple statement, test input) ‚Üí Apply minimal fixing only
2. ENHANCEMENT REQUEST (clear request to improve/fix/enhance something) ‚Üí Apply appropriate enhancement level

User's input text:
{input_text}

INPUT TYPE DETECTION:
- If input is a simple greeting (hello, hi, how are you, etc.) ‚Üí Just fix typos/grammar, keep it as a greeting
- If input is casual conversation or test text ‚Üí Minimal changes, preserve the casual nature
- If input is clearly asking to enhance/improve/fix something ‚Üí Apply enhancement framework
- If input contains action words like "make this better", "improve", "fix", "create", "write" ‚Üí Enhancement request
- If input is vague but seems to be asking for help with a task ‚Üí Enhancement request

FOR ACTUAL CONTENT (greetings, casual text, simple statements):
- Fix obvious typos and grammar errors only
- Preserve the original tone and intent exactly
- Don't turn casual text into formal prompts
- Keep it natural and conversational
- Output should be the corrected version of their actual text

FOR ENHANCEMENT REQUESTS:
Apply the full enhancement framework below.

ANALYSIS FRAMEWORK (only for enhancement requests):
1. What type of work is in progress? (writing, coding, planning, etc.)
2. What's the user's apparent skill level? (beginner asking for simple things vs advanced requests)
3. What enhancement level is appropriate for this request?
4. What practical improvements would genuinely help but they wouldn't think to ask for?

PRACTICAL MAGIC PRINCIPLES (only for enhancement requests):
‚úÖ Match enhancement level to user needs (light/moderate/full)
‚úÖ Use conversational, human language that feels natural and approachable
‚úÖ For simple requests: focus on clarity, tone, and polish with friendly guidance
‚úÖ For moderate requests: add helpful specifics and examples in a supportive tone
‚úÖ For complex requests: provide comprehensive details with encouraging, human-like language
‚úÖ Include real-world examples and practical advice that feels genuinely helpful
‚úÖ Mention common challenges in a way that's understanding, not lecturing
‚úÖ Frame improvements as helpful suggestions rather than rigid requirements
‚úÖ Keep it practical and actionable while sounding like friendly expert advice
‚úÖ Create prompts that sound like they're coming from a knowledgeable colleague
‚úÖ Help users ask better questions in a supportive, encouraging way
‚úÖ PRESERVE the original meaning and context exactly
‚ùå No robotic or overly technical language
‚ùå No overwhelming jargon or sterile instructions
‚ùå Don't sound like a manual or documentation

EXAMPLES:

ACTUAL CONTENT (minimal fixing):
‚ùå Input: "Hellop - how re you"
‚ùå Wrong Output: "Polish the greeting for tone and clarity‚Äîmake it sound friendly and natural"
‚úÖ Correct Output: "Hello - how are you?"

‚ùå Input: "thanks for the help"
‚ùå Wrong Output: "Create a more detailed thank you message with specific appreciation"
‚úÖ Correct Output: "Thanks for the help!"

ENHANCEMENT REQUESTS (human-like, polished tone):
‚úÖ Input: "Make this greeting more professional: Hello there"
‚úÖ Output: "Help me make this greeting sound more professional and polished. I'd like it to use proper business etiquette, include appropriate titles if I know them, and strike the right formal tone: Hello there"

‚úÖ Input: "Help me write a blog post about AI"
‚úÖ Output: "Write a compelling blog post about AI that really connects with readers. Include real-world examples people can relate to, address the common myths and concerns people have, explain both the exciting possibilities and realistic limitations, and give readers something practical they can actually do with this information"

YOUR TASK:
First determine if this is ACTUAL CONTENT or an ENHANCEMENT REQUEST.
- If ACTUAL CONTENT: Just fix typos/grammar while preserving the exact original intent and tone
- If ENHANCEMENT REQUEST: Create an enhanced prompt with appropriate level of detail

Give ONLY the result as output - don't explain your reasoning or add meta-commentary."""

        response = client.chat.completions.create(
            model="gpt-5-chat-latest",
            messages=[
                {
                    "role": "system",
                    "content": "You are a helpful expert who enhances prompts with a warm, human touch. When creating enhancement requests, write like a knowledgeable colleague offering friendly, polished advice - not like a robot or instruction manual."
                },
                {
                    "role": "user",
                    "content": enhancement_prompt
                }
            ],
            temperature=0.3,
            max_tokens=800
        )

        enhanced_prompt = response.choices[0].message.content.strip()

        # Clean up the response - remove any meta text
        if enhanced_prompt.startswith("Enhanced prompt:"):
            enhanced_prompt = enhanced_prompt.replace("Enhanced prompt:", "").strip()
        if enhanced_prompt.startswith("Here's"):
            lines = enhanced_prompt.split('\n')
            enhanced_prompt = '\n'.join(lines[1:]).strip()

        result = {
            'success': True,
            'prompt': enhanced_prompt,
            'status': 'success',
            'platform': platform,
            'original_length': len(input_text),
            'enhanced_length': len(enhanced_prompt),
            'metadata': {
                'mode': 'magic_pill_enhance',
                'practical_magic': True
            }
        }

        if credit_result.get('credits_used'):
            result['credits_used'] = credit_result['credits_used']
            result['credits_remaining'] = credit_result.get('remaining')

        print(f"‚úÖ Magic pill enhancement complete")
        return jsonify(result)

    except Exception as e:
        print(f"‚ùå Magic pill enhancement error: {e}")
        return jsonify({
            'error': 'Failed to enhance prompt',
            'details': str(e)
        }), 500

@app.route('/gmail-enhance', methods=['POST'])
def gmail_enhance():
    """Gmail email enhancement with context-aware tone balancing"""
    try:
        # ADD CREDIT CHECK - 10 credits for Gmail enhancement
        credit_result = optional_credit_check('gmail_enhance')
        if not credit_result['success']:
            return jsonify({
                'error': credit_result['message'],
                'credits_required': 10  # Gmail enhancement costs 10 credits
            }), 402

        data = request.get_json()
        email_text = data.get('text', '').strip()
        context = data.get('context', {})
        tone_preference = data.get('tone', 'professional-soft')  # Default balanced tone

        if not email_text:
            return jsonify({'error': 'Email text is required'}), 400

        print(f"üìß Gmail enhancement for: {email_text[:50]}...")
        print(f"üìß Context: Reply={context.get('isReply')}, Recipients={len(context.get('recipients', []))}")

        # Build context-aware email enhancement prompt
        enhancement_prompt = f"""You are an expert email communication specialist who helps reframe and polish emails while keeping ALL the original content.

CRITICAL RULES:
1. NEVER add placeholder text like [Name], [Date], [Time], etc.
2. KEEP all actual names, details, and specifics the user already wrote
3. Only reframe/polish what exists - don't add new information
4. This is about making their existing email better, not creating a new one

Original email to reframe:
{email_text}

Email context:
- Is this a reply? {context.get('isReply', False)}
- Subject line: {context.get('subject', 'No subject')}
- Formal context: {context.get('isFormal', False)}

YOUR TASK - REFRAME & POLISH:

1. PRESERVE everything specific:
   - Keep all actual names as written
   - Keep all dates, times, details
   - Keep the core message exactly
   - Keep the same information flow

2. POLISH the language:
   - Fix grammar and typos
   - Improve sentence structure
   - Add smooth transitions between ideas
   - Make it flow naturally

3. BALANCE professional and soft tone:
   - Professional: Clear, structured, grammatically correct
   - Soft: Warm, approachable, human
   - Use phrases like "I appreciate" instead of raw "thanks"
   - Add courtesy where natural (not forced)

REFRAMING EXAMPLES:

Bad original: "hey john can we meet tomorrow about the project its urgent"
Good reframe: "Hey John, can we meet tomorrow about the project? It's become quite urgent and I'd appreciate your input."
‚ùå WRONG: "Hi [Name], can we meet tomorrow..." (DON'T add placeholders!)

Bad original: "I need those reports ASAP. Send them."
Good reframe: "I need those reports as soon as possible. Could you please send them when you have a moment?"
‚ùå WRONG: "Hi [Name], I need the reports..." (DON'T add things not there!)

Bad original: "Sorry for late response. Yes I can do that. When do you need?"
Good reframe: "Sorry for the late response. Yes, I can definitely do that. When do you need it by?"
‚úÖ Notice: Just polished what was there, didn't add new greetings or names

WHAT TO DO:
‚úÖ Fix grammar, spelling, punctuation
‚úÖ Improve flow between sentences
‚úÖ Add natural transitions ("and", "so", "because")
‚úÖ Polish tone to be professional yet warm
‚úÖ Make choppy sentences smoother
‚úÖ Clarify ambiguous phrases

WHAT NOT TO DO:
‚ùå Don't add greetings if not present
‚ùå Don't add names in brackets [Name]
‚ùå Don't add information not implied
‚ùå Don't change the meaning
‚ùå Don't make it sound like a different person wrote it
‚ùå Don't over-formalize casual emails
‚ùå Don't add corporate jargon

Remember: You're polishing and reframing their EXACT email, not writing a new one. Every detail they included stays, you're just making it sound better.

Provide ONLY the reframed email text - no explanations."""

        response = client.chat.completions.create(
            model="gpt-5-chat-latest",  # or your preferred model
            messages=[
                {
                    "role": "system",
                    "content": "You are an email reframing expert. Polish and reframe the exact email given - never add placeholder text like [Name] or information not already there. Just make what they wrote sound better."
                },
                {
                    "role": "user",
                    "content": enhancement_prompt
                }
            ],
            temperature=0.3,  # Lower temperature to stay closer to original
            max_tokens=800
        )

        enhanced_email = response.choices[0].message.content.strip()

        # Clean up any meta text if accidentally included
        if enhanced_email.startswith("Enhanced email:"):
            enhanced_email = enhanced_email.replace("Enhanced email:", "").strip()
        if enhanced_email.startswith("Reframed email:"):
            enhanced_email = enhanced_email.replace("Reframed email:", "").strip()
        if enhanced_email.startswith("Here's"):
            lines = enhanced_email.split('\n')
            enhanced_email = '\n'.join(lines[1:]).strip()

        result = {
            'success': True,
            'email': enhanced_email,  # Note: using 'email' key instead of 'prompt'
            'status': 'success',
            'platform': 'gmail',
            'original_length': len(email_text),
            'enhanced_length': len(enhanced_email),
            'metadata': {
                'mode': 'gmail_enhance',
                'tone': tone_preference,
                'is_reply': context.get('isReply', False),
                'recipient_count': len(context.get('recipients', []))
            }
        }

        if credit_result.get('credits_used'):
            result['credits_used'] = credit_result['credits_used']
            result['credits_remaining'] = credit_result.get('remaining')

        print(f"‚úÖ Gmail enhancement complete - {len(email_text)} ‚Üí {len(enhanced_email)} chars")
        return jsonify(result)

    except Exception as e:
        print(f"‚ùå Gmail enhancement error: {e}")
        return jsonify({
            'error': 'Failed to enhance email',
            'details': str(e)
        }), 500

@app.route('/gmail-enhance-smart', methods=['POST'])
def gmail_enhance_smart():
    """Smart context-aware email enhancement with blend ratio control"""
    try:
        # Credit check - 10 credits for Gmail enhancement
        credit_result = optional_credit_check('gmail_enhance')
        if not credit_result['success']:
            return jsonify({
                'error': credit_result['message'],
                'credits_required': 10
            }), 402

        data = request.get_json()
        email_text = data.get('text', '').strip()
        context = data.get('context', {})
        mode = data.get('mode', 'balanced').lower()

        if not email_text:
            return jsonify({'error': 'Email text is required'}), 400

        # Map mode to blend ratio
        mode_map = {
            "polish": 0.2,
            "balanced": 0.5,
            "reframe": 0.9
        }
        blend_ratio = mode_map.get(mode, 0.5)

        # Calculate temperature based on blend ratio
        temperature = 0.1 + (blend_ratio * 0.6)

        print(f"üìß Gmail enhancement - Mode: {mode}, Blend: {blend_ratio}, Temp: {temperature}")
        print(f"üìß Context: Reply={context.get('isReply')}, Recipients={len(context.get('recipients', []))}")

        # Updated comparison table with refined reframe guidance + paragraph break rules
        comparison_table = """
ENHANCEMENT MODE COMPARISON TABLE:
================================================================================
MODE     | WHAT TO DO (QUALITATIVE)        | WHAT NOT TO DO                 | LEVEL DESCRIPTION
---------|---------------------------------|--------------------------------|------------------
POLISH   | ‚Ä¢ Fix objective textual errors  | ‚Ä¢ DON'T restructure sentences  | MINIMAL ‚Äî objective fixes only
         |   (spelling, grammar, punctuation, capitalization)
         | ‚Ä¢ Preserve greetings, signatures, quoted text, and lists exactly
         | ‚Ä¢ Keep contractions exactly as in original
         |                                 | ‚Ä¢ DON'T add or remove facts     |
---------|---------------------------------|--------------------------------|------------------
BALANCED | ‚Ä¢ Fix all errors and improve    | ‚Ä¢ DON'T invent new facts       | MODERATE ‚Äî readability + flow
         |   sentence flow and readability | ‚Ä¢ DON'T change greeting style  | (tidy structure, minor reorganization)
         | ‚Ä¢ Add paragraph breaks where    | ‚Ä¢ DON'T replace signatures     |
         |   natural; add brief courtesy   |   or remove quoted blocks      |
         |   phrases only when natural     |                                |
---------|---------------------------------|--------------------------------|------------------
REFRAME  | ‚Ä¢ Complete rewrite with balanced| ‚Ä¢ DON'T invent new facts       | MAJOR ‚Äî natural professional rewrite
         |   professional-friendly tone    | ‚Ä¢ DON'T add "Subject:" lines   | (contextual structure, not robotic)
         | ‚Ä¢ Always add greeting           | ‚Ä¢ DON'T alter signature blocks |
         | ‚Ä¢ Use natural prose as default  | ‚Ä¢ DON'T force bullets on       |
         | ‚Ä¢ Add bullets/lists ONLY for 3+ |   simple 1-2 item requests     |
         |   distinct action items         | ‚Ä¢ DON'T over-formalize casual  |
         | ‚Ä¢ Smart paragraph breaks for    |   emails into corporate speak  |
         |   readability (see rules below) |                                |
         | ‚Ä¢ Add closing when making       |                                |
         |   requests or addressing issues |                                |
--------------------------------------------------------------------------------
KEY GUIDELINES FOR REFRAME (Natural & Context-Aware):

- TONE: Strike a balance between casual and professional ("professionally friendly")
  Example: "hey can u send files" ‚Üí "Hi, could you send the files when you get a chance?"
  NOT: "Dear Sir/Madam, I hope this message finds you well..."

- STRUCTURE: Adapt to email complexity, don't force one format on everything
  ‚Ä¢ Short acknowledgments (1-2 sentences) ‚Üí Brief but complete with greeting
  ‚Ä¢ Simple requests (1-2 items) ‚Üí Natural prose, NO bullets needed
  ‚Ä¢ Complex requests (3+ items) ‚Üí Numbered lists for clarity
  ‚Ä¢ Status updates ‚Üí Natural paragraphs, not forced sections

- BULLETS: Use ONLY when truly needed (3+ distinct items/action points)
  ‚ùå "Can you review the document and send feedback?" ‚Üí Keep as prose
  ‚úÖ "Need: slides, budget data, Q3 report, timeline" ‚Üí Use numbered list

- PARAGRAPH BREAKS (CRITICAL for clean structure):
  1. Always add blank line after greeting
  2. If body has 2+ sentences covering different sub-topics ‚Üí add paragraph break between topics
  3. If body has 3+ sentences total ‚Üí break after every 1-2 sentences for readability
  4. Always add blank line before closing

  EXAMPLE OF GOOD PARAGRAPH BREAKS:
  ‚ùå BAD (cramped):
  "Hi, Just a quick update ‚Äî I've completed the analysis, and the findings are looking promising. The document is already shared in Drive, and the team has been notified. Cheers!"

  ‚úÖ GOOD (clean structure):
  "Hi,

  Just a quick update ‚Äî I've completed the analysis, and the findings are looking promising.

  The document is already shared in Drive, and the team has been notified.

  Cheers!"

- CLOSINGS: Add naturally based on email intent
  ‚Ä¢ ADD when: Making requests, apologizing, announcing delays, asking for help
  ‚Ä¢ SKIP when: Pure FYIs, simple status updates without asks, informational notes

- ALWAYS preserve signature blocks verbatim at the end
- NEVER add subject lines - output only the email body
- Keep the conversational flow natural, not robotic or over-structured
================================================================================

COMPREHENSIVE EXAMPLES (Polish / Balanced / Reframe)
================================================================================

EXAMPLE 1 - SHORT CASUAL REQUEST:
ORIGINAL: "hey john can u send the report asap also need budget numbers thx"

POLISH: "Hey John, can you send the report ASAP? Also need budget numbers. Thanks!"
(Basic fixes: capitalization, "u"‚Üí"you", "thx"‚Üí"Thanks", punctuation; structure unchanged)

BALANCED: "Hey John,

Could you send the report ASAP? I also need the budget numbers when you have a chance.

Thanks!"
(Improved flow, paragraphing, courtesy added naturally)

REFRAME: "Hi John,

Could you send me the report as soon as possible? I also need the budget numbers when you have a chance.

Thanks!"
(Natural rewrite, professionally friendly tone, NO bullets needed for 2 items, includes greeting and closing. Single paragraph since ideas are related.)

================================================================================

EXAMPLE 2 - STATUS UPDATE WITH MULTIPLE TOPICS (NEEDS PARAGRAPH BREAKS):
ORIGINAL: "fyi completed the analysis findings look promising shared doc in drive already notified the team"

POLISH: "FYI, completed the analysis. Findings look promising. Shared doc in Drive. Already notified the team."
(Fixed punctuation and capitalization)

BALANCED: "FYI, I completed the analysis and the findings look promising. I've shared the document in Drive and already notified the team."
(Improved flow in connected sentences)

REFRAME: "Hi,

Just a quick update ‚Äî I've completed the analysis, and the findings are looking promising.

The document is already shared in Drive, and the team has been notified.

Cheers!"
(NOTICE: Blank line after greeting, paragraph break between two different sub-topics, blank line before closing. Clean and readable!)

================================================================================

EXAMPLE 3 - SIMPLE ONE-ITEM REQUEST:
ORIGINAL: "can u review the deck and give feedback"

POLISH: "Can you review the deck and give feedback?"
(Fixed capitalization and punctuation)

BALANCED: "Could you review the deck and give me feedback when you have time?

Thanks!"
(Improved courtesy and flow)

REFRAME: "Hi,

Could you review the deck and share your feedback when you get a chance?

Thanks!"
(Natural prose, NO bullets - it's just one request. Greeting has blank line after it, closing has blank line before it.)

================================================================================

EXAMPLE 4 - COMPLEX REQUEST (3+ ITEMS - BULLETS APPROPRIATE):
ORIGINAL: "need help with presentation tomorrow can u review slides also need data from q3 and approval from sarah"

POLISH: "Need help with presentation tomorrow. Can you review slides? Also need data from Q3 and approval from Sarah."
(Fixes only)

BALANCED: "I need help with tomorrow's presentation. Could you review the slides?

I also need the Q3 data and approval from Sarah if possible."
(Improved tone and flow)

REFRAME: "Hi,

I'm preparing for tomorrow's presentation and need your help with a few things:

1. Review the slide deck for feedback
2. Q3 data for the analysis section
3. Approval from Sarah to proceed

Would you be able to help with these today?

Thanks!"
(3+ distinct items = bullets make sense. Notice blank lines: after greeting, before numbered list, before question, before closing.)

================================================================================

EXAMPLE 5 - SHORT ACKNOWLEDGMENT:
ORIGINAL: "ok noted"

POLISH: "Ok, noted."
(Fixed capitalization)

BALANCED: "Okay, noted. Thanks for letting me know."
(Added courtesy phrase)

REFRAME: "Hi,

Got it, thanks for the update!"
(Brief but complete with greeting. Single line body is fine for very short emails - blank line after greeting still present.)

================================================================================

EXAMPLE 6 - MEETING UPDATE WITH MULTIPLE POINTS (PARAGRAPH BREAKS NEEDED):
ORIGINAL: "meeting moved 3pm tomorrow sarah joining btw sales look good discuss strategy?"

POLISH: "Meeting moved to 3pm tomorrow. Sarah joining. BTW, sales look good. Discuss strategy?"
(Fixed grammar/punctuation)

BALANCED: "Meeting moved to 3pm tomorrow. Sarah will be joining us.

BTW, sales look good ‚Äî should we discuss strategy?"
(Improved readability and flow)

REFRAME: "Hi team,

Quick update: tomorrow's meeting has been moved to 3pm, and Sarah will be joining us.

Since sales numbers are looking strong, I'd like to add a strategy discussion to the agenda if that works for everyone.

Thanks!"
(NOTICE: Three paragraphs with proper breaks. First topic: meeting logistics. Second topic: strategy discussion request. Clean structure!)

================================================================================

EXAMPLE 7 - APOLOGETIC MESSAGE:
ORIGINAL: "sorry cant make it today something came up will reschedule"

POLISH: "Sorry, can't make it today. Something came up. Will reschedule."
(Objective fixes only)

BALANCED: "Sorry, I can't make it today. Something urgent came up.

I'll reschedule as soon as possible."
(Better structure and commitment)

REFRAME: "Hi,

I apologize, but I need to cancel our meeting today due to an unexpected situation.

I'll reach out shortly to reschedule at a time that works for you.

Thanks for understanding."
(Two separate ideas = paragraph break. First: apology and cancellation. Second: action plan.)

================================================================================

EXAMPLE 8 - LONGER EMAIL WITH MULTIPLE UPDATES (NEEDS MULTIPLE BREAKS):
ORIGINAL: "project running behind schedule vendor issues plus budget constraints team is working overtime to catch up will update u next week also need to discuss mitigation plan can we meet friday"

POLISH: "Project running behind schedule. Vendor issues plus budget constraints. Team is working overtime to catch up. Will update you next week. Also need to discuss mitigation plan. Can we meet Friday?"
(Objective fixes only)

BALANCED: "The project is running behind schedule due to vendor issues and budget constraints. The team is working overtime to catch up.

I'll update you next week. We also need to discuss the mitigation plan ‚Äî can we meet Friday?"
(Improved flow with natural paragraph break)

REFRAME: "Hi,

Quick update on the project: we're running behind schedule due to vendor issues and budget constraints. The team is working overtime to get us back on track.

I'll send you a detailed update next week. In the meantime, I'd like to discuss our mitigation plan ‚Äî are you available to meet on Friday?

Thanks!"
(NOTICE: Three clear paragraphs. 1) Problem statement. 2) Timeline and request. Each topic gets its own paragraph. Clean and scannable!)

================================================================================

EXAMPLE 9 - REPLY WITH QUOTED TEXT:
ORIGINAL:
Hi ‚Äî saw your notes below:
> The delivery is delayed by 3 days
can you confirm?
thx
‚ÄîR

POLISH:
Hi ‚Äî saw your notes below:
> The delivery is delayed by 3 days
Can you confirm?
Thx
‚ÄîR
(Fixed punctuation/caps; quoted text & signature preserved)

BALANCED:
Hi,

I saw your notes below:

> The delivery is delayed by 3 days

Can you please confirm this delay?

Thanks,
R
(Improved readability; preserved quoted text and signature)

REFRAME:
Hi,

Thanks for the update. I see the delivery is delayed by three days.

Could you confirm if this timeline is final and let me know if it impacts our schedule?

Thanks,
R
(Natural rewrite with proper paragraph breaks. Signature preserved. Clean structure.)

================================================================================

EXAMPLE 10 - FOUR DISTINCT REQUESTS (BULLETS + PARAGRAPH BREAKS):
ORIGINAL: "for monday launch need final slides q3 data design files and legal approval pls help"

POLISH: "For Monday launch, need final slides, Q3 data, design files, and legal approval. Pls help."
(Basic fixes)

BALANCED: "For the Monday launch, I need the final slides, Q3 data, design files, and legal approval.

Could you help with these?"
(Improved flow and courtesy)

REFRAME: "Hi,

I'm preparing for Monday's launch and need help gathering these items:

1. Final slide deck
2. Q3 data
3. Design files
4. Legal approval

Could you assist with coordinating these? Time-sensitive given the Monday deadline.

Thanks!"
(Notice clean spacing: greeting, context sentence, blank line, numbered list, blank line, follow-up question, blank line, closing. Very scannable!)

================================================================================
"""

        # Build mode-specific prompt
        if blend_ratio <= 0.3:  # Polish mode
            enhancement_prompt = f"""{comparison_table}

YOU ARE IN POLISH MODE (Minimal Changes - objective fixes only)

Original email to polish: {email_text}

Context:
- Recipients: {', '.join(context.get('recipients', ['Unknown'])[:3]) if context.get('recipients') else 'Unknown'}
- Subject: {context.get('subject', 'No subject')}

STRICT POLISH MODE RULES:
1. ONLY fix objective errors (spelling, grammar, punctuation, capitalization).
2. DO NOT restructure sentences or change wording.
3. DO NOT add or remove content, greetings, signatures, quoted text, or bullet structure.
4. DO NOT change tone or formality level.
5. Keep contractions exactly as they are.
6. Preserve quoted text (lines starting with '>') and signature blocks verbatim.

Output only the polished email, nothing else."""

        elif blend_ratio <= 0.6:  # Balanced mode
            enhancement_prompt = f"""{comparison_table}

YOU ARE IN BALANCED MODE (Context-Preserving Enhancement - Improve but preserve voice)

Original email to enhance: {email_text}

Context:
- Recipients: {', '.join(context.get('recipients', ['Unknown'])[:3]) if context.get('recipients') else 'Unknown'}
- Subject: {context.get('subject', 'No subject')}
- Is Reply: {context.get('isReply', False)}

BALANCED MODE PHILOSOPHY:
This mode improves clarity and readability while preserving the original voice, tone, and context. It's the middle ground between minimal fixes (Polish) and professional rewrite (Reframe). Best for: reply emails, team communication, casual but clear messages.

CRITICAL BALANCED MODE RULES:

1. PRESERVE TONE MARKERS (Keep the personality):
   - Keep casual greetings: "Hey" stays "Hey", "Yo" ‚Üí "Hey", "Hi all" stays "Hi all"
   - Keep original closing style or lack thereof
   - If original has no greeting, don't add one
   - If original has no closing, don't add one
   - Maintain energy level: excited stays excited, neutral stays neutral
   - Keep exclamation points if they express enthusiasm

2. MINIMAL RESTRUCTURING (Improve, don't rebuild):
   - Fix grammar, spelling, punctuation
   - Break up run-on sentences naturally
   - Add paragraph breaks only for readability (not aggressive formatting)
   - Don't reorganize content order
   - Don't add bullet points unless original had them
   - Keep conversational flow intact

3. REPLY-AWARE (Context matters):
   - Short replies should stay short
   - Don't add formal greetings to quick replies
   - Match the conversational style of email threads
   - Preserve back-and-forth casual tone

4. VOICE PRESERVATION:
   - Keep contractions if original used them casually ("let's", "we'll", "I'm")
   - Don't over-formalize internal team communication
   - Preserve personality and warmth
   - Casual can stay casual‚Äîjust clearer

5. WHAT TO IMPROVE:
   - Fix all errors (typos, grammar, spelling)
   - Clarify ambiguous phrasing
   - Add paragraph breaks for long blocks of text
   - Improve sentence flow without changing meaning
   - Make it more readable without making it stuffy

6. WHAT NOT TO DO:
   - DON'T change greeting style (Hey stays Hey, no greeting stays no greeting)
   - DON'T add closings unless original had one
   - DON'T make it overly formal or corporate
   - DON'T add content not in the original
   - DON'T restructure heavily
   - DON'T change from casual to professional tone

7. PRESERVE CONTEXT:
   - Quoted text and signature blocks: verbatim
   - Email is a reply: keep it conversational and brief
   - Internal team email: keep casual and friendly
   - Thread context: match existing tone

EXAMPLES OF BALANCED MODE:

EXAMPLE 1 - CASUAL REPLY:
ORIGINAL: "hey john thx for update yeah lets go with option 2 makes sense can u send details to sarah"

BALANCED: "Hey John,

Thanks for the update. Yeah, let's go with option 2‚Äîmakes sense.

Can you send the details to Sarah?"

(NOTICE: Kept "Hey", kept "Yeah", no formal closing added, preserved casual tone while improving clarity)

EXAMPLE 2 - TEAM UPDATE:
ORIGINAL: "hey team quick update finished testing found couple bugs working on fixes should be done tomorrow"

BALANCED: "Hey team,

Quick update: I finished testing and found a couple of bugs. Working on fixes now‚Äîshould be done by tomorrow."

(NOTICE: Kept "Hey team", kept conversational, no formal closing, just clearer)

EXAMPLE 3 - INTERNAL EMAIL:
ORIGINAL: "fyi meeting moved to 3pm tomorrow also sarah joining lets discuss roadmap"

BALANCED: "FYI, meeting moved to 3pm tomorrow. Sarah will be joining us.

Let's discuss the roadmap then."

(NOTICE: No greeting added, no closing added, kept informal "FYI", just improved readability)

Output only the enhanced email, nothing else."""

        else:  # Reframe mode
            # Detect email type for context-aware conciseness
            email_lower = email_text.lower()

            # Sensitive topics (keep warmer tone, less aggressive conciseness)
            sensitive_keywords = ['sorry', 'apologize', 'apology', 'mistake', 'error', 'issue', 'problem',
                                'concerned', 'worried', 'disappointed', 'upset', 'cancel', 'delay',
                                'unable', 'cannot', 'cant', 'won\'t']
            is_sensitive = any(keyword in email_lower for keyword in sensitive_keywords)

            # Business/transactional (be more concise and direct)
            business_keywords = ['invoice', 'payment', 'amount', 'budget', 'quote', 'proposal',
                               'contract', 'agreement', 'deadline', 'report', 'data', 'numbers',
                               'ro', 'po', 'cr', 'approval', 'status', 'update']
            is_business = any(keyword in email_lower for keyword in business_keywords)

            # Currency detection (smart but safe - only add symbols if explicitly mentioned)
            has_indian_currency = any(word in email_lower for word in ['lakhs', 'lacs', 'crores', 'rupees', 'rs', '‚Çπ', 'inr'])
            has_us_currency = any(word in email_lower for word in ['dollars', '$', 'usd'])
            has_euro = any(word in email_lower for word in ['euros', '‚Ç¨', 'eur'])
            has_gbp = any(word in email_lower for word in ['pounds', '¬£', 'gbp'])

            # Adjust temperature based on email type
            if is_business:
                temperature = 0.3  # More consistent for business emails

            # Build context-aware conciseness instruction
            if is_sensitive:
                conciseness_rule = """
2. CONCISENESS: Use clear but empathetic phrasing (this is a sensitive topic)
   - Keep apologetic/empathetic language warm ("I apologize" not just "Sorry")
   - Only apologize when YOU directly caused a problem affecting the recipient
   - Don't apologize for internal process issues or neutral status updates
   - Avoid being overly blunt
   - Balance directness with consideration"""
            elif is_business:
                conciseness_rule = """
2. CONCISENESS & DIRECTNESS: Be AGGRESSIVELY concise (business/transactional email)

   REMOVE CORPORATE FLUFF:
   - ‚ùå "I hope this email finds you well" ‚Üí ‚úÖ Remove entirely
   - ‚ùå "I hope you're doing well" ‚Üí ‚úÖ Remove entirely
   - ‚ùå "I'm reaching out regarding" ‚Üí ‚úÖ "This is regarding"
   - ‚ùå "I wanted to reach out about" ‚Üí ‚úÖ "Quick update on"
   - ‚ùå "I was wondering if you might be able to" ‚Üí ‚úÖ "Could you"
   - ‚ùå "at your earliest convenience" ‚Üí ‚úÖ "when possible" or remove
   - ‚ùå "if that would be possible for you" ‚Üí ‚úÖ Remove

   USE ACTIVE VOICE:
   - ‚ùå "errors were made" ‚Üí ‚úÖ "we made errors" or "I found errors"
   - ‚ùå "the report was completed" ‚Üí ‚úÖ "the team completed the report"
   - ‚ùå "corrections need to be implemented" ‚Üí ‚úÖ "we need to correct these"
   - ‚ùå "it was discovered that" ‚Üí ‚úÖ "I discovered" or "we found"

   DON'T OVER-APOLOGIZE:
   - Only apologize when YOU caused a problem directly affecting the recipient
   - ‚ùå "Apologies for the oversight" (in status update) ‚Üí ‚úÖ Remove
   - Status updates and internal issues don't need apologies

   BE DIRECT:
   - ‚ùå "it seems that" / "it appears" ‚Üí ‚úÖ Direct statement
   - ‚ùå "the amount that was put in while uploading was" ‚Üí ‚úÖ "the uploaded amount was"
   - Cut ALL unnecessary words - be ruthlessly concise"""
            else:
                conciseness_rule = """
2. CONCISENESS: Use natural, moderately concise phrasing
   - Avoid overly wordy constructions
   - Keep it professional but conversational
   - Don't sacrifice warmth for brevity"""

            # Build currency instruction based on detection
            currency_instruction = ""
            if has_us_currency:
                currency_instruction = """

CRITICAL - US CURRENCY DETECTED:
- MUST use $ symbol (NOT ‚Çπ, ‚Ç¨, or ¬£)
- Example: $50,000 NOT ‚Çπ50,000
- Format: $25,000 with standard US comma placement"""
            elif has_indian_currency:
                currency_instruction = """

CRITICAL - INDIAN CURRENCY DETECTED:
- MUST use ‚Çπ symbol (NOT $, ‚Ç¨, or ¬£)
- Example: ‚Çπ1,71,000 or ‚Çπ17,10,000
- Format large numbers with proper comma placement"""
            elif has_euro:
                currency_instruction = """

CRITICAL - EURO CURRENCY DETECTED:
- MUST use ‚Ç¨ symbol (NOT $, ‚Çπ, or ¬£)
- Example: ‚Ç¨25,000"""
            elif has_gbp:
                currency_instruction = """

CRITICAL - BRITISH CURRENCY DETECTED:
- MUST use ¬£ symbol (NOT $, ‚Çπ, or ‚Ç¨)
- Example: ¬£25,000"""
            else:
                # No clear currency detected - be conservative
                currency_instruction = """

NOTE: No clear currency detected:
- Keep original number format
- Don't add currency symbols unless explicitly mentioned in original
- Format numbers clearly with commas for readability"""

            enhancement_prompt = f"""{comparison_table}

YOU ARE IN REFRAME MODE (Natural Professional Rewrite - Context-Aware with Clean Paragraph Structure)

Original email to rewrite: {email_text}

Context:
- Recipients: {', '.join(context.get('recipients', ['Unknown'])[:3]) if context.get('recipients') else 'Unknown'}
- Subject: {context.get('subject', 'No subject')}
- Is Reply: {context.get('isReply', False)}
- Email Type Detected: {'Sensitive/Apology' if is_sensitive else 'Business/Transactional' if is_business else 'General'}

CRITICAL REFRAME RULES (Follow These Exactly):

1. TONE: Professionally friendly, NOT corporate formal

{conciseness_rule}{currency_instruction}

3. GREETING: Always add a greeting (Hi, Hello, Hi [Name]) - even for short emails

4. PARAGRAPH BREAKS (CRITICAL - Follow This Structure):
   ‚úì Always add blank line after greeting
   ‚úì If body has 2+ sentences covering different sub-topics ‚Üí add paragraph break between topics
   ‚úì If body has 3+ sentences total ‚Üí break after every 1-2 sentences for readability
   ‚úì Always add blank line before closing

   STUDY THIS EXAMPLE:
   ‚ùå BAD (Everything cramped):
   "Hi, Just a quick update ‚Äî I've completed the analysis, and the findings are looking promising. The document is already shared in Drive, and the team has been notified. Cheers!"

   ‚úÖ GOOD (Clean paragraph structure):
   "Hi,

   Just a quick update ‚Äî I've completed the analysis, and the findings are looking promising.

   The document is already shared in Drive, and the team has been notified.

   Cheers!"

5. STRUCTURE: Adapt to email type intelligently
   - 1-2 sentence acknowledgments ‚Üí Keep brief but with proper spacing
   - Simple requests (1-2 items) ‚Üí Natural prose with paragraph breaks if multiple topics
   - Complex requests (3+ distinct items) ‚Üí Use numbered lists with proper spacing
   - Status updates ‚Üí Natural paragraphs with breaks between different updates

6. BULLETS: Use ONLY when there are 3+ distinct action items or deliverables
   - ‚ùå "Review the deck and send feedback" ‚Üí Keep as prose (it's one request)
   - ‚ùå "Send report and budget numbers" ‚Üí Keep as prose (only 2 items)
   - ‚úÖ "Need slides, Q3 data, design files, and approval" ‚Üí Use numbered list (4 items)

7. CLOSINGS: Add naturally based on intent
   - ADD: When making requests, apologizing, announcing delays, asking for help
   - SKIP: For pure FYIs or simple informational updates without requests
   - Keep closings natural: "Thanks!", "Thanks for your help", "Appreciate it"

8. NEVER invent facts or add content not in the original
9. NEVER add "Subject:" lines - output only the email body starting with greeting
10. ALWAYS preserve signature blocks verbatim at the end

Study the REFRAME examples above carefully - notice the clean paragraph breaks and spacing patterns.

Output only the rewritten email body with proper paragraph breaks, nothing else."""

        response = client.chat.completions.create(
            model="chatgpt-4o-latest",
            messages=[
                {
                    "role": "system",
                    "content": f"You are an email enhancement expert. You MUST follow the {mode.upper()} mode rules exactly. For REFRAME mode: aggressively cut fluff for business emails, use active voice, don't over-apologize, use natural prose as default, add bullets ONLY for 3+ distinct items, maintain professionally friendly tone (not corporate formal), always add greeting, use smart paragraph breaks for clean structure (blank line after greeting, break between different topics, blank line before closing), preserve signatures verbatim. Study all examples to understand the required approach."
                },
                {
                    "role": "user",
                    "content": enhancement_prompt
                }
            ],
            temperature=temperature,
            max_tokens=600
        )

        enhanced_email = response.choices[0].message.content.strip()

        # Clean up any accidental meta text or subject lines
        if enhanced_email.startswith("Enhanced email:"):
            enhanced_email = enhanced_email.replace("Enhanced email:", "").strip()
        if enhanced_email.startswith("Here's"):
            lines = enhanced_email.split('\n')
            enhanced_email = '\n'.join(lines[1:]).strip()
        if "Output:" in enhanced_email:
            enhanced_email = enhanced_email.split("Output:")[-1].strip()

        # Remove any subject line if accidentally added
        if enhanced_email.startswith("Subject:"):
            lines = enhanced_email.split('\n')
            for i, line in enumerate(lines):
                if line and not line.startswith("Subject:"):
                    enhanced_email = '\n'.join(lines[i:]).strip()
                    break

        result = {
            'success': True,
            'email': enhanced_email,
            'status': 'success',
            'platform': 'gmail',
            'original_length': len(email_text),
            'enhanced_length': len(enhanced_email),
            'metadata': {
                'mode': mode,
                'blend_ratio': blend_ratio,
                'temperature': temperature,
                'is_reply': context.get('isReply', False),
                'recipient_count': len(context.get('recipients', [])),
                'auto_tone_detection': True,
                'formatting_applied': True
            }
        }

        if credit_result.get('credits_used'):
            result['credits_used'] = credit_result['credits_used']
            result['credits_remaining'] = credit_result.get('remaining')

        print(f"‚úÖ Gmail {mode} enhancement complete - {len(email_text)} ‚Üí {len(enhanced_email)} chars")
        return jsonify(result)

    except Exception as e:
        print(f"‚ùå Gmail enhancement error: {e}")
        return jsonify({
            'error': 'Failed to enhance email',
            'details': str(e)
        }), 500

@app.route('/gmail-enhance-friendly', methods=['POST'])
def gmail_enhance_friendly():
    """Friendly tone - casual, conversational, relaxed"""
    try:
        credit_result = optional_credit_check('gmail_enhance')
        if not credit_result['success']:
            return jsonify({'error': credit_result['message'], 'credits_required': 10}), 402

        data = request.get_json()
        email_text = data.get('text', '').strip()

        if not email_text:
            return jsonify({'error': 'Email text is required'}), 400

        enhancement_prompt = f"""Make this email friendly and conversational.

Original email: {email_text}

RULES:
- Fix only obvious errors
- Keep contractions (don't, won't, I'll)
- Keep casual phrases
- Add warmth without being overly enthusiastic
- Use "Thanks!" instead of "Thank you"
- Keep it natural and relaxed
- Don't make informal emails formal
- Preserve the casual vibe

Output only the polished email, nothing else."""

        response = client.chat.completions.create(
            model="gpt-5-chat-latest",
            messages=[
                {"role": "system", "content": "You make emails sound friendly and natural. Keep it casual."},
                {"role": "user", "content": enhancement_prompt}
            ],
            temperature=0.4,
            max_tokens=500
        )

        enhanced_email = response.choices[0].message.content.strip()

        return jsonify({
            'success': True,
            'email': enhanced_email,
            'tone': 'friendly'
        })

    except Exception as e:
        return jsonify({'error': 'Failed to enhance email', 'details': str(e)}), 500

@app.route('/gmail-enhance-formal', methods=['POST'])
def gmail_enhance_formal():
    """Formal tone - executive, professional, polished"""
    try:
        credit_result = optional_credit_check('gmail_enhance')
        if not credit_result['success']:
            return jsonify({'error': credit_result['message'], 'credits_required': 10}), 402

        data = request.get_json()
        email_text = data.get('text', '').strip()

        if not email_text:
            return jsonify({'error': 'Email text is required'}), 400

        enhancement_prompt = f"""Make this email formal and executive-appropriate.

Original email: {email_text}

RULES:
- NEVER add placeholder text like [Name], [Date], [Time], etc.
- Remove ALL contractions (use "do not" not "don't")
- Use formal vocabulary (utilize vs use, regarding vs about)
- Structure sentences properly
- Remove casual phrases and slang
- Use "Sincerely" or "Best regards" for closing
- Keep it crisp and professional
- Don't add unnecessary corporate jargon
- Maintain brevity
- Don't add anything extra from you side, unless and until it is required

Output only the polished email, nothing else."""

        response = client.chat.completions.create(
            model="gpt-5-chat-latest",
            messages=[
                {"role": "system", "content": "You create formal, executive-level emails. Be concise and professional."},
                {"role": "user", "content": enhancement_prompt}
            ],
            temperature=0.2,
            max_tokens=500
        )

        enhanced_email = response.choices[0].message.content.strip()

        return jsonify({
            'success': True,
            'email': enhanced_email,
            'tone': 'formal'
        })

    except Exception as e:
        return jsonify({'error': 'Failed to enhance email', 'details': str(e)}), 500

@app.route('/gmail-enhance-assertive', methods=['POST'])
def gmail_enhance_assertive():
    """Assertive tone - direct, confident, no-nonsense"""
    try:
        credit_result = optional_credit_check('gmail_enhance')
        if not credit_result['success']:
            return jsonify({'error': credit_result['message'], 'credits_required': 10}), 402

        data = request.get_json()
        email_text = data.get('text', '').strip()

        if not email_text:
            return jsonify({'error': 'Email text is required'}), 400

        enhancement_prompt = f"""Make this email direct and assertive.

Original email: {email_text}

RULES:
- Use strong, active verbs (will vs might, need vs would like)
- Remove hedging language (perhaps, maybe, possibly)
- Make requests clear expectations
- State deadlines directly
- Remove apologetic language unless necessary
- Keep sentences short and punchy
- Get to the point immediately
- Don't add softening phrases

Output only the polished email, nothing else."""

        response = client.chat.completions.create(
            model="gpt-5-chat-latest",
            messages=[
                {"role": "system", "content": "You create direct, assertive emails. Be confident and clear."},
                {"role": "user", "content": enhancement_prompt}
            ],
            temperature=0.3,
            max_tokens=500
        )

        enhanced_email = response.choices[0].message.content.strip()

        return jsonify({
            'success': True,
            'email': enhanced_email,
            'tone': 'assertive'
        })

    except Exception as e:
        return jsonify({'error': 'Failed to enhance email', 'details': str(e)}), 500

@app.route('/gmail-enhance-persuasive', methods=['POST'])
def gmail_enhance_persuasive():
    """Persuasive tone - compelling, benefit-focused, convincing"""
    try:
        credit_result = optional_credit_check('gmail_enhance')
        if not credit_result['success']:
            return jsonify({'error': credit_result['message'], 'credits_required': 10}), 402

        data = request.get_json()
        email_text = data.get('text', '').strip()

        if not email_text:
            return jsonify({'error': 'Email text is required'}), 400

        enhancement_prompt = f"""Make this email more persuasive and compelling while keeping the original meaning and facts exactly intact.

Original email: {email_text}

RULES:
- Keep all original facts and the core context unchanged
- Do not add placeholder text like [Name], [Date], [Time], etc.
- Reframe wording to emphasize benefits for the recipient (what's in it for them)
- Use recipient-focused ("you") language and a clear value-driven ask
- Strengthen clarity and impact with concise phrasing
- Only add a few short, natural sentences if needed to improve clarity, emphasize value, or provide urgency
- Do NOT introduce new topics or unrelated content
- Make the ask clear and attractive, but not forceful
- Avoid exaggeration, over-promising, or being overly salesy
- Keep the overall length close to the original unless the original is too short

Output only the polished, persuasive email, nothing else."""

        response = client.chat.completions.create(
            model="gpt-5-chat-latest",
            messages=[
                {"role": "system", "content": "You transform emails into persuasive, benefit-focused versions while preserving the original context and facts."},
                {"role": "user", "content": enhancement_prompt}
            ],
            temperature=0.4,
            max_tokens=500
        )

        enhanced_email = response.choices[0].message.content.strip()

        return jsonify({
            'success': True,
            'email': enhanced_email,
            'tone': 'persuasive'
        })

    except Exception as e:
        return jsonify({'error': 'Failed to enhance email', 'details': str(e)}), 500

@app.route('/gmail-enhance-urgent', methods=['POST'])
def gmail_enhance_urgent():
    """Urgent tone - time-sensitive, action-focused, clear deadlines"""
    try:
        credit_result = optional_credit_check('gmail_enhance')
        if not credit_result['success']:
            return jsonify({'error': credit_result['message'], 'credits_required': 10}), 402

        data = request.get_json()
        email_text = data.get('text', '').strip()

        if not email_text:
            return jsonify({'error': 'Email text is required'}), 400

        enhancement_prompt = f"""Make this email convey urgency effectively.

Original email: {email_text}

RULES:
- Highlight time sensitivity clearly
- Put deadlines upfront
- Use action verbs (need, require, must)
- Make next steps crystal clear
- Keep it brief - urgency means brevity
- Don't add panic, just clarity
- Structure: deadline ‚Üí action needed ‚Üí consequence
- Bold or emphasize dates if critical

Output only the polished email, nothing else."""

        response = client.chat.completions.create(
            model="gpt-5-chat-latest",
            messages=[
                {"role": "system", "content": "You create urgent emails that drive action without panic."},
                {"role": "user", "content": enhancement_prompt}
            ],
            temperature=0.3,
            max_tokens=500
        )

        enhanced_email = response.choices[0].message.content.strip()

        return jsonify({
            'success': True,
            'email': enhanced_email,
            'tone': 'urgent'
        })

    except Exception as e:
        return jsonify({'error': 'Failed to enhance email', 'details': str(e)}), 500

@app.route('/gmail-enhance-apologetic', methods=['POST'])
def gmail_enhance_apologetic():
    """Apologetic tone - diplomatic, taking responsibility, maintaining relationships"""
    try:
        credit_result = optional_credit_check('gmail_enhance')
        if not credit_result['success']:
            return jsonify({'error': credit_result['message'], 'credits_required': 10}), 402

        data = request.get_json()
        email_text = data.get('text', '').strip()

        if not email_text:
            return jsonify({'error': 'Email text is required'}), 400

        enhancement_prompt = f"""Make this email appropriately apologetic and diplomatic.

Original email: {email_text}

RULES:
- Include sincere apology without over-apologizing
- Take responsibility where appropriate
- Offer solutions or next steps
- Maintain professionalism
- Don't blame others
- Focus on moving forward
- Keep dignity while being sorry
- Acknowledge impact on them

Output only the polished email, nothing else."""

        response = client.chat.completions.create(
            model="gpt-5-chat-latest",
            messages=[
                {"role": "system", "content": "You create diplomatic apologies that maintain relationships."},
                {"role": "user", "content": enhancement_prompt}
            ],
            temperature=0.3,
            max_tokens=500
        )

        enhanced_email = response.choices[0].message.content.strip()

        return jsonify({
            'success': True,
            'email': enhanced_email,
            'tone': 'apologetic'
        })

    except Exception as e:
        return jsonify({'error': 'Failed to enhance email', 'details': str(e)}), 500

@app.route('/gmail-enhance-informative', methods=['POST'])
def gmail_enhance_informative():
    """Informative tone - clear, structured, educational"""
    try:
        credit_result = optional_credit_check('gmail_enhance')
        if not credit_result['success']:
            return jsonify({'error': credit_result['message'], 'credits_required': 10}), 402

        data = request.get_json()
        email_text = data.get('text', '').strip()

        if not email_text:
            return jsonify({'error': 'Email text is required'}), 400

        enhancement_prompt = f"""Make this email clear and informative.

Original email: {email_text}

RULES:
- Structure information logically
- Use bullet points for lists
- Put key information first
- Use clear headers if needed
- Define any technical terms simply
- Make data/facts easy to scan
- Keep explanations concise
- End with clear next steps or summary

Output only the polished email, nothing else."""

        response = client.chat.completions.create(
            model="gpt-5-chat-latest",
            messages=[
                {"role": "system", "content": "You structure emails to be clear and informative."},
                {"role": "user", "content": enhancement_prompt}
            ],
            temperature=0.3,
            max_tokens=500
        )

        enhanced_email = response.choices[0].message.content.strip()

        return jsonify({
            'success': True,
            'email': enhanced_email,
            'tone': 'informative'
        })

    except Exception as e:
        return jsonify({'error': 'Failed to enhance email', 'details': str(e)}), 500

@app.route('/gmail-enhance-enthusiastic', methods=['POST'])
def gmail_enhance_enthusiastic():
    """Enthusiastic tone - positive, energetic, motivational"""
    try:
        credit_result = optional_credit_check('gmail_enhance')
        if not credit_result['success']:
            return jsonify({'error': credit_result['message'], 'credits_required': 10}), 402

        data = request.get_json()
        email_text = data.get('text', '').strip()

        if not email_text:
            return jsonify({'error': 'Email text is required'}), 400

        enhancement_prompt = f"""Make this email enthusiastic and positive.

Original email: {email_text}

RULES:
- Add energy without being unprofessional
- Use positive language
- Show genuine excitement where appropriate
- Use exclamation points sparingly (1-2 max)
- Focus on opportunities and positives
- Keep it authentic, not fake
- Celebrate achievements if mentioned
- Don't overdo it - professional enthusiasm

Output only the polished email, nothing else."""

        response = client.chat.completions.create(
            model="gpt-5-chat-latest",
            messages=[
                {"role": "system", "content": "You add appropriate enthusiasm and positivity to emails."},
                {"role": "user", "content": enhancement_prompt}
            ],
            temperature=0.4,
            max_tokens=500
        )

        enhanced_email = response.choices[0].message.content.strip()

        return jsonify({
            'success': True,
            'email': enhanced_email,
            'tone': 'enthusiastic'
        })

    except Exception as e:
        return jsonify({'error': 'Failed to enhance email', 'details': str(e)}), 500

@app.route('/gmail-enhance-custom', methods=['POST'])
def gmail_enhance_custom():
    """Gmail email enhancement with custom user instructions"""
    try:
        # Credit check - 15 credits for custom Gmail enhancement
        credit_result = optional_credit_check('gmail_enhance')
        if not credit_result['success']:
            return jsonify({
                'error': credit_result['message'],
                'credits_required': 15  # Custom enhancement costs 15 credits
            }), 402

        data = request.get_json()
        email_text = data.get('text', '').strip()
        context = data.get('context', {})
        custom_prompt = data.get('customPrompt', '').strip()

        if not email_text:
            return jsonify({'error': 'Email text is required'}), 400

        if not custom_prompt:
            return jsonify({'error': 'Custom prompt is required'}), 400

        print(f"üéØ Custom Gmail enhancement for: {email_text[:50]}...")
        print(f"üéØ Custom instruction: {custom_prompt}")
        print(f"üìß Context: Reply={context.get('isReply')}, Recipients={len(context.get('recipients', []))}")

        # Build custom enhancement prompt
        enhancement_prompt = f"""You are an expert email communication specialist who helps enhance emails based on custom user instructions.

CRITICAL RULES:
1. NEVER add placeholder text like [Name], [Date], [Time], etc.
2. KEEP all actual names, details, and specifics the user already wrote
3. Apply the user's custom instruction while preserving the core message
4. Don't add information that wasn't implied in the original email

Original email:
{email_text}

Email context:
- Is this a reply? {context.get('isReply', False)}
- Subject line: {context.get('subject', 'No subject')}
- Formal context: {context.get('isFormal', False)}
- Recipients: {', '.join(context.get('recipients', ['Unknown'])[:3]) if context.get('recipients') else 'Unknown'}

USER'S CUSTOM INSTRUCTION:
{custom_prompt}

YOUR TASK:

1. APPLY the user's custom instruction to the email
2. PRESERVE the core message and all specific details
3. MAINTAIN the original facts, names, dates, and context
4. ENHANCE according to the instruction while keeping it natural

WHAT TO DO:
‚úÖ Apply the custom instruction faithfully
‚úÖ Keep all actual names and details
‚úÖ Preserve the email's purpose
‚úÖ Make natural improvements that align with the instruction
‚úÖ Fix grammar if needed (unless instruction says otherwise)

WHAT NOT TO DO:
‚ùå Don't add placeholder text like [Name], [Date], etc.
‚ùå Don't add greetings if instruction doesn't require them
‚ùå Don't add information not in the original
‚ùå Don't change the meaning unless instruction explicitly requires it
‚ùå Don't ignore the user's instruction
‚ùå Don't add signature blocks or quoted text

EXAMPLES:

Example 1:
Original: "hey can we meet tomorrow i have some ideas"
Instruction: "remove casual language"
Result: "Can we meet tomorrow? I have some ideas to discuss."

Example 2:
Original: "I need the reports by Friday. Thanks."
Instruction: "make it sound more urgent"
Result: "I urgently need the reports by Friday. This is time-sensitive, so please prioritize it. Thanks."

Example 3:
Original: "Sorry for the delay. Here are the files you requested."
Instruction: "remove apology"
Result: "Here are the files you requested."

Remember: Apply the user's instruction while preserving the original email's content and specifics.

Provide ONLY the enhanced email text - no explanations, no meta-commentary."""

        response = client.chat.completions.create(
            model="gpt-5-chat-latest",
            messages=[
                {
                    "role": "system",
                    "content": "You are an email enhancement expert who applies custom user instructions to emails. Always preserve actual details and never add placeholder text. Follow the user's instruction precisely."
                },
                {
                    "role": "user",
                    "content": enhancement_prompt
                }
            ],
            temperature=0.4,
            max_tokens=800
        )

        enhanced_email = response.choices[0].message.content.strip()

        # Clean up any meta text if accidentally included
        if enhanced_email.startswith("Enhanced email:"):
            enhanced_email = enhanced_email.replace("Enhanced email:", "").strip()
        if enhanced_email.startswith("Result:"):
            enhanced_email = enhanced_email.replace("Result:", "").strip()
        if enhanced_email.startswith("Here's"):
            lines = enhanced_email.split('\n')
            enhanced_email = '\n'.join(lines[1:]).strip()

        result = {
            'success': True,
            'email': enhanced_email,
            'status': 'success',
            'platform': 'gmail',
            'original_length': len(email_text),
            'enhanced_length': len(enhanced_email),
            'metadata': {
                'mode': 'gmail_enhance_custom',
                'custom_instruction': custom_prompt,
                'is_reply': context.get('isReply', False),
                'recipient_count': len(context.get('recipients', []))
            }
        }

        if credit_result.get('credits_used'):
            result['credits_used'] = credit_result['credits_used']
            result['credits_remaining'] = credit_result.get('remaining')

        print(f"‚úÖ Custom Gmail enhancement complete - {len(email_text)} ‚Üí {len(enhanced_email)} chars")
        return jsonify(result)

    except Exception as e:
        print(f"‚ùå Custom Gmail enhancement error: {e}")
        return jsonify({
            'error': 'Failed to enhance email with custom instruction',
            'details': str(e)
        }), 500

@app.route('/ai-platform-custom', methods=['POST'])
def ai_platform_custom():
    """Enhance user prompts with custom instructions before sending to ChatGPT"""
    try:
        # Credit check - 15 credits for custom prompt enhancement
        credit_result = optional_credit_check('convert_custom')
        if not credit_result['success']:
            return jsonify({
                'error': credit_result['message'],
                'credits_required': 15
            }), 402

        data = request.get_json()
        original_prompt = data.get('text', '').strip()
        enhancement_instruction = data.get('customPrompt', '').strip()

        if not original_prompt:
            return jsonify({'error': 'Original prompt is required'}), 400

        if not enhancement_instruction:
            return jsonify({'error': 'Enhancement instruction is required'}), 400

        print(f"üéØ Enhancing prompt: {original_prompt[:50]}...")
        print(f"üìù Enhancement: {enhancement_instruction}")

        # Build the enhancement prompt - works exactly like ChatGPT
        system_prompt = """You are ChatGPT, helping a user refine their prompt. The user has written a prompt and wants to improve it based on a specific instruction.

Your task: Apply their enhancement instruction naturally to make the prompt better, just like you would in a normal conversation.

Rules:
- Understand what they're asking for and apply it naturally
- Keep their original intent and core request
- Be creative and thoughtful in how you enhance it
- Output ONLY the enhanced/refined prompt, nothing else
- Don't add meta-commentary or explanations"""

        user_prompt = f"""I have this prompt:
"{original_prompt}"

Can you refine it to: {enhancement_instruction}

Just give me the refined prompt, nothing else."""

        response = client.chat.completions.create(
            model="gpt-4o",  # Using latest GPT-4o for best results
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.7,  # Natural ChatGPT-like creativity
            max_tokens=2000   # Allow for comprehensive enhancements
        )

        enhanced_prompt = response.choices[0].message.content.strip()

        # Clean up any wrapper text
        prefixes_to_remove = [
            "Enhanced prompt:",
            "Here's the enhanced prompt:",
            "Result:",
            "Enhanced version:",
            "Improved prompt:"
        ]

        for prefix in prefixes_to_remove:
            if enhanced_prompt.startswith(prefix):
                enhanced_prompt = enhanced_prompt[len(prefix):].strip()

        # Remove quotes if the entire response is wrapped in them
        if (enhanced_prompt.startswith('"') and enhanced_prompt.endswith('"')) or \
           (enhanced_prompt.startswith("'") and enhanced_prompt.endswith("'")):
            enhanced_prompt = enhanced_prompt[1:-1].strip()

        result = {
            'success': True,
            'converted_prompt': enhanced_prompt,
            'status': 'success',
            'original_length': len(original_prompt),
            'converted_length': len(enhanced_prompt),
            'metadata': {
                'mode': 'custom_enhancement',
                'enhancement_instruction': enhancement_instruction,
                'improvement_ratio': round(len(enhanced_prompt) / len(original_prompt), 2)
            }
        }

        if credit_result.get('credits_used'):
            result['credits_used'] = credit_result['credits_used']
            result['credits_remaining'] = credit_result.get('remaining')

        print(f"‚úÖ Prompt enhanced: {len(original_prompt)} ‚Üí {len(enhanced_prompt)} chars")
        print(f"üìä Enhancement preview: {enhanced_prompt[:100]}...")

        return jsonify(result)

    except Exception as e:
        print(f"‚ùå Prompt enhancement error: {e}")
        import traceback
        traceback.print_exc()

        return jsonify({
            'error': 'Failed to enhance prompt',
            'details': str(e)
        }), 500

@app.route('/auto-smart-actions', methods=['POST'])
def auto_smart_actions():
    """Generate single smart action for auto-notification after AI responses"""
    try:
        logging.info("=== Auto smart actions request started ===")

        # ADD CREDIT CHECK
        credit_result = optional_credit_check('smart_actions')
        if not credit_result['success']:
            return jsonify({
                'error': credit_result['message'],
                'credits_required': get_feature_credits('smart_actions')
            }), 402

        # Parse request
        data = request.get_json(force=True)
        conversation = data.get('conversation', '').strip()
        platform = data.get('platform', 'unknown')

        logging.info(f"Auto-mode conversation length: {len(conversation)}, Platform: {platform}")

        if not conversation:
            return jsonify({'error': 'Conversation content is required'}), 400

        # Extract the last AI response, excluding follow-up questions
        last_ai_response = extract_last_ai_response(conversation)
        conversation_context = conversation[-3000:] if len(conversation) > 3000 else conversation

        # Check if the last response is just a follow-up question
        is_just_question = check_if_follow_up_question(last_ai_response)

        # If it's mainly a follow-up question, get more context
        if is_just_question:
            logging.info("Detected follow-up question, extracting more context")
            last_ai_response = extract_main_content_before_question(conversation)

        # Build enhanced auto-action prompt that avoids simple agreements
        auto_action_prompt = f"""
You are an expert at understanding conversations and suggesting PRACTICAL next actions.

CRITICAL RULE: The AI may have asked a follow-up question like "Would you like me to..." or "Should I also...".
DO NOT just say "yes" or agree to it. Instead, think about what the USER actually needs to accomplish.

CONVERSATION CONTEXT:
{conversation_context}

LAST AI RESPONSE (main content, not follow-up questions):
{last_ai_response}

Your task: Generate ONE practical, specific action that helps the user DO something concrete.

PRACTICAL ACTION PRINCIPLES:
1. Focus on DOING, not just discussing
2. Be specific about implementation details
3. Request concrete deliverables (code, examples, templates)
4. Ask for real-world applications
5. Seek optimization or improvement of what was discussed
6. Request validation, testing, or verification methods

AVOID THESE COMPLETELY:
‚úó Simply agreeing to AI's follow-up questions ("Yes, do that", "Sure, create that")
‚úó Vague requests ("tell me more", "explain further")
‚úó Theoretical discussions without practical application
‚úó Repeating what the AI already offered
‚úó Any response starting with "Yes," "Sure," "Okay," regarding the AI's question

GOOD EXAMPLES based on different contexts:
- If AI provided a solution ‚Üí "Show me how to integrate this with [specific technology/framework]"
- If AI explained a concept ‚Üí "Create a working example that I can run locally with error handling"
- If AI gave options ‚Üí "Build a comparison table with performance metrics and implementation complexity"
- If AI wrote code ‚Üí "Add unit tests for edge cases and a README with setup instructions"
- If AI created content ‚Üí "Convert this into a production-ready version with SEO optimization"
- If AI made a video script ‚Üí "Create a detailed shot list with camera angles and transition effects"
- If AI analyzed something ‚Üí "Generate an actionable checklist with priority levels and timelines"

SPECIFIC CONTEXT ANALYSIS:
- What concrete thing is the user trying to build/solve/create?
- What's the next PRACTICAL step they need?
- What specific technical detail would move them forward?
- What real-world application would help?
- What would make this production-ready?

FORMAT YOUR RESPONSE AS JSON:
{{
    "action_prompt": {{
        "prompt": "[Specific, practical action that leads to concrete output - NEVER just agreeing]",
        "focus": "implementation|testing|optimization|integration|deployment|validation|production",
        "deliverable": "[What concrete thing this will produce]",
        "value": "[How this moves the project/understanding forward]"
    }},
    "reasoning": "[Why this is more useful than just agreeing to the AI's question]",
    "practical_score": [0.0-1.0 how practical/actionable this is]
}}

Remember: The user should think "That's exactly what I need to make this real!" not "Why is it just agreeing?"."""

        # Use reliable models with optimized parameters
        models_to_try = [
            {
                "name": "chatgpt-4o-latest",
                "params": {
                    "temperature": 0.5,  # Higher for more creative practical suggestions
                    "max_tokens": 800,
                    "presence_penalty": 0.2,  # Encourage diverse suggestions
                    "frequency_penalty": 0.2
                }
            },
            {
                "name": "gpt-3.5-turbo",
                "params": {
                    "temperature": 0.5,
                    "max_tokens": 600,
                    "presence_penalty": 0.2,
                    "frequency_penalty": 0.2
                }
            }
        ]

        response = None
        model_used = None

        # Try models in order
        for model_config in models_to_try:
            try:
                model_name = model_config["name"]
                params = model_config["params"]

                logging.info(f"Trying auto-actions model: {model_name}")

                response = client.chat.completions.create(
                    model=model_name,
                    messages=[
                        {"role": "system", "content": "You are an expert at generating practical, actionable next steps that help users accomplish real tasks. Never just agree with AI follow-up questions - always suggest something that adds real value."},
                        {"role": "user", "content": auto_action_prompt}
                    ],
                    **params
                )

                model_used = model_name
                logging.info(f"Successfully used auto-actions model: {model_name}")
                break

            except Exception as e:
                error_msg = str(e)
                logging.warning(f"Auto-actions model {model_name} failed: {error_msg}")
                continue

        if not response:
            return jsonify({
                'success': False,
                'error': 'All AI models failed to respond'
            }), 500

        # Parse response
        ai_response = response.choices[0].message.content.strip()
        logging.info(f"Auto-actions AI Response length: {len(ai_response)}")

        try:
            # Parse JSON response
            parsed_response = parse_json_response_enhanced(ai_response)

            # Extract and validate action prompt
            action_prompt = parsed_response.get('action_prompt', {})

            if not isinstance(action_prompt, dict) or 'prompt' not in action_prompt:
                raise ValueError("No valid action prompt found")

            prompt_text = action_prompt.get('prompt', '').strip()

            # Validate it's not just agreeing with a question
            if is_simple_agreement(prompt_text):
                logging.info("Detected simple agreement, generating better action")
                prompt_text = generate_better_practical_action(last_ai_response, conversation_context, platform)
                action_prompt = {
                    "prompt": prompt_text,
                    "focus": "implementation",
                    "deliverable": "concrete implementation",
                    "value": "practical progress"
                }

            if not prompt_text or len(prompt_text) < 20:
                raise ValueError("Action prompt too short or empty")

            # Calculate quality score with practical focus
            practical_score = parsed_response.get('practical_score', 0.7)
            confidence = parsed_response.get('confidence', practical_score)
            quality_score = calculate_practical_action_quality(prompt_text, last_ai_response, practical_score)

            # Only use high-quality suggestions
            if quality_score < 0.5:
                logging.info(f"Low quality score ({quality_score}), using contextual fallback")
                prompt_text = generate_better_practical_action(last_ai_response, conversation_context, platform)
                action_prompt = {
                    "prompt": prompt_text,
                    "focus": "practical_application",
                    "deliverable": "actionable output",
                    "value": "concrete progress"
                }

            result = {
                'success': True,
                'action': {
                    "prompt": prompt_text,
                    "focus": action_prompt.get('focus', 'implementation'),
                    "deliverable": action_prompt.get('deliverable', 'concrete output'),
                    "value": action_prompt.get('value', 'practical advancement')
                },
                'reasoning': parsed_response.get('reasoning', 'Practical next step for real progress'),
                'platform': platform,
                'model': model_used,
                'auto_mode': True,
                'quality_score': quality_score,
                'practical_score': practical_score
            }

            if credit_result.get('credits_used'):
                result['credits_used'] = credit_result['credits_used']
                result['credits_remaining'] = credit_result.get('remaining')

            logging.info(f"‚úÖ Practical auto action generated (score: {quality_score:.2f}): {prompt_text[:50]}...")
            return jsonify(result)

        except (json.JSONDecodeError, ValueError) as e:
            logging.error(f"Auto-actions JSON parsing failed: {str(e)}")

            # Generate intelligent contextual fallback
            fallback_prompt = generate_better_practical_action(last_ai_response, conversation_context, platform)

            fallback_action = {
                "prompt": fallback_prompt,
                "focus": "practical_implementation",
                "deliverable": "concrete result",
                "value": "actionable progress"
            }

            result = {
                'success': True,
                'action': fallback_action,
                'reasoning': 'Practical action generated from context analysis',
                'platform': platform,
                'model': model_used,
                'auto_mode': True,
                'fallback': True
            }

            if credit_result.get('credits_used'):
                result['credits_used'] = credit_result['credits_used']
                result['credits_remaining'] = credit_result.get('remaining')

            return jsonify(result)

    except Exception as e:
        error_msg = str(e)
        error_type = type(e).__name__

        logging.error(f"=== Auto smart actions error ===")
        logging.error(f"Error type: {error_type}")
        logging.error(f"Error message: {error_msg}")

        return jsonify({
            'success': False,
            'error': 'Failed to generate auto action',
            'details': error_msg[:200],
            'error_type': error_type
        }), 500


def extract_last_ai_response(conversation):
    """Extract the last AI response from the conversation, excluding follow-up questions"""
    lines = conversation.split('\n')
    ai_response = []
    capturing = False

    # Patterns that indicate follow-up questions
    follow_up_patterns = [
        'would you like', 'do you want', 'should i also', 'shall i',
        'would you prefer', 'interested in', 'need help with', 'want me to',
        'can i help', 'anything else', 'what else', 'additionally',
        'would that be helpful', 'is there anything specific'
    ]

    # Reverse iterate to find the last AI response
    for i in range(len(lines) - 1, -1, -1):
        line = lines[i].strip()

        # Skip empty lines
        if not line:
            continue

        # Check if this line looks like a follow-up question
        line_lower = line.lower()
        is_follow_up = any(pattern in line_lower for pattern in follow_up_patterns) and '?' in line

        # Check for AI response markers
        if any(marker in line_lower for marker in ['assistant:', 'ai:', 'bot:', 'claude:', 'chatgpt:', 'gemini:']):
            if ai_response and not is_follow_up:  # We've captured content, this is the start marker
                break
            capturing = True
            continue

        # Check for user markers (stop capturing)
        if any(marker in line_lower for marker in ['user:', 'human:', 'you:', 'me:']):
            if ai_response:  # We've found the end of AI response
                break

        if capturing or (not capturing and i > len(lines) - 10):  # Capture last ~10 lines if no markers
            if line and not is_follow_up:  # Only add non-empty, non-follow-up lines
                ai_response.insert(0, line)

    # Join and return the response
    result = '\n'.join(ai_response)

    # If result is too short or mostly questions, get more context
    if len(result) < 200 or result.count('?') > 3:
        # Try to get more substantial content from earlier in conversation
        return extract_main_content_before_question(conversation)

    return result[-1500:] if len(result) > 1500 else result


def extract_main_content_before_question(conversation):
    """Extract the main AI response content before any follow-up questions"""
    # Split conversation into chunks and find substantial content
    chunks = conversation.split('\n\n')

    # Look for the last substantial chunk that's not a question
    for i in range(len(chunks) - 1, -1, -1):
        chunk = chunks[i].strip()
        if len(chunk) > 200 and chunk.count('?') < 2:
            # This looks like substantial content
            return chunk[-1500:]

    # Fallback: get the middle portion of the conversation (avoiding questions at the end)
    if len(conversation) > 2000:
        return conversation[-2500:-500]
    else:
        return conversation[:-300] if len(conversation) > 300 else conversation


def check_if_follow_up_question(text):
    """Check if the text is primarily a follow-up question"""
    if not text:
        return False

    text_lower = text.lower()

    # Common follow-up question patterns
    follow_up_indicators = [
        'would you like me to',
        'should i also',
        'do you want me to',
        'shall i create',
        'would you prefer',
        'can i help you with',
        'interested in seeing',
        'would that be helpful',
        'anything else you'
    ]

    # Check if text is mainly a question
    question_ratio = text.count('?') / max(len(text.split('\n')), 1)
    has_follow_up = any(indicator in text_lower for indicator in follow_up_indicators)

    return question_ratio > 0.3 or has_follow_up


def is_simple_agreement(prompt_text):
    """Check if the prompt is just a simple agreement"""
    if not prompt_text:
        return False

    lower_prompt = prompt_text.lower().strip()

    # Simple agreement patterns
    agreement_starters = [
        'yes,', 'yes ', 'yes.', 'sure,', 'sure ', 'okay,', 'ok,',
        'great,', 'perfect,', 'excellent,', 'definitely,', 'absolutely,',
        "yes, let's", "yes let's", "sure, let's", "okay, let's"
    ]

    return any(lower_prompt.startswith(starter) for starter in agreement_starters)


def calculate_practical_action_quality(prompt_text, last_response, practical_score):
    """Calculate quality score for the generated action with practical focus"""
    score = practical_score

    # Check for action-oriented language (boost score)
    action_words = [
        'create', 'build', 'implement', 'test', 'add', 'modify', 'generate',
        'develop', 'write', 'design', 'integrate', 'optimize', 'validate',
        'deploy', 'configure', 'setup', 'analyze', 'convert', 'transform'
    ]
    if any(word in prompt_text.lower() for word in action_words):
        score += 0.15

    # Check for specificity (boost score)
    specific_indicators = ['with', 'using', 'including', 'for', 'based on', 'that']
    if any(indicator in prompt_text.lower() for indicator in specific_indicators):
        score += 0.1

    # Check for concrete deliverables (boost score)
    deliverable_words = [
        'example', 'template', 'script', 'code', 'implementation', 'version',
        'prototype', 'demo', 'test', 'documentation', 'guide', 'checklist'
    ]
    if any(word in prompt_text.lower() for word in deliverable_words):
        score += 0.1

    # Penalize generic or agreement-based responses
    generic_phrases = [
        'tell me more', 'anything else', 'what else', 'continue', 'go on',
        'yes,', 'sure,', 'okay,', 'explain more', 'describe'
    ]
    if any(phrase in prompt_text.lower() for phrase in generic_phrases):
        score -= 0.4

    # Check for appropriate length (not too short, not too long)
    word_count = len(prompt_text.split())
    if 15 <= word_count <= 60:
        score += 0.1
    elif word_count < 10 or word_count > 100:
        score -= 0.2

    # Ensure score is between 0 and 1
    return max(0.0, min(1.0, score))


def generate_better_practical_action(last_response, conversation, platform=None):
    """Generate better practical actions instead of just agreeing"""

    last_response_lower = last_response.lower() if last_response else conversation[-500:].lower()

    # Platform-specific or content-specific practical actions
    if 'code' in last_response_lower or '```' in last_response_lower or 'function' in last_response_lower:
        actions = [
            "Create a complete working example with error handling, input validation, and comments that I can run immediately",
            "Show me how to integrate this code with a REST API backend and PostgreSQL database",
            "Build a comprehensive test suite with unit tests, edge cases, and performance benchmarks",
            "Refactor this for production use with proper logging, configuration management, and Docker deployment",
            "Add TypeScript types, JSDoc comments, and create a CI/CD pipeline configuration"
        ]
    elif 'video' in last_response_lower or 'content' in last_response_lower or 'script' in last_response_lower:
        actions = [
            "Create a detailed shot list with timestamps, camera angles, transitions, and visual effects descriptions",
            "Generate 5 alternative hooks for the first 3 seconds with psychological triggers and A/B testing metrics",
            "Build a complete production checklist with equipment specs, location requirements, and crew assignments",
            "Write platform-specific variations optimized for TikTok (9:16), Instagram Reels, and YouTube Shorts with hashtags",
            "Design a storyboard with keyframes, motion graphics, and audio cue markers"
        ]
    elif 'design' in last_response_lower or 'ui' in last_response_lower or 'interface' in last_response_lower:
        actions = [
            "Create a complete Figma component library with all states, variants, and auto-layout configurations",
            "Build an interactive HTML/CSS/JS prototype with micro-animations and state management",
            "Generate a comprehensive accessibility audit with WCAG 2.1 AA compliance checklist and fixes",
            "Design a complete mobile-first responsive system with breakpoints, grid layouts, and touch interactions",
            "Create a design system documentation with tokens, usage guidelines, and code snippets"
        ]
    elif 'data' in last_response_lower or 'analysis' in last_response_lower or 'metrics' in last_response_lower:
        actions = [
            "Create a Python script with pandas and plotly to automate this analysis with real-time data updates",
            "Build an interactive dashboard mockup with drill-down capabilities, filters, and export functions",
            "Generate optimized SQL queries with indexes, CTEs, and performance explain plans",
            "Develop a complete monitoring system with Prometheus metrics, Grafana dashboards, and alert rules",
            "Create a Jupyter notebook with statistical analysis, visualizations, and machine learning predictions"
        ]
    elif 'strategy' in last_response_lower or 'plan' in last_response_lower or 'approach' in last_response_lower:
        actions = [
            "Create a detailed Gantt chart with milestones, dependencies, critical path, and resource allocation",
            "Build a comprehensive risk assessment matrix with probability scores, impact analysis, and mitigation plans",
            "Generate a complete business case with ROI calculations, cost-benefit analysis, and sensitivity models",
            "Develop OKRs with specific metrics, tracking methodology, and quarterly review templates",
            "Create a stakeholder communication plan with RACI matrix and escalation procedures"
        ]
    elif 'api' in last_response_lower or 'integration' in last_response_lower or 'backend' in last_response_lower:
        actions = [
            "Create a complete REST API implementation with authentication, rate limiting, and OpenAPI documentation",
            "Build a GraphQL schema with resolvers, subscriptions, and DataLoader optimization",
            "Generate Postman collection with test scripts, environment variables, and automated testing",
            "Implement webhook handlers with retry logic, signature verification, and event queuing",
            "Create a microservices architecture diagram with service mesh, API gateway, and monitoring setup"
        ]
    elif 'database' in last_response_lower or 'sql' in last_response_lower or 'query' in last_response_lower:
        actions = [
            "Create optimized database schema with indexes, constraints, triggers, and migration scripts",
            "Build a complete data access layer with repository pattern, caching, and connection pooling",
            "Generate database performance tuning report with query optimization and index recommendations",
            "Implement database backup and recovery procedures with point-in-time restore capabilities",
            "Create a data warehouse design with ETL pipelines and dimensional modeling"
        ]
    else:
        # Generic but practical actions
        actions = [
            "Turn this into a step-by-step implementation guide with code examples and validation checkpoints",
            "Create a production-ready template with best practices, error handling, and documentation",
            "Build a working proof of concept with minimal dependencies that demonstrates the core functionality",
            "Generate comprehensive test scenarios with expected outputs and edge case handling",
            "Develop a troubleshooting guide with common issues, solutions, and debugging strategies",
            "Create an automation script that implements this workflow with logging and notifications"
        ]

    import random
    return random.choice(actions)


def parse_json_response_enhanced(response_text):
    """Enhanced JSON parsing with multiple fallback strategies"""
    # Try direct JSON parsing
    try:
        return json.loads(response_text)
    except json.JSONDecodeError:
        pass

    # Try to extract JSON from markdown code blocks
    json_pattern = r'```(?:json)?\s*(\{.*?\})\s*```'
    match = re.search(json_pattern, response_text, re.DOTALL)
    if match:
        try:
            return json.loads(match.group(1))
        except json.JSONDecodeError:
            pass

    # Try to find JSON-like structure
    try:
        start = response_text.find('{')
        end = response_text.rfind('}') + 1
        if start >= 0 and end > start:
            potential_json = response_text[start:end]
            return json.loads(potential_json)
    except (ValueError, json.JSONDecodeError):
        pass

    # If all else fails, raise error
    raise json.JSONDecodeError("Could not parse JSON from response", response_text, 0)


# ========================================
# DEMO ANALYTICS ENDPOINTS
# ========================================

@app.route('/track-demo', methods=['POST'])
def track_demo():
    """Track demo interactions (pill clicks, page visits, etc.)"""
    try:
        data = request.get_json()
        event_type = data.get('event')  # 'page_visits', 'pill_clicks', 'get_started_clicks'
        session_id = data.get('sessionId', 'unknown')
        user_agent = request.headers.get('User-Agent', 'unknown')
        metadata = data.get('metadata', {})

        # Save to database
        conn = sqlite3.connect('demo_analytics.db')
        cursor = conn.cursor()

        cursor.execute('''
            INSERT INTO demo_events (event_type, session_id, user_agent, metadata)
            VALUES (?, ?, ?, ?)
        ''', (
            event_type,
            session_id,
            user_agent,
            str(metadata)
        ))

        conn.commit()
        conn.close()

        return jsonify({'success': True, 'event': event_type})

    except Exception as e:
        print(f"‚ùå Demo tracking error: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/analytics/demo-stats', methods=['GET'])
def get_demo_stats():
    """Get demo analytics stats with unique users tracking"""
    try:
        conn = sqlite3.connect('demo_analytics.db')
        cursor = conn.cursor()

        # Helper function to get counts with unique users
        def get_stats(time_filter=''):
            if time_filter:
                where_clause = f"WHERE {time_filter}"
            else:
                where_clause = ""

            # Total events by type
            cursor.execute(f'''
                SELECT event_type, COUNT(*) as count
                FROM demo_events
                {where_clause}
                GROUP BY event_type
            ''')
            totals = {row[0]: row[1] for row in cursor.fetchall()}

            # Unique users (distinct session_ids)
            cursor.execute(f'''
                SELECT COUNT(DISTINCT session_id) as unique_users
                FROM demo_events
                {where_clause}
            ''')
            unique_users = cursor.fetchone()[0]

            return totals, unique_users

        # Get stats for different time periods
        all_time, all_time_users = get_stats()
        today, today_users = get_stats("DATE(timestamp) = DATE('now')")
        yesterday, yesterday_users = get_stats("DATE(timestamp) = DATE('now', '-1 day')")
        this_week, this_week_users = get_stats("DATE(timestamp) >= DATE('now', '-7 days')")
        month_to_date, mtd_users = get_stats("strftime('%Y-%m', timestamp) = strftime('%Y-%m', 'now')")
        year_to_date, ytd_users = get_stats("strftime('%Y', timestamp) = strftime('%Y', 'now')")

        # Get daily breakdown (last 30 days)
        cursor.execute('''
            SELECT
                event_type,
                DATE(timestamp) as date,
                COUNT(*) as count,
                COUNT(DISTINCT session_id) as unique_users
            FROM demo_events
            WHERE DATE(timestamp) >= DATE('now', '-30 days')
            GROUP BY event_type, DATE(timestamp)
            ORDER BY date DESC
        ''')

        daily = {}
        daily_unique_users = {}
        for event_type, date, count, unique in cursor.fetchall():
            if event_type not in daily:
                daily[event_type] = {}
            daily[event_type][date] = count

            if date not in daily_unique_users:
                daily_unique_users[date] = 0
            daily_unique_users[date] = max(daily_unique_users[date], unique)

        conn.close()

        return jsonify({
            'success': True,
            'totals': {
                'events': all_time,
                'unique_users': all_time_users
            },
            'today': {
                'events': today,
                'unique_users': today_users
            },
            'yesterday': {
                'events': yesterday,
                'unique_users': yesterday_users
            },
            'this_week': {
                'events': this_week,
                'unique_users': this_week_users
            },
            'month_to_date': {
                'events': month_to_date,
                'unique_users': mtd_users
            },
            'year_to_date': {
                'events': year_to_date,
                'unique_users': ytd_users
            },
            'daily': daily,
            'daily_unique_users': daily_unique_users
        })

    except Exception as e:
        print(f"‚ùå Analytics error: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/analytics/demo-dashboard', methods=['GET'])
def demo_dashboard():
    """Enhanced dashboard with unique users tracking"""
    return '''
    <!DOCTYPE html>
    <html>
    <head>
        <title>Solthron Demo Analytics</title>
        <style>
            body {
                font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Arial;
                padding: 40px;
                background: #f5f5f5;
            }
            h1 { color: #333; margin-bottom: 10px; }
            .time-filter {
                display: flex;
                gap: 10px;
                margin: 20px 0 30px 0;
                flex-wrap: wrap;
            }
            .time-btn {
                padding: 10px 20px;
                border: 2px solid #ddd;
                background: white;
                border-radius: 8px;
                cursor: pointer;
                font-weight: 500;
                transition: all 0.2s;
            }
            .time-btn:hover {
                border-color: #ffff00;
                background: #fffef0;
            }
            .time-btn.active {
                border-color: #ffff00;
                background: #ffff00;
                color: #000;
            }
            .metrics {
                display: grid;
                grid-template-columns: repeat(4, 1fr);
                gap: 20px;
                margin: 30px 0;
            }
            .card {
                background: white;
                padding: 30px;
                border-radius: 12px;
                box-shadow: 0 2px 8px rgba(0,0,0,0.1);
                text-align: center;
            }
            .number {
                font-size: 48px;
                font-weight: bold;
                color: #ffff00;
                text-shadow: 1px 1px 2px rgba(0,0,0,0.1);
                margin: 10px 0;
            }
            .label {
                color: #666;
                font-size: 14px;
                text-transform: uppercase;
                letter-spacing: 1px;
            }
            .subtitle {
                color: #999;
                font-size: 12px;
                margin-top: 8px;
            }
            table {
                width: 100%;
                background: white;
                border-radius: 12px;
                overflow: hidden;
                box-shadow: 0 2px 8px rgba(0,0,0,0.1);
                margin-top: 30px;
            }
            th {
                background: #333;
                color: white;
                padding: 15px;
                text-align: left;
            }
            td {
                padding: 15px;
                border-bottom: 1px solid #eee;
            }
            tr:hover { background: #f9f9f9; }
            .pill-icon { color: #ffff00; font-size: 20px; }
            .user-icon { color: #4CAF50; font-size: 20px; }
        </style>
    </head>
    <body>
        <h1>üìä Solthron Demo Analytics Dashboard</h1>
        <p class="subtitle" id="currentView">Viewing: All Time</p>

        <div class="time-filter">
            <button class="time-btn" onclick="setTimeFilter('today')">Today</button>
            <button class="time-btn" onclick="setTimeFilter('yesterday')">Yesterday</button>
            <button class="time-btn" onclick="setTimeFilter('this_week')">This Week</button>
            <button class="time-btn" onclick="setTimeFilter('month_to_date')">Month to Date</button>
            <button class="time-btn" onclick="setTimeFilter('year_to_date')">Year to Date</button>
            <button class="time-btn active" onclick="setTimeFilter('totals')">All Time</button>
        </div>

        <div class="metrics">
            <div class="card">
                <div class="label"><span class="user-icon">üë•</span> Unique Users</div>
                <div class="number" id="uniqueUsers">-</div>
                <div class="subtitle">Distinct visitors</div>
            </div>

            <div class="card">
                <div class="label">Page Visits</div>
                <div class="number" id="pageVisits">-</div>
                <div class="subtitle">Total page loads</div>
            </div>

            <div class="card">
                <div class="label"><span class="pill-icon">üíä</span> Pill Clicks</div>
                <div class="number" id="pillClicks">-</div>
                <div class="subtitle">Demo interactions</div>
            </div>

            <div class="card">
                <div class="label">Get Started</div>
                <div class="number" id="getStartedClicks">-</div>
                <div class="subtitle">Extension downloads</div>
            </div>
        </div>

        <h2>üìÖ Daily Breakdown (Last 30 Days)</h2>
        <table>
            <thead>
                <tr>
                    <th>Date</th>
                    <th>Unique Users</th>
                    <th>Page Visits</th>
                    <th>Pill Clicks</th>
                    <th>Get Started</th>
                </tr>
            </thead>
            <tbody id="dailyTable"></tbody>
        </table>

        <script>
            let statsData = null;
            let currentFilter = 'totals';

            fetch('/analytics/demo-stats')
                .then(r => r.json())
                .then(data => {
                    statsData = data;
                    updateMetrics('totals');
                    updateDailyTable();
                });

            function setTimeFilter(filter) {
                currentFilter = filter;

                document.querySelectorAll('.time-btn').forEach(btn => {
                    btn.classList.remove('active');
                });
                event.target.classList.add('active');

                const labels = {
                    'today': 'Today',
                    'yesterday': 'Yesterday',
                    'this_week': 'This Week (Last 7 Days)',
                    'month_to_date': 'Month to Date',
                    'year_to_date': 'Year to Date',
                    'totals': 'All Time'
                };
                document.getElementById('currentView').textContent = 'Viewing: ' + labels[filter];

                updateMetrics(filter);
            }

            function updateMetrics(filter) {
                if (!statsData) return;

                const data = statsData[filter];
                const events = data.events || {};

                document.getElementById('uniqueUsers').textContent = data.unique_users || 0;
                document.getElementById('pageVisits').textContent = events.page_visits || 0;
                document.getElementById('pillClicks').textContent = events.pill_clicks || 0;
                document.getElementById('getStartedClicks').textContent = events.get_started_clicks || 0;
            }

            function updateDailyTable() {
                if (!statsData) return;

                const tbody = document.getElementById('dailyTable');
                const daily = statsData.daily;
                const uniqueUsers = statsData.daily_unique_users;

                const dates = [...new Set([
                    ...Object.keys(daily.page_visits || {}),
                    ...Object.keys(daily.pill_clicks || {}),
                    ...Object.keys(daily.get_started_clicks || {}),
                    ...Object.keys(uniqueUsers || {})
                ])].sort().reverse();

                tbody.innerHTML = '';
                dates.forEach(date => {
                    const row = tbody.insertRow();
                    row.innerHTML = `
                        <td><strong>${date}</strong></td>
                        <td>${uniqueUsers[date] || 0}</td>
                        <td>${daily.page_visits?.[date] || 0}</td>
                        <td>${daily.pill_clicks?.[date] || 0}</td>
                        <td>${daily.get_started_clicks?.[date] || 0}</td>
                    `;
                });
            }
        </script>
    </body>
    </html>
    '''

if __name__ == '__main__':
    app.run(debug=True)

# Set application variable for PythonAnywhere
application = app
